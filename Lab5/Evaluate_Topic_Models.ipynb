{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48n79i-k2Wpu"
      },
      "source": [
        "### Evaluate Topic Model in Python: Latent Dirichlet Allocation (LDA)\\\n",
        "##### A step-by-step guide to building interpretable topic models\n",
        "\n",
        "** **\n",
        "*Preface: This article aims to provide consolidated information on the underlying topic and is not to be considered as the original work. The information and the code are repurposed through several online articles, research papers, books, and open-source code*\n",
        "** **\n",
        "\n",
        "In the previous [article](https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0), I introduced the concept of topic modeling and walked through the code for developing your first topic model using Latent Dirichlet Allocation (LDA) method in the python using Gensim implementation.\n",
        "\n",
        "Pursuing on that understanding, in this article, we’ll go a few steps deeper by outlining the framework to quantitatively evaluate topic models through the measure of topic coherence and share the code template in python using Gensim implementation to allow for end-to-end model development.\n",
        "\n",
        "### Why evaluate topic models?\n",
        "\n",
        "![img](https://tinyurl.com/y3xznjwq)\n",
        "\n",
        "We know probabilistic topic models, such as LDA, are popular tools for text analysis, providing both a predictive and latent topic representation of the corpus. However, there is a longstanding assumption that the latent space discovered by these models is generally meaningful and useful, and that evaluating such assumptions is challenging due to its unsupervised training process. Besides, there is a no-gold standard list of topics to compare against every corpus.\n",
        "\n",
        "Nevertheless, it is equally important to identify if a trained model is objectively good or bad, as well have an ability to compare different models/methods. To do so, one would require an objective measure for the quality. Traditionally, and still for many practical applications, to evaluate if “the correct thing” has been learned about the corpus, an implicit knowledge and “eyeballing” approaches are used. Ideally, we’d like to capture this information in a single metric that can be maximized, and compared.\n",
        "\n",
        "Let’s take a look at roughly what approaches are commonly used for the evaluation:\n",
        "\n",
        "**Eye Balling Models**\n",
        "- Top N words\n",
        "- Topics / Documents\n",
        "\n",
        "**Intrinsic Evaluation Metrics**\n",
        "- Capturing model semantics\n",
        "- Topics interpretability\n",
        "\n",
        "**Human Judgements**\n",
        "- What is a topic\n",
        "\n",
        "**Extrinsic Evaluation Metrics/Evaluation at task**\n",
        "- Is model good at performing predefined tasks, such as classification\n",
        "\n",
        "Natural language is messy, ambiguous and full of subjective interpretation, and sometimes trying to cleanse ambiguity reduces the language to an unnatural form. In this article, we’ll explore more about topic coherence, an intrinsic evaluation metric, and how you can use it to quantitatively justify the model selection.\n",
        "\n",
        "### What is Topic Coherence?\n",
        "\n",
        "Before we understand topic coherence, let’s briefly look at the perplexity measure. Perplexity as well is one of the intrinsic evaluation metric, and is widely used for language model evaluation. It captures how surprised a model is of new data it has not seen before, and is measured as the normalized log-likelihood of a held-out test set.\n",
        "\n",
        "Focussing on the log-likelihood part, you can think of the perplexity metric as measuring how probable some new unseen data is given the model that was learned earlier. That is to say, how well does the model represent or reproduce the statistics of the held-out data.\n",
        "\n",
        "However, recent studies have shown that predictive likelihood (or equivalently, perplexity) and human judgment are often not correlated, and even sometimes slightly anti-correlated.\n",
        "\n",
        "*Optimizing for perplexity may not yield human interpretable topics*\n",
        "\n",
        "This limitation of perplexity measure served as a motivation for more work trying to model the human judgment, and thus *Topic Coherence*.\n",
        "\n",
        "The concept of topic coherence combines a number of measures into a framework to evaluate the coherence between topics inferred by a model. But before that…\n",
        "\n",
        "#### What is topic coherence?\n",
        "Topic Coherence measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference. But,\n",
        "\n",
        "#### What is coherence?\n",
        "Topic Coherence measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference. But …\n",
        "\n",
        "### Coherence Measures\n",
        "Let’s take quick look at different coherence measures, and how they are calculated:\n",
        "\n",
        "1. `C_v` measure is based on a sliding window, one-set segmentation of the top words and an indirect confirmation measure that uses normalized pointwise mutual information (NPMI) and the cosine similarity\n",
        "2. `C_p` is based on a sliding window, one-preceding segmentation of the top words and the confirmation measure of Fitelson's coherence\n",
        "3. `C_uci` measure is based on a sliding window and the pointwise mutual information (PMI) of all word pairs of the given top words\n",
        "4. `C_umass` is based on document cooccurrence counts, a one-preceding segmentation and a logarithmic conditional probability as confirmation measure\n",
        "5. `C_npmi` is an enhanced version of the C_uci coherence using the normalized pointwise mutual information (NPMI)\n",
        "6. `C_a` is based on a context window, a pairwise comparison of the top words and an indirect confirmation measure that uses normalized pointwise mutual information (NPMI) and the cosine similarity\n",
        "\n",
        "There is, of course, a lot more to the concept of topic model evaluation, and the coherence measure. However, keeping in mind the length, and purpose of this article, let’s apply these concepts into developing a model that is at least better than with the default parameters. Also, we’ll be re-purposing already available online pieces of code to support this exercise instead of re-inventing the wheel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH51RfbU2Wpx"
      },
      "source": [
        "### Model Implementation\n",
        "1. Loading Data\n",
        "2. Data Cleaning\n",
        "3. Phrase Modeling: Bi-grams and Tri-grams\n",
        "4. Data Transformation: Corpus and Dictionary\n",
        "5. Base Model\n",
        "6. Hyper-parameter Tuning\n",
        "7. Final model\n",
        "8. Visualize Results\n",
        "\n",
        "** **\n",
        "\n",
        "For this tutorial, we’ll use the dataset of papers published in NeurIPS (NIPS) conference which is one of the most prestigious yearly events in the machine learning community. The CSV data file contains information on the different NeurIPS papers that were published from 1987 until 2016 (29 years!). These papers discuss a wide variety of topics in machine learning, from neural networks to optimization methods, and many more.\n",
        "\n",
        "<img src=\"https://s3.amazonaws.com/assets.datacamp.com/production/project_158/img/nips_logo.png\" alt=\"The logo of NIPS (Neural Information Processing Systems)\">\n",
        "\n",
        "Let’s start by looking at the content of the file\n",
        "\n",
        "** **\n",
        "#### Step 1: Loading Data\n",
        "** **\n",
        "\n",
        "For this tutorial, we’ll use the dataset of papers published in NIPS conference. The NIPS conference (Neural Information Processing Systems) is one of the most prestigious yearly events in the machine learning community. The CSV data file contains information on the different NIPS papers that were published from 1987 until 2016 (29 years!). These papers discuss a wide variety of topics in machine learning, from neural networks to optimization methods, and many more.\n",
        "\n",
        "Let’s start by looking at the content of the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "CYY71TMF2Wpx",
        "outputId": "1f449a47-a1e6-4813-e1ec-107c69f68ffc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id  year                                              title event_type  \\\n",
              "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
              "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
              "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
              "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
              "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
              "\n",
              "                                            pdf_name          abstract  \\\n",
              "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
              "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
              "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
              "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
              "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
              "\n",
              "                                          paper_text  \n",
              "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
              "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
              "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
              "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
              "4  Neural Network Ensembles, Cross\\nValidation, a...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5dd12209-83d4-431e-948c-d15797576d2a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>event_type</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1987</td>\n",
              "      <td>Self-Organization of Associative Database and ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1-self-organization-of-associative-database-an...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>1987</td>\n",
              "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>1988</td>\n",
              "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>1994</td>\n",
              "      <td>Bayesian Query Construction for Neural Network...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1001</td>\n",
              "      <td>1994</td>\n",
              "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dd12209-83d4-431e-948c-d15797576d2a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5dd12209-83d4-431e-948c-d15797576d2a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5dd12209-83d4-431e-948c-d15797576d2a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7e1699c7-909a-470d-b66b-ce4498dbcd17\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e1699c7-909a-470d-b66b-ce4498dbcd17')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7e1699c7-909a-470d-b66b-ce4498dbcd17 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "papers",
              "summary": "{\n  \"name\": \"papers\",\n  \"rows\": 6560,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1901,\n        \"min\": 1,\n        \"max\": 6603,\n        \"num_unique_values\": 6560,\n        \"samples\": [\n          3087,\n          78,\n          5412\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1987,\n        \"max\": 2016,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          1992,\n          1990,\n          2012\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6560,\n        \"samples\": [\n          \"Natural Actor-Critic for Road Traffic Optimisation\",\n          \"Learning Representations by Recirculation\",\n          \"Quantized Kernel Learning for Feature Matching\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"event_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Oral\",\n          \"Spotlight\",\n          \"Poster\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pdf_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6560,\n        \"samples\": [\n          \"3087-natural-actor-critic-for-road-traffic-optimisation.pdf\",\n          \"78-learning-representations-by-recirculation.pdf\",\n          \"5412-quantized-kernel-learning-for-feature-matching.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3244,\n        \"samples\": [\n          \"Tensor CANDECOMP/PARAFAC (CP) decomposition has wide applications in statistical learning of latent variable models and in data mining. In this paper, we propose fast and randomized tensor CP decomposition algorithms based on sketching. We build on the idea of count sketches, but introduce many novel ideas which are unique to tensors. We develop novel methods for randomized com- putation of tensor contractions via FFTs, without explicitly forming the tensors. Such tensor contractions are encountered in decomposition methods such as ten- sor power iterations and alternating least squares. We also design novel colliding hashes for symmetric tensors to further save time in computing the sketches. We then combine these sketching ideas with existing whitening and tensor power iter- ative techniques to obtain the fastest algorithm on both sparse and dense tensors. The quality of approximation under our method does not depend on properties such as sparsity, uniformity of elements, etc. We apply the method for topic mod- eling and obtain competitive results.\",\n          \"Many spectral unmixing methods rely on the non-negative decomposition of spectral data onto a dictionary of spectral templates. In particular, state-of-the-art music transcription systems decompose the spectrogram of the input signal onto a dictionary of representative note spectra. The typical measures of fit used to quantify the adequacy of the decomposition compare the data and template entries frequency-wise. As such, small displacements of energy from a frequency bin to another as well as variations of timber can disproportionally harm the fit. We address these issues by means of optimal transportation and propose a new measure of fit that treats the frequency distributions of energy holistically as opposed to frequency-wise. Building on the harmonic nature of sound, the new measure is invariant to shifts of energy to harmonically-related frequencies, as well as to small and local displacements of energy. Equipped with this new measure of fit, the dictionary of note templates can be considerably simplified to a set of Dirac vectors located at the target fundamental frequencies (musical pitch values). This in turns gives ground to a very fast and simple decomposition algorithm that achieves state-of-the-art performance on real musical data.\",\n          \"The problem of  multiclass boosting is considered. A new framework,based on multi-dimensional codewords and predictors is introduced. The optimal set of codewords is derived, and a margin enforcing loss proposed. The resulting risk is minimized by gradient descent on a multidimensional functional space. Two algorithms are proposed: 1) CD-MCBoost, based on coordinate descent, updates one predictor component at a time, 2) GD-MCBoost, based on gradient descent, updates all components jointly. The algorithms differ in the weak learners that they support but are both shown to be 1) Bayes consistent, 2) margin enforcing, and 3) convergent to the global minimum of the risk. They also reduce to AdaBoost when there are only two classes. Experiments show that both methods outperform previous multiclass boosting approaches on a number of datasets.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6553,\n        \"samples\": [\n          \"550\\n\\nAckley and Littman\\n\\nGeneralization and scaling in reinforcement\\nlearning\\nDavid H. Ackley\\nMichael L. Littman\\nCognitive Science Research Group\\nBellcore\\nMorristown, NJ 07960\\n\\nABSTRACT\\nIn associative reinforcement learning, an environment generates input\\nvectors, a learning system generates possible output vectors, and a reinforcement function computes feedback signals from the input-output\\npairs. The task is to discover and remember input-output pairs that\\ngenerate rewards. Especially difficult cases occur when rewards are\\nrare, since the expected time for any algorithm can grow exponentially\\nwith the size of the problem. Nonetheless, if a reinforcement function\\npossesses regularities, and a learning algorithm exploits them, learning\\ntime can be reduced below that of non-generalizing algorithms. This\\npaper describes a neural network algorithm called complementary reinforcement back-propagation (CRBP), and reports simulation results\\non problems designed to offer differing opportunities for generalization.\\n\\n1\\n\\nREINFORCEMENT LEARNING REQUIRES SEARCH\\n\\nReinforcement learning (Sutton, 1984; Barto & Anandan, 1985; Ackley, 1988; Allen,\\n1989) requires more from a learner than does the more familiar supervised learning\\nparadigm. Supervised learning supplies the correct answers to the learner, whereas\\nreinforcement learning requires the learner to discover the correct outputs before\\nthey can be stored. The reinforcement paradigm divides neatly into search and\\nlearning aspects: When rewarded the system makes internal adjustments to learn\\nthe discovered input-output pair; when punished the system makes internal adjustments to search elsewhere.\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n1.1\\n\\nMAKING REINFORCEMENT INTO ERROR\\n\\nFollowing work by Anderson (1986) and Williams (1988), we extend the backpropagation algorithm to associative reinforcement learning. Start with a \\\"garden variety\\\" backpropagation network: A vector i of n binary input units propagates\\nthrough zero or more layers of hidden units, ultimately reaching a vector 8 of m\\nsigmoid units, each taking continuous values in the range (0,1). Interpret each 8j\\nas the probability that an associated random bit OJ takes on value 1. Let us call\\nthe continuous, deterministic vector 8 the search vector to distinguish it from the\\nstochastic binary output vector o.\\nGiven an input vector, we forward propagate to produce a search vector 8, and\\nthen perform m independent Bernoulli trials to produce an output vector o. The\\ni - 0 pair is evaluated by the reinforcement function and reward or punishment\\nensues. Suppose reward occurs. We therefore want to make 0 more likely given i.\\nBackpropagation will do just that if we take 0 as the desired target to produce an\\nerror vector (0 - 8) and adjust weights normally.\\nNow suppose punishment occurs, indicating 0 does not correspond with i. By choice\\nof error vector, backpropagation allows us to push the search vector in any direction;\\nwhich way should we go? In absence of problem-specific information, we cannot pick\\nan appropriate direction with certainty. Any decision will involve assumptions. A\\nvery minimal \\\"don't be like 0\\\" assumption-employed in Anderson (1986), Williams\\n(1988), and Ackley (1989)-pushes s directly away from 0 by taking (8 - 0) as the\\nerror vector. A slightly stronger \\\"be like not-o\\\" assumption-employed in Barto &\\nAnandan (1985) and Ackley (1987)-pushes s directly toward the complement of 0\\nby taking ((1 - 0) - 8) as the error vector. Although the two approaches always\\nagree on the signs of the error terms, they differ in magnitudes. In this work,\\nwe explore the second possibility, embodied in an algorithm called complementary\\nreinforcement back-propagation ( CRBP).\\nFigure 1 summarizes the CRBP algorithm. The algorithm in the figure reflects three\\nmodifications to the basic approach just sketched. First, in step 2, instead of using\\nthe 8j'S directly as probabilities, we found it advantageous to \\\"stretch\\\" the values\\nusing a parameter v. When v < 1, it is not necessary for the 8i'S to reach zero or\\none to produce a deterministic output. Second, in step 6, we found it important\\nto use a smaller learning rate for punishment compared to reward. Third, consider\\nstep 7: Another forward propagation is performed, another stochastic binary output vector 0* is generated (using the procedure from step 2), and 0* is compared\\nto o. If they are identical and punishment occurred, or if they are different and\\nreward occurred, then another error vector is generated and another weight update\\nis performed. This loop continues until a different output is generated (in the case\\nof failure) or until the original output is regenerated (in the case of success). This\\nmodification improved performance significantly, and added only a small percentage\\nto the total number of weight updates performed.\\n\\n551\\n\\n\\f552\\n\\nAckley and Littman\\n\\nO. Build a back propagation network with input dimensionality n and output\\ndimensionality m. Let t = 0 and te = O.\\n1. Pick random i E 2n and forward propagate to produce a/s.\\n2. Generate a binary output vector o. Given a uniform random variable ~ E [0,1]\\nand parameter 0 < v < 1,\\nOJ\\n\\n=\\n\\n{1,\\n\\n0,\\n\\nif(sj - !)/v+! ~ ~j\\notherwise.\\n\\n3. Compute reinforcement r = f(i,o). Increment t. If r < 0, let te = t.\\n4. Generate output errors ej. If r > 0, let tj = OJ, otherwise let tj = 1- OJ. Let\\nej = (tj - sj)sj(l- Sj).\\n5. Backpropagate errors.\\n6. Update weights. 1:::..Wjk = 1]ekSj, using 1] = 1]+ if r ~ 0, and 1] = 1]- otherwise,\\nwith parameters 1]+,1]- > o.\\n7. Forward propagate again to produce new Sj's. Generate temporary output\\nvector 0*. If (r > 0 and 0* #- 0) or (r < 0 and 0* = 0), go to 4.\\n8. If te ~ t, exit returning te, else go to 1.\\n\\nFigure 1: Complementary Reinforcement Back Propagation-CRBP\\n\\n2\\n\\nON-LINE GENERALIZATION\\n\\nWhen there are many possible outputs and correct pairings are rare, the computational cost associated with the search for the correct answers can be profound.\\nThe search for correct pairings will be accelerated if the search strategy can effectively generalize the reinforcement received on one input to others. The speed of\\nan algorithm on a given problem relative to non-generalizing algorithms provides a\\nmeasure of generalization that we call on-line generalization.\\nO. Let z be an array of length 2n. Set the z[i] to random numbers from 0 to\\n2m - 1. Let t = te = O.\\n1. Pick a random input i E 2n.\\n2. Compute reinforcement r = f(i, z[i]). Increment t.\\n3. If r < 0 let z[i] = (z[i] + 1) mod 2m , and let te = t.\\n4. If te <t:: t exit returning t e, else go to 1.\\n\\nFigure 2: The Table Lookup Reference Algorithm Tref(f, n, m)\\nConsider the table-lookup algorithm Tref(f, n, m) summarized in Figure 2. In this\\nalgorithm, a separate storage location is used for each possible input. This prevents\\nthe memorization of one i - 0 pair from interfering with any other. Similarly,\\nthe selection of a candidate output vector depends only on the slot of the table\\ncorresponding to the given input. The learning speed of T ref depends only on the\\ninput and output dimensionalities and the number of correct outputs associated\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n\\nwith each input. When a problem possesses n input bits and n output bits, and\\nthere is only one correct output vector for each input vector, Tre{ runs in about 4n\\ntime (counting each input-output judgment as one.) In such cases one expects to\\ntake at least 2n - 1 just to find one correct i - 0 pair, so exponential time cannot be\\navoided without a priori information. How does a generalizing algorithm such as\\nCRBP compare to Trer?\\n\\n3\\n\\nSIMULATIONS ON SCALABLE PROBLEMS\\n\\nWe have tested CRBP on several simple problems designed to offer varying degrees\\nand types of generalization. In all of the simulations in this section, the following\\ndetails apply: Input and output bit counts are equal (n). Parameters are dependent\\non n but independent of the reinforcement function f. '7+ is hand-picked for each\\nn,l 11- = 11+/10 and II = 0.5. All data points are medians of five runs. The stopping\\ncriterion te ~ t is interpreted as te +max(2000, 2n+l) < t. The fit lines in the figures\\nare least squares solutions to a x bn , to two significant digits.\\nAs a notational convenience, let c = ~\\n\\n3.1\\n\\nn\\n\\nE ij\\n\\n;=1\\n\\n-\\n\\nthe fraction of ones in the input.\\n\\nn-MAJORlTY\\n\\nConsider this \\\"majority rules\\\" problem: [if c > ~ then 0 = In else 0 = on]. The i-o\\nmapping is many-to-l. This problem provides an opportunity for what Anderson\\n(1986) called \\\"output generalization\\\": since there are only two correct output states,\\nevery pair of output bits are completely correlated in the cases when reward occurs.\\n\\nG)\\n\\n'iii\\nu\\nrn\\n\\nC)\\n\\n0\\n\\n::::.\\nG)\\n\\nE\\n\\n;\\n\\n10 7\\n10 6\\n10 5\\n10 4\\n\\nx\\n\\nTable\\n\\nD\\n\\nCRBP n-n-n\\n\\n+ CRBP n-n\\n\\n10 3\\n10 2\\n10 1\\n10 0\\n0\\n\\n1\\n\\n2\\n\\n3\\n\\n456\\n\\n78\\n\\n91011121314\\n\\nn\\nFigure 3: The n-majority problem\\n\\nFigure 3 displays the simulation results. Note that although Trer is faster than\\nCRBP at small values of n, CRBP's slower growth rate (1.6n vs 4.2n ) allows it to\\ncross over and begin outperforming Trer at about 6 bits. Note also--in violation of\\n1 For n = 1 to 12. we used '1+\\n0.219. 0.170. 0.121}.\\n\\n= {2.000. 1.550. 1.130.0.979.0.783.0.709.0.623.0.525.0.280.\\n\\n553\\n\\n\\f554\\n\\nAckley and Littman\\n\\nsome conventional wisdom-that although n-majority is a linearly separable problem, the performance of CRBP with hidden units is better than without. Hidden\\nunits can be helpful--even on linearly separable problems-when there are opportunities for output generalization.\\n\\n3.2\\n\\nn-COPY AND THE 2k -ATTRACTORS FAMILY\\n\\nAs a second example, consider the n-copy problem: [0 = i]. The i-o mapping is now\\n1-1, and the values of output bits in rewarding states are completely uncorrelated,\\nbut the value of each output bit is completely correlated with the value of the\\ncorresponding input bit. Figure 4 displays the simulation results. Once again, at\\n\\nG)\\n\\n'ii\\n\\ntA\\nQ\\n0\\n\\n::::.\\nG)\\n\\n-\\n\\n.5\\n\\n10 7\\n10 6\\n10 5\\n10 4\\n\\nx\\n150*2.0I\\\\n\\n\\nD\\n\\n10 3\\n10 2\\n\\n12*2.2I\\\\n\\n\\n+\\n\\nTable\\nCRBP n-n-n\\nCRBP n-n\\n\\n10 1\\n10 0\\n0\\n\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\n9\\n\\n10 1112\\n\\nn\\nFigure 4: The n-copy problem\\nlow values of n, Trer is faster, but CRBP rapidly overtakes Trer as n increases. In\\nn-copy, unlike n-majority, CRBP performs better without hidden units.\\nThe n-majority and n-copy problems are extreme cases of a spectrum. n-majority\\ncan be viewed as a \\\"2-attractors\\\" problem in that there are only two correct\\noutputs-all zeros and all ones-and the correct output is the one that i is closer\\nto in hamming distance. By dividing the input and output bits into two groups\\nand performing the majority function independently on each group, one generates\\na \\\"4-aUractors\\\" problem. In general, by dividing the input and output bits into\\n1 ~ Ie ~ n groups, one generates a \\\"2i:-attractors\\\" problem. When Ie = 1, nmajority results, and when Ie n, n-copy results.\\n\\n=\\n\\nFigure 5 displays simulation results on the n = 8-bit problems generated when Ie is\\nvaried from 1 to n. The advantage of hidden units for low values of Ie is evident,\\nas is the advantage of \\\"shortcut connections\\\" (direct input-to-output weights) for\\nlarger values of Ie. Note also that combination of both hidden units and shortcut\\nconnections performs better than either alone.\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n\\n105~--------------------------------~\\n\\nCASP 8-10-8\\n-+- CASP 8-8\\n.... CASP 8-10-Sls\\n-0-\\n\\n... Table\\n\\n3\\n\\n2\\n\\n1\\n\\n5\\n\\n4\\n\\n7\\n\\n6\\n\\n8\\n\\nk\\n\\nFigure 5: The 21:- attractors family at n = 8\\n\\n3.3\\n\\nn-EXCLUDED MIDDLE\\n\\nAll of the functions considered so far have been linearly separable. Consider this\\n\\\"folded majority\\\" function: [if\\n< c < then 0 on else 0 In]. Now, like\\nn-majority, there are only two rewarding output states, but the determination of\\nwhich output state is correct is not linearly separable in the input space. When\\nn = 2, the n-excluded middle problem yields the EQV (i.e., the complement of\\nXOR) function, but whereas functions such as n-parity [if nc is even then 0\\non\\nelse 0 = In] get more non-linear with increasing n, n-excluded middle does not.\\n\\ni\\n\\ni\\n\\n=\\n\\n=\\n\\n=\\n\\n107~------------------------------~~\\n\\n-\\n\\n10 6\\n10 5\\n\\nD)\\n\\n10 4\\n10 3\\n\\nI)\\n\\n'ii\\nu\\nf)\\n\\n.2\\n\\nI)\\n\\nE\\n\\n:::\\n\\nx\\nc\\n\\n17oo*1.6\\\"n\\n\\nTable\\n\\nCRSP n-n-n/s\\n\\n10 2\\n10 1\\n10 0\\n0\\n\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\n9\\n\\n10 1112\\n\\nn\\nFigure 6: The n-excluded middle problem\\nFigure 6 displays the simulation results. CRBP is slowed somewhat compared to\\nthe linearly separable problems, yielding a higher \\\"cross over point\\\" of about 8 bits.\\n\\n555\\n\\n\\f556\\n\\nAckley and Littman\\n\\n4\\n\\nSTRUCTURING DEGENERATE OUTPUT SPACES\\n\\nAll of the scaling problems in the previous section are designed so that there is\\na single correct output for each possible input. This allows for difficult problems\\neven at small sizes, but it rules out an important aspect of generalizing algorithms\\nfor associative reinforcement learning: If there are multiple satisfactory outputs\\nfor given inputs, a generalizing algorithm may impose structure on the mapping it\\nproduces.\\nWe have two demonstrations of this effect, \\\"Bit Count\\\" and \\\"Inverse Arithmetic.\\\"\\nThe Bit Count problem simply states that the number of I-bits in the output should\\nequal the number of I-bits in the input. When n = 9, Tref rapidly finds solutions\\ninvolving hundreds of different output patterns. CRBP is slower--especially with\\nrelatively few hidden units-but it regularly finds solutions involving just 10 output\\npatterns that form a sequence from 09 to 19 with one bit changing per step.\\n0+Ox4=0\\n1+0x4=1\\n2+0x4=2\\n3+0x4=3\\n\\n0+2x4=8\\n1+2x4=9\\n2 + 2 x 4 = 10\\n3+2x4=11\\n\\n4+0x4=4 4+ 2 x 4 =\\n5+0x4=5 5 + 2 x 4 =\\n6+0x4=6 6 + 2 x 4 =\\n7+0x4=7 7 + 2 x 4 =\\n\\n12\\n13\\n14\\n15\\n\\n2+2-4=0 2+2+4=8\\n3+2-4=1 3+2+4=9\\n2+2+4=2 2 + 2 x 4 = 10\\n3+2+4=3 3+2x4=1l\\n6+2-4=4\\n7+2-4=5\\n6+2+4=6\\n7+2-.;-4=7\\n\\n6+\\n7+\\n6+\\n7+\\n\\n2+ 4 =\\n2+ 4 =\\n2x4=\\n2x4=\\n\\n0+4 x 4 = 16 0+6 x 4 =\\n1+4x4=17 1 + 6 x 4 =\\n2 + 4 x 4 = 18 2 + 6 x 4 =\\n3 +4 x 4 = 19 3 + 6 x 4 =\\n\\n24\\n25\\n26\\n27\\n\\n4+4\\n5+ 4\\n6+ 4\\n7+ 4\\n\\n=\\n=\\n=\\n=\\n\\n28\\n29\\n30\\n31\\n24\\n25\\n26\\n27\\n\\nx\\nx\\nx\\nx\\n\\n4=\\n4=\\n4=\\n4=\\n\\n6+ 6 + 4 =\\n7+6+4=\\n2+ 4 x 4 =\\n3+ 4 x 4=\\n\\n12 4 x 4 +\\n13 5 + 4 x\\n14 6 + 4 x\\n15 7 +4 x\\n\\n4=\\n4=\\n4\\n4=\\n\\n=\\n\\n20 4 + 6 x\\n21 5 + 6 x\\n22 6 + 6 x\\n23 7 + 6 x\\n\\n4\\n4\\n4\\n4\\n\\n16\\n17\\n18\\n19\\n\\n0+6 x\\n1+ 6 x\\n2+ 6x\\n3+ 6x\\n\\n4=\\n4=\\n4=\\n4=\\n\\n20\\n21\\n22\\n23\\n\\n4+\\n5+\\n6+\\n7+\\n\\n4 = 28\\n4 = 29\\n4 30\\n4 = 31\\n\\n6\\n6\\n6\\n6\\n\\nx\\nx\\nx\\nx\\n\\n=\\n\\nFigure 7: Sample CRBP solutions to Inverse Arithmetic\\n\\nThe Inverse Arithmetic problem can be summarized as follows: Given i E 25 , find\\n:1:, y, z E 23 and 0, <> E {+(OO)' -(01)' X (10)' +(11)} such that :I: oy<>z = i. In all there are\\n13 bits of output, interpreted as three 3-bit binary numbers and two 2-bit operators,\\nand the task is to pick an output that evaluates to the given 5-bit binary input\\nunder the usual rules: operator precedence, left-right evaluation, integer division,\\nand division by zero fails.\\nAs shown in Figure 7, CRBP sometimes solves this problem essentially by discovering positional notation, and sometimes produces less-globally structured solutions,\\nparticularly as outputs for lower-valued i's, which have a wider range of solutions.\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n\\n5\\n\\nCONCLUSIONS\\n\\nSome basic concepts of supervised learning appear in different guises when the\\nparadigm of reinforcement learning is applied to large output spaces. Rather than\\na \\\"learning phase\\\" followed by a \\\"generalization test,\\\" in reinforcement learning\\nthe search problem is a generalization test, performed simultaneously with learning.\\nInformation is put to work as soon as it is acquired.\\nThe problem of of \\\"overfitting\\\" or \\\"learning the noise\\\" seems to be less of an issue,\\nsince learning stops automatically when consistent success is reached. In experiments not reported here we gradually increased the number of hidden units on\\nthe 8-bit copy problem from 8 to 25 without observing the performance decline\\nassociated with \\\"too many free parameters.\\\"\\nThe 2 k -attractors (and 2 k -folds-generalizing Excluded Middle) families provide\\na starter set of sample problems with easily understood and distinctly different\\nextreme cases.\\nIn degenerate output spaces, generalization decisions can be seen directly in the\\ndiscovered mapping. Network analysis is not required to \\\"see how the net does it.\\\"\\nThe possibility of ultimately generating useful new knowledge via reinforcement\\nlearning algorithms cannot be ruled out.\\nReferences\\nAckley, D.H. (1987) A connectionist machine for genetic hillclimbing. Boston, MA: Kluwer\\nAcademic Press.\\nAckley, D.H. (1989) Associative learning via inhibitory search. In D.S. Touretzky (ed.),\\nAdvances in Neural Information Processing Systems 1, 20-28. San Mateo, CA: Morgan\\nKaufmann.\\nAllen, R.B. (1989) Developing agent models with a neural reinforcement technique. IEEE\\nSystems, Man, and Cybernetics Conference. Cambridge, MA.\\nAnderson, C.W. (1986) Learning and problem solving with multilayer connectionist systems. University of Mass. Ph.D. dissertation. COINS TR 86-50. Amherst, MA.\\nBarto, A.G. (1985) Learning by statistical cooperation of self-interested neuron-like computing elements. Human Neurobiology, 4:229-256.\\nBarto, A.G., & Anandan, P. (1985) Pattern recognizing stochastic learning automata.\\nIEEE Transactions on Systems, Man, and Cybernetics, 15, 360-374.\\nRumelhart, D.E., Hinton, G.E., & Williams, R.J. (1986) Learning representations by backpropagating errors. Nature, 323, 533-536.\\nSutton, R.S. (1984) Temporal credit assignment in reinforcement learning. University of\\nMass. Ph.D. dissertation. COINS TR 84-2. Amherst, MA.\\nWilliams, R.J. (1988) Toward a theory of reinforcement-learning connectionist systems.\\nCollege of Computer Science of Northeastern University Technical Report NU-CCS-88-3.\\nBoston, MA.\\n\\n557\\n\\n\\f\",\n          \"Dynamics of Supervised Learning with\\nRestricted Training Sets and Noisy Teachers\\n\\nA.C.C. Coolen\\nDept of Mathematics\\nKing's College London\\nThe Strand, London WC2R 2LS, UK\\ntcoolen@mth.kc1.ac.uk\\n\\nC.W.H.Mace\\nDept of Mathematics\\nKing's College London\\nThe Strand, London WC2R 2LS, UK\\ncmace@mth.kc1.ac.uk\\n\\nAbstract\\nWe generalize a recent formalism to describe the dynamics of supervised\\nlearning in layered neural networks, in the regime where data recycling\\nis inevitable, to the case of noisy teachers. Our theory generates reliable\\npredictions for the evolution in time of training- and generalization errors, and extends the class of mathematically solvable learning processes\\nin large neural networks to those situations where overfitting can occur.\\n\\n1 Introduction\\nTools from statistical mechanics have been used successfully over the last decade to study\\nthe dynamics of learning in layered neural networks (for reviews see e.g. [1] or [2]). The\\nsimplest theories result upon assuming the data set to be much larger than the number\\nof weight updates made, which rules out recycling and ensures that any distribution of\\nrelevance will be Gaussian. Unfortunately, both in terms of applications and in terms of\\nmathematical interest, this regime is not the most relevant one. Most complications and\\npeculiarities in the dynamics of learning arise precisely due to data recycling, which creates\\nfor the system the possibility to improve performance by memorizing answers rather than\\nby learning an underlying rule. The dynamics of learning with restricted training sets was\\nfirst studied analytically in [3] (linear learning rules) and [4] (systems with binary weights).\\nThe latter studies were ahead of their time, and did not get the attention they deserved just\\nbecause at that stage even the simpler learning dynamics without data recycling had not\\nyet been studied. More recently attention has moved back to the dynamics of learning\\nin the recycling regime. Some studies aimed at developing a general theory [5, 6, 7],\\nsome at finding exact solutions for special cases [8]. All general theories published so far\\nhave in common that they as yet considered realizable scenario's: the rule to be learned\\nwas implementable by the student, and overfitting could not yet occur. The next hurdle is\\nthat where restricted training sets are combined with unrealizable rules. Again some have\\nturned to non-typical but solvable cases, involving Hebbian rules and noisy [9] or 'reverse\\nwedge' teachers [10]. More recently the cavity method has been used to build a general\\ntheory [11] (as yet for batch learning only). In this paper we generalize the general theory\\nlaunched in [6,5,7], which applies to arbitrary learning rules, to the case of noisy teachers.\\nWe will mirror closely the presentation in [6] (dealing with the simpler case of noise-free\\nteachers), and we refer to [5, 7] for background reading on the ideas behind the formalism.\\n\\n\\fA. C. C. Coolen and C. W. H. Mace\\n\\n238\\n\\n2 Definitions\\nAs in [6, 5] we restrict ourselves for simplicity to perceptrons. A student perceptron operates a linear separation, parametrised by a weight vector J E iRN :\\nS:{-I,I}N -t{-I,I}\\n\\nS(e) = sgn[J?e]\\n\\nIt aims to emulate a teacher o~erating a similar rule, which, however, is characterized by a\\nvariable weight vector BE iR ,drawn at random from a distribution P(B) such as\\nP(B) = >'6[B+B*]\\n\\noutput noise:\\n\\n+ (1->')6[B-B*]\\n\\n(1)\\n\\nP(B) = [~~/NrN e- tN (B-B')2/E2\\n(2)\\nThe parameters>. and ~ control the amount of teacher noise, with the noise-free teacher\\nB = B* recovered in the limits>. -t 0 and ~ -t O. The student modifies J iteratively, using\\nexamples of input vectors which are drawn at random from a fixed (randomly composed)\\nE {-I, I}N with a> 0, and the corresponding\\ntraining set containing p = aN vectors\\nvalues of the teacher outputs. We choose the teacher noise to be consistent, i.e. the answer\\nwill remain the same when that particular question\\ngiven by the teacher to a question\\nre-appears during the learning process. Thus T(e?) = sgn[BJL . e], with p teacher weight\\nvectors BJL, drawn randomly and independently from P(B), and we generalize the training\\nl , B l ), . .. , (e, BP)}. Consistency of teacher noise is natural\\nset accordingly to jj =\\nin terms of applications, and a prerequisite for overfitting phenomena. Averages over the\\ntraining set will be denoted as ( ... ) b; averages over all possible input vectors E {-I, I}N\\nas ( ... )e. We analyze two classes of learning rules, of the form J (? + 1) = J (?) + f).J (?):\\n\\nGaussian weight noise:\\n\\ne\\n\\ne\\n\\ne\\n\\nHe\\n\\ne\\n\\n= 11 {e(?) 9 [J(?)?e(?), B(?)?e(?)] - ,J(?) }\\nf).J(?) = 11 {(e 9 [J(?)?e, B?eDl> - ,J(m) }\\n\\non-line:\\n\\nf).J(?)\\n\\nbatch :\\n\\n(3)\\n\\nIn on-line learning one draws at each step ? a question/answer pair (e (?), B (?)) at random from the training set. In batch learning one iterates a deterministic map which is an\\naverage over all data in the training set. Our performance measures are the training- and\\ngeneralization errors, defined as follows (with the step function O[x > 0] = 1, O[x < 0] = 0):\\nEt(J)\\n\\n= (O[-(J ?e)(B ?em b\\n\\nEg(J)\\n\\n= (O[-(J ?e)(B* ?e)])e\\n\\n(4)\\n\\nWe introduce macroscopic observables, taylored to the present problem, generalizing [5, 6]:\\nQ[J]=J 2,\\nR[J]=J?B*,\\nP[x,y,z;J]=(6[x-J?e]6[y-B*?e]6[z-B?eDl> (5)\\nAs in [5, 6] we eliminate technical subtleties by assuming the number of arguments (x, y, z)\\nfor which P[x, y, z; J] is evaluated to go to infinity after the limit N -t 00 has been taken.\\n\\n3 Derivation of Macroscopic Laws\\nUpon generalizing the calculations in [6, 5], one finds for on-line learning:\\n\\n!\\n!\\n\\nQ = 2'f} !dXdydZ P[x, y, z] xg[x, z] - 2'f},Q + 'f}2!dXdYdZ P[x, y, z] g2[x, z]\\n\\n(6)\\n\\nR = 'f} !dXdydZ P[x, y, z] y9[x, z]- 'f},R\\n\\n(7)\\n\\n:t\\n\\nP[x, y, z] =\\n\\n~\\n\\n!\\n\\ndx' P[x', y, z] {6[x-x' -'f}G[x', z]] -6[x-x']}\\n\\n-'f}! / dx'dy'dz' / dx'dy'dz'9[x', z]A[x, y, z; x',y', z']\\n\\n1\\n+'i'f}2\\n\\n!\\n\\n+ 'f}, :x\\n\\nEP2P[x, y, z]\\ndx'dy'dz' P[x', y', z']92[x', z'] 8x\\n\\n{xP[x , y, z]}\\n\\n(8)\\n\\n\\fSupervised Learning with Restricted Training Sets\\n\\n239\\n\\nThe complexity of the problem is concentrated in a Green's function:\\nA[x, y, Zj x', y', z'] = lim\\nN-+oo\\n\\n(( ([1-6ee , ]6[x-J?e]6[y-B*?e]6[z-B?e] (e?e')6[x' -J?e']6[y' - B*?e']6[y' - B?e'])i?i> )QW;t\\n\\nJ\\n\\nIt involves a conditional average of the form (K[J])QW;t = dJ Pt(JIQ,R,P)K[J], with\\nPt(J) 6[Q-Q[J]]6[R- R[J]] nXYZ 6[P[x, y, z] -P[x, y, Zj J]]\\nPt(JIQ,R,P)\\nJdJ Pt(J) 6[Q - Q[J]]6[R- R[J]] nXYZ 6[P[x, y, z] - P[x, y, z; J]]\\n\\n=\\n\\nin which Pt (J) is the weight probability density at time t. The solution of (6,7,8) can be\\nused to generate the N -+ 00 performance measures (4) at any time:\\nEt\\n\\n=/\\n\\ndxdydz P[x, y, z]O[-xz]\\n\\nEg\\n\\n= 11\\\"-1 arccos[RIVQ]\\n\\n(9)\\n\\nExpansion of these equations in powers of\\\"\\\" and retaining only the terms linear in \\\"\\\" gives\\nthe corresponding equations describing batch learning. So far this analysis is exact.\\n\\n4\\n\\nClosure of Macroscopic Laws\\n\\nAs in [6, 5] we close our macroscopic laws (6,7,8) by making the two key assumptions\\nunderlying dynamical replica theory:\\n(i) For N -+ 00 our macroscopic observables obey closed dynamic equations.\\n(ii) These equations are self-averaging with respect to the specific realization of D.\\n\\n(i) implies that probability variations within {Q, R, P} subshells are either absent or irrelevant to the macroscopic laws. We may thus make the simplest choice for Pt (J IQ, R, P):\\nPt(JIQ,R,P) -+ 6[Q-Q[J]] 6[R-R[J]]\\n\\nII 6[P[x,y,z]-P[x,y,ZjJ]]\\n\\n(10)\\n\\nxyz\\n\\nThe procedure (10) leads to exact laws if our observables {Q, R, P} indeed obey closed\\nequations for N -+ 00. It is a maximum entropy approximation if not. (ii) allows us\\nto average the macroscopic laws over all training sets; it is observed in simulations, and\\nproven using the formalism of [4]. Our assumptions (10) result in the closure of (6,7,8),\\nsince now the Green's function can be written in terms of {Q, R, Pl. The final ingredient\\nof dynamical replica theory is doing the average of fractions with the replica identity\\n\\n/ JdJ W[JID]GIJID])\\n\\n\\\\\\n\\nJdJ W[JID]\\n\\n= lim\\nsets\\n\\n/dJ I\\n\\n???\\n\\ndJn (G[J 1 ID]\\n\\nn-+O\\n\\nIT\\n\\nW[JO<ID])sets\\n\\na=1\\n\\nOur problem has been reduced to calculating (non-trivial) integrals and averages. One\\nfinds that P[x, y, z] P[x, zly]P[y] with Ply] (211\\\")-!exp[-!y 21With the short-hands\\nDy = P[y]dy and (f(x, y, z)) = Dydxdz P[x, zly]f(x, y, z) we can write the resulting\\nmacroscopic laws, for the case of output noise (1), in the following compact way:\\n\\n=\\n\\nd\\n\\ndt Q = 2\\\",(V - ,Q)\\n\\n[)\\n\\n[)tP[x,zly] =\\n\\n=\\n\\nJ\\n\\n+ rJ2 Z\\n\\nd\\n\\ndtR = \\\",(W - ,R)\\n\\n(11)\\n\\n1 [)x[)22P[x,zIY]\\na1/dx'P[x',zly] {6[x-x'-\\\",G[x',z]]-6[x-x'] }+2\\\",2Z\\n\\n-\\\",:x {P[x,zly]\\n\\n[U(x-RY)+Wy-,x+[V-RW-(Q-R2)U]~[x,y,z])}\\n\\n(12)\\n\\nwith\\n\\nU = (~[x, y, z]9[x, z]),\\n\\nv = (x9[x, z]),\\n\\nW = (y9[x, z]),\\n\\nZ = (9 2[x, z])\\n\\nThe solution of (12) is at any time of the following form:\\n\\nP[x,zly]\\n\\n= (1-,x)6[y-z]P+[xly] + ,x6[y+z]P-[xly]\\n\\n(13)\\n\\n\\fA. C. C. Coolen and C. W. H. Mace\\n\\n240\\n\\nFinding the function <I> [x, y, z] (in replica symmetric ansatz) requires solving a saddle-point\\nproblem for a scalar observable q and two functions M?[xly]. Upon introducing\\n\\nB = . . :. V. .,. .q.,-Q___R,-2\\nQ(I-q)\\n(with Jdx M?[xly]\\n\\nJdx M?[xly]eBxs J[x, y]\\nJdx M?[xly]eBxs\\n\\n(f[x, y])? =\\n*\\n\\n= 1 for all y) the saddle-point equations acquire the fonn\\np?[Xly] =\\n\\nfor all X, y :\\n\\n((x-Ry)2) + (qQ-R 2)[I-!:.]\\na\\n\\n!\\n\\nDs (O[X -xl);\\n\\n2 !DYDS S[(I-A)(X); + A(X);]\\n= qQ+Q-2R\\n..jqQ_R2\\n\\n(14)\\n(15)\\n\\nThe equations (14) which detennine M?[xly] have the same structure as the corresponding\\n(single) equation in [5, 6], so the proofs in [5, 6] again apply, and the solutions M?[xly],\\ngiven a q in the physical range q E [R2/Q, 1], are unique. The function <I> [x, y, z] is then\\ngiven by\\n<I> [X,\\n\\ny, z]\\n\\n=!\\n\\nDs s\\n{(I-A)O[Z-y](o[X -x)); + AO[Z+Y](o[X -xl);}\\n..jqQ_R2 P[X, zly]\\n(16)\\n\\nWorking out predictions from these equations is generally CPU-intensive, mainly due to\\nthe functional saddle-point equation (14) to be solved at each time step. However, as in [7]\\none can construct useful approximations of the theory, with increasing complexity:\\n\\n(i) Large a approximation (giving the simplest theory, without saddle-point equations)\\n(ii) Conditionally Gaussian approximation for M[xly] (with y-dependent moments)\\n(iii) Annealed approximation of the functional saddle-point equation\\n\\n5 Benchmark Tests: The Limits a --+ 00 and ,\\\\ --+ 0\\nWe first show that in the limit a --+ 00 our theory reduces to the simple (Q, R) formalism\\nof infinite training sets, as worked out for noisy teachers in [12]. Upon making the ansatz\\n\\np?[xly] = P[xly] = [27r(Q-R 2)]-t e- t [x- Rv]2/(Q-R 2)\\n\\n(17)\\n\\none finds\\n\\n<I>[x,y,Z] = (x-Ry)/(Q-R 2)\\n\\nM?[xly] = P[xly],\\n\\nInsertion of our ansatz into (12), followed by rearranging of terms and usage of the above\\nexpression for <I> [x, y, z], shows that (12) is satisfied. The remaining equations (11) involve\\nonly averages over the Gaussian distribution (17), and indeed reduce to those of [12]:\\n\\n~! Q =\\n\\n(I-A) { 2(x9[x, y))\\n1 d\\n--d R\\n1} t\\n\\n+ 1}{92[x, y)) } + A {2(x9[x,-y)) + 1}(92[x,-y)) } - 2,Q\\n\\n= (I-A)(y9[x,y)) + A(y9[x,-yl) -,R\\n\\nNext we turn to the limit A --+ 0 (restricted training sets & noise-free teachers) and show that\\nhere our theory reproduces the fonnalism of [6,5]. Now we make the following ansatz:\\n\\nP+[xly] = P[xly],\\n\\nP[x, zly]\\n\\n= o[z-y]P[xIY]\\n\\n(18)\\n\\nInsertion shows that for A = 0 solutions of this fonn indeed solve our equations, giving\\n<p[x, y, z]--+ <I> [x, y] and M+[xly]\\nM[xly), and leaving us exactly with the fonnalism\\nof [6, 5] describing the case of noise-free teachers and restricted training sets (apart from\\nsome new tenns due to the presence of weight decay, which was absent in [6, 5]).\\n\\n=\\n\\n\\f241\\n\\nSupervised Learning with Restricted Training Sets\\n0. , r------~--__,\\n\\n0..4\\n\\n~-------_____I\\n\\n0..4\\n\\n11>=0.'\\n\\n0..3\\n\\na=4\\n\\n0. ,\\n\\n0..0.\\n\\n--\\n\\n, 0.\\n\\n0.2\\n\\n_ __ ___ _____ _\\n\\na= 1\\n\\n0;=1\\n\\n------- ---- -- --- -\\n\\n0.\\n\\n0;=2\\n\\n=-=\\n-\\n\\n0;=2\\n\\n- - ----- -\\n\\na=4\\na=4\\n\\n= =-=\\n--=-=--=-=--=-=-=-- -=-=-_oed\\n\\na=4\\n\\n,\\n\\n0;=2\\n\\n':::::========:::j\\n\\n0..3\\n\\n-- - ----\\n\\n0;=1\\n\\n:::---- - -----1\\n\\n0;=2\\n\\n0..2\\n\\n11>=0.'\\n\\n~-------~\\n\\n0;=1\\n\\n0.,\\n\\n11>=0,\\n\\n\\\"\\n\\n,\\n\\nno. I\\n\\n0.\\n\\n, 0.\\n\\n\\\"\\n\\nFigure 1: On-line Hebbian learning: conditionally Gaussian approximation versus exact\\nsolution in [9] (.,., = 1, ,X = 0.2). Left: \\\"I = 0.1, right: \\\"I = 0.5. Solid lines: approximated\\ntheory, dashed lines: exact result. Upper curves: Eg as functions of time (here the two\\ntheories agree), lower curves: E t as functions of time.\\n\\n6\\n\\nBenchmark Tests: Hebbian Learning\\n\\nThe special case of Hebbian learning, i.e. Q[x, z] = sgn(z), can be solved exactly at any\\ntime, for arbitrary {a, ,x, \\\"I} [9], providing yet another excellent benchmark for our theory.\\nFor batch execution of Hebbian learning the macroscopic laws are obtained upon expanding\\n(11,12) and retaining only those terms which are linear in.,.,. All integrations can now be\\ndone and all equations solved explicitly, resulting in U =0, Z = 1, W = (I-2,X)J2/7r, and\\n\\nQ\\n\\n= Qo e-2rryt +\\n\\n2Ro(I-2'x) e-17\\\"Yt[I_e-rrrt]\\n\\\"I\\n\\nf{ + [~(I-2,X)2+.!.]\\n\\nV:;\\n\\n7r\\n\\na\\n\\n[I-e- 17 \\\"Y tF\\n\\\"12\\n\\nR = Ro e- 17\\\"Y t +(I-2'x)J2/7r[I-e- 17\\\"Y t ]/\\\"I\\nq = [aR2+(I_e- 17\\\"Yt)2 i'l]/aQ\\np?[xIY] = [27r(Q-R2)] -t e-tlz-RH sgn(y)[1-e-\\\"..,t]/a\\\"Y]2/(Q-R2)\\n(19)\\nFrom these results, in tum, follow the performance measures Eg = 7r- 1 arccos[ R/ JQ) and\\n\\nE = ! - !(1-,X)!D\\n2\\n\\nt\\n\\n2\\n\\nerf[IYIR+[I-e- 77\\\"Y t ]/a\\\"l] + !,X!D erf[IYIR-[I-e- 17\\\"Y t ]/a\\\"l]\\nY\\nJ2(Q-R2)\\n2\\ny\\nJ2(Q-R2)\\n\\nComparison with the exact solution, calculated along the lines of [9] or, equivalently, obtained upon putting t ?\\nin [9], shows that the above expressions are all exact.\\n\\n.,.,-2\\n\\nFor on-line execution we cannot (yet) solve the functional saddle-point equation in general.\\nHowever, some analytical predictions can still be extracted from (11,12,13):\\n\\nQ = Qo e-217\\\"Yt + 2Ro(I-2,X) e-77\\\"Yt[I_e-17\\\"Yt]\\n\\\"I\\n\\nR = Ro e- 17\\\"Y t + (I-2,X)J2/7r[I-e- 17\\\"Y t ]/\\\"I\\n\\nJ\\n\\nf{ + [~(I-2,X)2+.!.]\\n\\nV:;\\n\\n7r\\n\\na\\n\\n[I_e- 17\\\"Y t ]2\\n\\\"12\\n\\n+ !L[I_e- 217\\\"Y t ]\\n2\\\"1\\n\\ndx xP?[xIY] = Ry ? sgn(y)[I-e- 17\\\"Y t ]/a\\\"l\\n\\nwith U =0, W = (I-2,X)J2/7r, V = W R+[I-e- 17\\\"Y t ]/a\\\"l, and Z = 1. Comparison with the\\nresults in [9] shows that the above expressions, and thus also that of E g , are all fully exact,\\nat any time. Observables involving P[x, y, z] (including the training error) are not as easily\\nsolved from our equations. Instead we used the conditionally Gaussian approximation\\n(found to be adequate for the noiseless Hebbian case [5, 6, 7]). The result is shown in\\nfigure 1. The agreement is reasonable, but significantly less than that in [6]; apparently\\nteacher noise adds to the deformation of the field distribution away from a Gaussian shape.\\n\\n\\f242\\n\\nA. C. C. Coolen and C. W H. Mac\\n\\n~\\n\\n0.6\\n\\n000000\\n\\n0.4\\n\\n0.4\\n\\nE\\n\\n~\\n\\n0.2\\n\\nI\\ni\\n0.0\\n\\n0\\n\\n4\\n\\n2\\n\\n6\\n\\n10\\n\\n0.0\\n\\n-3\\n\\n-2\\n\\n-I\\n\\n0\\nX\\n\\n0.6\\n\\nf\\n\\n0.4\\n\\n0.4 [\\n\\nE\\n0.2\\n\\n0.2\\n\\n0.0\\n\\nL-o!i6iIII.\\\"\\\"\\\"\\\"\\\"',-\\\"--~_~~_ _--'\\n\\n-3\\n\\n-2\\n\\n-I\\n\\n0\\n\\n2\\n\\n3\\n\\nX\\n\\n,=\\n\\nFigure 2: Large a approximation versus numerical simulations (with N = 10,000), for\\n0 and A = 0.2. Top row: Perceptron rule, with.,., = ~. Bottom row: Adatron rule,\\nwith.,., = ~. Left: training errors E t and generalisation errors Eg as functions of time, for\\naE {~, 1, 2}. Lines: approximated theory, markers: simulations (circles: E t , squares: Eg) .\\nRight: joint distributions for student field and teacher noise p?[x] = dy P[x, y, z = ?y]\\n(upper: P+[x], lower: P-[x]). Histograms: simulations, lines: approximated theory.\\n\\nJ\\n\\n7\\n\\nNon-Linear Learning Rules: Theory versus Simulations\\n\\nIn the case of non-linear learning rules no exact solution is known against which to test our\\nformalism, leaving numerical simulations as the yardstick. We have evaluated numerically\\nthe large a approximation of our theory for Perceptron learning, 9[x, z] = sgn(z)O[-xz],\\nand for Adatron learning, 9[x, z] = sgn(z)lzIO[-xz]. This approximation leads to the\\nfollowing fully explicit equation for the field distributions:\\n\\n1/\\n\\nd\\n-p?[xly]\\n= dt\\na\\n.\\n\\nWith\\n\\nU=\\n\\n' +1\\n\\ndx' p?[x'ly]{o[x-x'-.,.,.1'[x', ?y]] -o[x-x]}\\n\\n_ ~ {P[ I ] [W _\\n.,., 8\\nx y\\ny\\n\\nJ\\n\\nX\\n\\n~ p?[xly]\\n\\n_.,.,2 Z!:I 2\\n2\\nuX\\n\\n,X + U[X?(y)-RY]+(V-RW)[X-X?(y)]]}\\nQ _ R2\\n\\nDydx {(I-A)P+[xly][x-P(y)]9[x,Y]+AP-[xly][x-x-(y)]9[x,-y])\\nV =\\nW=\\nZ=\\n\\n!\\n1\\n1\\n\\nDydx x {(I-A)P+[xly]9[x, Y]+AP-[xly]9[x,-y])\\nDydx y {(1-A)P+[xly]9[x, Y]+AP-[xly]9[x,-y])\\n\\nDydx {(I-A)P+[xly]92[x, Y]+AP-[xly]9 2[x,-yJ)\\n\\n\\fSupervised Learning with Restricted Training Sets\\n\\n243\\n\\nJ\\n\\nand with the short-hands X?(y) = dx xP?[xly). The result of our comparison is shown\\nin figure 2. Note: E t increases monotonically with a, and Eg decreases monotonically\\nwith a, at any t. As in the noise-free formalism [7], the large a approximation appears to\\ncapture the dominant terms both for a -7 00 and for a -7 O. The predicting power of our\\ntheory is mainly limited by numerical constraints. For instance, the Adatron learning rule\\ngenerates singularities at x = 0 in the distributions P?[xly) (especially for small \\\"I) which,\\nalthough predicted by our theory, are almost impossible to capture in numerical solutions.\\n\\n8 Discussion\\nWe have shown how a recent theory to describe the dynamics of supervised learning with\\nrestricted training sets (designed to apply in the data recycling regime, and for arbitrary online and batch learning rules) [5, 6, 7] in large layered neural networks can be generalized\\nsuccessfully in order to deal also with noisy teachers. In our generalized approach the joint\\ndistribution P[x, y, z) for the fields of student, 'clean' teacher, and noisy teacher is taken to\\nbe a dynamical order parameter, in addition to the conventional observables Q and R. From\\nthe order parameter set {Q, R, P} we derive the generalization error Eg and the training\\nerror E t . Following the prescriptions of dynamical replica theory one finds a diffusion\\nequation for P[x, y, z], which we have evaluated by making the replica-symmetric ansatz.\\nWe have carried out several orthogonal benchmark tests of our theory: (i) for a -7 00 (no\\ndata recycling) our theory is exact, (ii) for A -7 0 (no teacher noise) our theory reduces\\nto that of [5, 6, 7], and (iii) for batch Hebbian learning our theory is exact. For on-line\\nHebbian learning our theory is exact with regard to the predictions for Q, R, Eg and the\\ny-dependent conditional averages Jdx xP?[xly), at any time, and a crude approximation\\nof our equations already gives reasonable agreement with the exact results [9] for E t . For\\nnon-linear learning rules (Perceptron and Adatron) we have compared numerical solution\\nof a simple large a aproximation of our equations to numerical simulations, and found\\nsatisfactory agreement. This paper is a preliminary presentation of results obtained in the\\nsecond stage of a research programme aimed at extending our theoretical tools in the arena\\nof learning dynamics, building on [5, 6, 7]. Ongoing work is aimed at systematic application of our theory and its approximations to various types of non-linear learning rules, and\\nat generalization of the theory to multi-layer networks.\\n\\nReferences\\n[1]\\n[2]\\n[3]\\n[4]\\n[5]\\n[6]\\n[7]\\n[8]\\n[9]\\n[10]\\n[11]\\n[12]\\n\\nMace C.W.H. and Coolen AC.C (1998), Statistics and Computing 8, 55\\nSaad D. (ed.) (1998), On-Line Learning in Neural Networks (Cambridge: CUP)\\nHertz J.A., Krogh A and Thorgersson G.I. (1989), J. Phys. A 22, 2133\\nHomerH. (1992a), Z. Phys. B 86, 291 and Homer H. (1992b), Z. Phys. B 87,371\\nCoolen A.C.C. and Saad D. (1998), in On-Line Learning in Neural Networks, Saad\\nD. (ed.), (Cambridge: CUP)\\nCoolen AC.C. and Saad D. (1999), in Advances in Neural Information Processing\\nSystems 11, Kearns D., Solla S.A., Cohn D.A (eds.), (MIT press)\\nCoolen A.C.C. and Saad D. (1999), preprints KCL-MTH-99-32 & KCL-MTH-99-33\\nRae H.C., Sollich P. and Coolen AC.C. (1999), in Advances in Neural Information\\nProcessing Systems 11, Kearns D., Solla S.A., Cohn D.A. (eds.), (MIT press)\\nRae H.C., Sollich P. and Coolen AC.C. (1999),J. Phys. A 32, 3321\\nInoue J.I. (1999) private communication\\nWong K.YM., Li S. and Tong YW. (1999),preprint cond-mat19909004\\nBiehl M., Riegler P. and Stechert M. (1995), Phys. Rev. E 52, 4624\\n\\n\\f\",\n          \"Predicting Action Content On-Line and in\\nReal Time before Action Onset ? an\\nIntracranial Human Study\\n\\nShengxuan Ye\\nCalifornia Institute of Technology\\nPasadena, CA\\nsye@caltech.edu\\n\\nUri Maoz\\nCalifornia Institute of Technology\\nPasadena, CA\\nurim@caltech.edu\\nIan Ross\\nHuntington Hospital\\nPasadena, CA\\nianrossmd@aol.com\\n\\nAdam Mamelak\\nCedars-Sinai Medical Center\\nLos Angeles, CA\\nadam.mamelak@cshs.org\\n\\nChristof Koch\\nCalifornia Institute of Technology\\nPasadena, CA\\nAllen Institute for Brain Science\\nSeattle, WA\\nkoch@klab.caltech.edu\\n\\nAbstract\\nThe ability to predict action content from neural signals in real time before the action occurs has been long sought in the neuroscientific study of decision-making,\\nagency and volition. On-line real-time (ORT) prediction is important for understanding the relation between neural correlates of decision-making and conscious,\\nvoluntary action as well as for brain-machine interfaces. Here, epilepsy patients,\\nimplanted with intracranial depth microelectrodes or subdural grid electrodes for\\nclinical purposes, participated in a ?matching-pennies? game against an opponent.\\nIn each trial, subjects were given a 5 s countdown, after which they had to raise\\ntheir left or right hand immediately as the ?go? signal appeared on a computer\\nscreen. They won a fixed amount of money if they raised a different hand than\\ntheir opponent and lost that amount otherwise. The question we here studied was\\nthe extent to which neural precursors of the subjects? decisions can be detected in\\nintracranial local field potentials (LFP) prior to the onset of the action.\\nWe found that combined low-frequency (0.1?5 Hz) LFP signals from 10 electrodes\\nwere predictive of the intended left-/right-hand movements before the onset of the\\ngo signal. Our ORT system predicted which hand the patient would raise 0.5 s\\nbefore the go signal with 68?3% accuracy in two patients. Based on these results,\\nwe constructed an ORT system that tracked up to 30 electrodes simultaneously,\\nand tested it on retrospective data from 7 patients. On average, we could predict\\nthe correct hand choice in 83% of the trials, which rose to 92% if we let the system\\ndrop 3/10 of the trials on which it was less confident. Our system demonstrates?\\nfor the first time?the feasibility of accurately predicting a binary action on single\\ntrials in real time for patients with intracranial recordings, well before the action\\noccurs.\\n\\n1\\n\\n\\f1\\n\\nIntroduction\\n\\nThe work of Benjamin Libet [1, 2] and others [3, 4] has challenged our intuitive notions of the relation between decision making and conscious voluntary action. Using electrocorticography (EEG),\\nthese experiments measured brain potentials from subjects that were instructed to flex their wrist at a\\ntime of their choice and note the position of a rotating dot on a clock when they felt the urge to move.\\nThe results suggested that a slow cortical wave measured over motor areas?termed ?readiness potential? [5], and known to precede voluntary movement [6]?begins a few hundred milliseconds before the average reported time of the subjective ?urge? to move. This suggested that action onset and\\ncontents could be decoded from preparatory motor signals in the brain before the subject becomes\\naware of an intention to move and of the contents of the action. However, the readiness potential\\nwas computed by averaging over 40 or more trials aligned to movement onset after the fact. More\\nrecently, it was shown that action contents can be decoded using functional magnetic-resonance\\nimaging (fMRI) several seconds before movement onset [7]. But, while done on a single-trial basis,\\ndecoding the neural signals took place off-line, after the experiment was concluded, as the sluggish\\nnature of fMRI hemodynamic signals precluded real-time analysis. Moreover, the above studies\\nfocused on arbitrary and meaningless action?purposelessly raising the left or right hand?while\\nwe wanted to investigate prediction of reasoned action in more realistic, everyday situations with\\nconsequences for the subject.\\nIntracranial recordings are good candidates for single-trial, ORT analysis of action onset and contents [8, 9], because of the tight temporal pairing of LFP to the underlying neuronal signals. Moreover, such recordings are known to be cleaner and more robust, with signal-to-noise ratios up to\\n100 times larger than surface recordings like EEG [10, 11]. We therefore took advantage of a rare\\nopportunity to work with epilepsy patients implanted with intracranial electrodes for clinical purposes. Our ORT system (Fig. 1) predicts, with far above chance accuracy, which one of two future\\nactions is about to occur on this one trial and feeds the prediction back to the experimenter, all\\nbefore the onset of the go signal that triggers the patient?s movement (see Experimental Methods).\\nWe achieve relatively high prediction performance using only part of the data?learning from brain\\nactivity in past trials only (Fig. 2) to predict future ones (Fig. 3)?while still running the analysis\\nquickly enough to act upon the prediction before the subject moved.\\n\\n2\\n2.1\\n\\nExperimental Methods\\nSubjects\\n\\nSubjects in this experiment were 8 consenting intractable epilepsy patients that were implanted with\\nintracranial electrodes as part of their presurgical clinical evaluation (ages 18?60, 3 males). They\\nwere inpatients in the neuro-telemetry ward at the Cedars Sinai Medical Center or the Huntington\\nMemorial Hospital, and are designated with CS or HMH after their patient numbers, respectively. Six\\nof them?P12CS, P15CS, P22CS and P29?31HMH were implanted with intracortical depth electrodes targeting their bilateral anterior-cingulate cortex, amygdala, hippocampus and orbitofrontal\\ncortex. These electrodes had eight 40 ?m microwires at their tips, 7 for recording and 1 serving as\\na local ground. Two patients, P15CS and P22CS, had additional microwires in the supplementary\\nmotor area. We utilized the LFP recorded from the microwires in this study. Two other patients,\\nP16CS and P19CS, were implanted with an 8?8 subdural grid (64 electrodes) over parts of their\\ntemporal and prefrontal dorsolateral cortices. The data of one patient?P31HMH?was excluded\\nbecause microwire signals were too noisy for meaningful analysis. The institutional review boards\\nof Cedars Sinai Medical Center, the Huntington Memorial Hospital and the California Institute of\\nTechnology approved the experiments.\\nDuring the experiment, the subject sat in a hospital bed in a semi-inclined ?lounge chair? position.\\nThe stimulus/analysis computer (bottom left of Fig. 4) displaying the game screen (bottom right\\ninset of Fig. 4) was positioned to be easily viewable for the subject. When playing against the\\nexperimenter, the latter sat beside the bed. The response box was placed within easy reach of the\\nsubject (Fig. 4).\\n2\\n\\n\\f2.2\\n\\nExperiment Design\\n\\nAs part of our focus on purposeful, reasoned action, we had the subjects play a matching-pennies\\ngame?a 2-choice version of ?rock paper scissors??either against the experimenter or against a\\ncomputer. The subjects pressed down a button with their left hand and another with their right on a\\nresponse box. Then, in each trial, there was a 5 s countdown followed by a go signal, after which\\nthey had to immediately lift one of their hands. It was agreed beforehand that the patient would win\\nthe trial if she lifted a different hand than her opponent, and lose if she raised the same hand as her\\nopponent. Both players started off with a fixed amount of money, $5, and in each trial $0.10 was\\ndeducted from the loser and awarded to the winner. If a player lifted her hand before the go signal,\\ndid not lift her hand within 500 ms of the go signal, or lifted no hand or both hands at the go signal?\\nan error trial?she lost $0.10 without her opponent gaining any money. The subjects were shown the\\ncountdown, the go signal, the overall score, and various instructions on a stimulus computer placed\\nbefore them (Fig. 4). Each game consisted of 50 trials. If, at the end of the game, the subject had\\nmore money than her opponent, she received that money in cash from the experimenter.\\nBefore the experimental session began, the experimenter explained the rules of the game to the subject, and she could practice playing the game until she was familiar with it. Consequently, patients\\nusually made only few errors during the games (<6% of the trials). Following the tutorial, the subject played 1?3 games against the computer and then once against the experimenter, depending on\\ntheir availability and clinical circumstances. The first 2 games of P12CS were removed because\\nthe subject tended to constantly raise the right hand regardless of winning or losing. Two patients,\\nP15CS and P19CS, were tested in actual ORT conditions. In such sessions?3 games each?the\\nsubjects always played against the experimenter. These ORT games were different from the other\\ngames in two respects. First, a computer screen was placed behind the patient, in a location where\\nshe could not see it. Second, the experimenter was wearing earphones (Fig. 1,4). Half a second before go-signal onset, an arrow pointing towards the hand that the system predicted the experimenter\\nhad to raise to win the trial was displayed on that screen. Simultaneously, a monophonic tone was\\nplayed in the experimenter?s earphone ipsilateral to that hand. The experimenter then lifted that hand\\nat the go signal (see Supplemental Movie).\\n\\nCheetah Machine\\nCollect\\nand save\\ndata\\n\\nPatient\\nwith intracranial electrodes\\n\\nDown\\nsampling\\n\\nBuffer\\n\\n1Gbps\\nRouter\\n\\nTTL Signal\\n\\nThe winner is\\nPlayer 1\\nPLAYER 1 PLAYER 2\\nSCORE 1\\n\\nAnalysis/stimulus machine\\n\\nSCORE 2\\n\\nResponse Box Game Screen\\n\\n/\\nExperimenter\\n\\nResult\\nInterpreta\\ntion\\n\\nAnalysis\\n\\nFiltering\\n\\nDisplay/Sound\\n\\nFigure 1: A schematic diagram of the on-line real-time (ORT) system. Neural signals flow from\\nthe patient through the Cheetah machine to the analysis/stimulus computer, which controls the input\\nand output of the game and computes the prediction of the hand the patient would raise at the go\\nsignal. It displays it on a screen behind the patient and informs the experimenter which hand to raise\\nby playing a tone in his ipsilateral ear using earphones.\\n\\n3\\n\\n\\f3\\n3.1\\n\\nThe real-time system\\nHardware and software overview\\n\\n?V\\n\\n?V\\n\\n?V\\n\\nNeural data from the intracranial electrodes were transferred to a recording system (Neuralynx,\\nDigital Lynx), where it was collected and saved to the local Cheetah machine, down sampled\\nfrom 32 kHz to 2 kHz and buffered. The data were then transferred, through a dedicated 1 Gbps\\nlocal-area network, to the analysis/stimulus machine. This computer first band-pass-filtered the\\ndata to the 0.1?5 Hz range (delta and lower theta bands) using a second-order zero-lag elliptic\\nfilter with an attenuation of 40 dB (cf. Figs. 2a and 2b). We found that this frequency range?\\ngenerally comparable to that of the readiness potential?resulted in optimal prediction performance.\\nIt then ran the analysis algorithm (see below) on the filtered data. This computer also controlled\\nthe game screen, displaying the names of the players, their current scores and various instructions.\\nThe analysis/stimulus computer further\\ncontrolled the response box, which con- (a)\\n800\\nsisted of 4 LED-lit buttons. The buttons of the subject and her opponent\\n600\\nflashed red or blue whenever she or her\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nopponent won, respectively. Addition(b)100\\nally, the analysis/stimulus computer sent\\n0\\na unique transistor-transistor logic (TTL)\\n?100\\n?200\\npulse whenever the game screen changed\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nor a button was pressed on the response\\nbox, which synchronized the timing of (c) 100\\n0\\nthese events with the LFP recordings.\\n?100\\nIn real-time game sessions, the analy?200\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nsis/stimulus computer also displayed the\\nappropriate arrow on the computer screen (d) 1\\nbehind the subject and played the tone\\n0\\nto the appropriate ear of the experimenter\\n?1\\n0.5 s before go-signal onset (Figs. 1,4).\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nThe analysis software was based on a\\nmachine-learning algorithm that trained\\non past-trials data to predict the current\\ntrial and is detailed below. The training phase included the first 70% of the\\ntrials, with the prediction carried out on\\nthe remaining 30% using the trained parameters, together with an online weighting system (see below). The system examined only neural activity, and had no\\naccess to the subject?s left/right-choice\\nhistory. After filtering all the training\\ntrials (Fig. 2b), the system found the\\nmean and standard error over all leftward\\nand rightward training trials, separately\\n(Fig. 2c, left designated in red). It then\\nfound the electrodes and time windows\\nwhere the left/right separation was high\\n(Fig. 2d,e; see below), and trained the classifiers on these time windows (Fig. 2f?g).\\nThe best electrode/time-window/classifier\\n(ETC) combinations were then used to\\npredict the current trial in the prediction\\nphase (Fig. 3). The number of ETCs that\\ncan be actively monitored is currently limited to 10 due to the computational power\\nof the real-time system.\\n\\nEl 49?T1\\n\\n(e)\\n\\nEl 49?T2\\n\\nEl 49?T3\\n\\n1\\n0\\n?1\\n?5\\n\\n?4\\n\\n?3\\n?2\\n?1\\nCountdown to go signal at t=0 (seconds)\\n\\n0\\n\\n(f)\\nClassifier\\nCf1\\n\\nClassifier\\nCf2\\n\\n...\\n\\nClassifier\\nCf6\\n\\nEl 49?T1?Cf1\\nEl 49?T1?Cf2\\nEl 49?T1?Cf6\\n...\\nEl 49?T2?Cf1\\nEl 49?T2?Cf2\\nEl 49?T2?Cf6\\nEl 49?T3?Cf1\\nEl 49?T3?Cf2\\nEl 49?T3?Cf6\\n\\n(g)\\nCombination\\nEl49-T1-Cf2\\n\\nCombination\\nEl49-T2-Cf2\\n\\n...\\n\\nCombination\\nEl49-T2-Cf6\\n\\nFigure 2: The ORT-system?s training phase. Left (in\\nred) and right (in blue) raw signals (a) are low-pass filtered (b). Mean?standard errors of signals preceeding left- and right-hand movments (c) are used to compute a left/right separability index (d), from which time\\nwindows with good separation are found (e). Seven\\nclassifiers are then applied to all the time windows (f)\\nand the best electrode/time-window/classifier combinations are selected (g) and used in the prediction phase\\n(Fig. 3).\\n\\n4\\n\\n\\f?V\\n\\n100\\n0\\n?100\\n?200\\n?5\\n\\n?4\\n\\n?3\\n\\n?2\\n\\n?1\\n\\n0\\n\\nTrained classifiers\\n\\nCombination\\nE l 49?T1?Cf2\\n\\nCombination\\nE l 49?T2?Cf2\\n\\nWeight = 1\\n\\nWeight = 1\\n\\nCombination\\nE l 49?T2?Cf6\\n\\n&\\n\\nWeight = 1\\n\\nPredicted result\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nR\\n\\nL\\n\\n&\\n\\nR\\n\\nL\\nReal result\\n\\nAdjust the weights\\n\\nL\\n\\n==\\n\\nFigure 3: The ORT-system?s prediction phase. A new signal?from 5 to 0.5 seconds before the\\ngo signal?is received in real time, and each electrode/time-window/classifier combination (ETC)\\nclassifies it as resulting in left- or right-hand movement. These predictions are then compared to the\\nactual hand movement, with the weights associated with ETCs that correctly (incorrectly) predicted\\nincreasing (decreasing).\\n\\n3.2\\n\\nComputing optimal left/right-separating time windows\\n\\nThe algorithm focused on finding the time windows with the best left/right separation for the different recording electrodes over the training set (Fig. 2c?e). That is, we wanted to predict whether\\nthe signal aN (t) on trial N will result in a leftward or rightward movement?i.e., whether the label of the N th trial will be Lt or Rt, respectively. For each electrode, we looked at the N ? 1\\nprevious trials a1 (t), a2 (t), . . . , aN ?1 (t), and their associated labels as l1 , l2 , . . . , lN ?1 . Now, let\\nN ?1\\n?1\\nL(t) = {ai (t) | li = Lt}N\\ni=1 and R(t) = {ai (t) | li = Rt}i=1 be the set of previous leftward and\\nrightward trials in the training set, respectively. Furthermore, let Lm (t) (Rm (t)) and Ls (t) (Rs (t))\\nbe the mean and standard error of L(t) (R(t)), respectively. We can now define the normalized\\nrelative left/right separation for each electrode at time t (see Fig. 2d):\\n?\\n[Lm (t) ? Ls (t)] ? [Rm (t) + Rs (t)]\\n?\\n?\\nif [Lm (t) ? Ls (t)] ? [Rm (t) + Rs (t)] > 0\\n?\\n?\\nLm (t) ? Rm (t)\\n?\\n?\\n?\\n?\\n?\\n[Rm (t) ? Rs (t)] ? [Lm (t) + Ls (t)]\\n?(t) =\\n?\\nif [Rm (t) ? Rs (t)] ? [Lm (t) + Ls (t)] > 0\\n?\\n?\\n?\\nRm (t) ? Lm (t)\\n?\\n?\\n?\\n?\\n?\\n?\\n0\\notherwise\\nThus, ?(t) > 0 (?(t) < 0) means that the leftward trials tend to be considerably higher (lower)\\nthan rightward trials for that electrode at time t, while ?(t) = 0 suggests no left/right separation at\\ntime t. We define a consecutive time period of |?(t)| > 0 for t < prediction time (the time before\\nthe go signal when we want the system to output a prediction; -0.5 s for the ORT trials) as a time\\nwindow (Fig. 2e). After all time windows are found for all electrodes, time windows lessRthan M ms\\nt\\napart are combined into one. Then, for each time window from t1 to t2 we define a = t12 |?(t)|dt.\\nWe then eliminate all time windows satisfying a < A. We found the values M = 200 ms and\\nA = 4, 500 ?V ? ms to be optimal for real-time analysis. This resulted in 20?30 time windows over\\nall 64 electrodes that we monitored.\\n5\\n\\n\\f1\\n$4.80\\n\\n$5.20\\n\\nP15CS\\n\\nUri\\n\\nFigure 4: The experimental setup in the clinic. At 400 ms before the go signal, the patient and\\nexperimenter are watching the game screen (inset on bottom right) on the analysis/stimulus computer\\n(bottom left) and still pressing down the buttons of the response box. The realtime system already\\ncomputed a prediction, and thus displays an arrow on the screen behind the patient and plays a tone\\nin the experimenter?s ear ipsilateral to the hand it predicts he should raise to beat the patient (see\\nSupplemental Movie).\\n3.3\\n\\nClassifiers selection and ETC determination\\n\\nWe used ensemble learning with 7 types of relatively simple binary classifiers (due to real-time\\nprocessing considerations) on every electrode?s time windows (Fig. 2f). Classifiers A to G would\\nclassify aN (t) as Lt if:\\nP\\nP\\nP\\n(A) Defining aN,M , Lm,M and Rm,M as aN (t), Lm (t) and Rm (t) over time window M ,\\n\\u0001\\n\\u0001\\n\\u0001\\n(i) sign Rm,M 6= sign aN,M = sign Lm,M , or\\n\\f\\n\\f\\n\\f \\f\\n\\u0001\\n\\u0001\\n\\u0001\\n(ii) sign Rm,M = sign aN,M = sign Lm,M and \\fLm,M \\f > \\fRm,M \\f, or\\n\\f\\n\\f\\n\\f \\f\\n\\u0001\\n\\u0001\\n\\u0001\\n(iii) sign Rm (t) 6= sign SN,M 6= sign Lm (t) and \\fLm,M \\f < \\fRm,M \\f;\\n\\f\\n\\u0001\\n\\u0001\\f \\f\\n\\u0001\\n\\u0001\\f\\n(B) \\fmean aN (t) ? mean Lm (t) \\f < \\fmean aN (t) ? mean Rm (t) \\f;\\n\\f\\n\\f\\n\\u0001\\n\\u0001\\f\\n\\u0001\\n\\u0001\\f\\n(C) \\fmedian aN (t) ? median Lm (t) \\f < \\fmedian aN (t) ? median Rm (t) \\f over the time\\nwindow;\\n\\f\\n\\f\\n\\f\\n\\f\\n\\f\\n(D) aN (t) ? Lm (t)\\fL2 < \\faN (t) ? Rm (t)\\fL2 over the time window;\\n(E) aN (t) is convex/concave like Lm (t) while Rm (t) is concave/convex, respectively;\\n(F) Linear support-vector machine (SVM) designates it as so; and\\n(G) k-nearest neighbors (KNN) with Euclidean distance designates it as so.\\nEach classifier is optimized for certain types of features. To estimate how well its classification\\nwould generalize from the training to the test set, we trained and tested it using a 70/30 crossvalidation procedure within the training set. We tested each classifier on every time window of every\\nelectrode, discarding those with accuracy <0.68, which left 12.0 ? 1.6% of the original 232 ? 18\\nETCs, on average (?standard error). The training phase therefore ultimately output a set of S binary\\nETC combinations (Fig. 2g) that were used in the prediction phase (Fig. 3).\\n3.4\\n\\nThe prediction-phase weighting system\\n\\nIn the prediction phase, each of the overall S binary ETCs calculates a prediction, ci ? {?1, 1} (for\\nright and left, respectively), independently at the desired prediction time. All classifiers are initially\\n6\\n\\n\\fPS\\ngiven the same weight, w1 = w2 = ? ? ? = wS = 1. We then calculate ? = i=1 wi ? ci and predict\\nleft (right) if ? > d (? < ?d), or declare it an undetermined trial if ?d < ? < d. Here d is the\\ndrop-off threshold for the prediction. Thus the larger d is, the more confident the system needs to be\\nto make a prediction, and the larger the proportion of trials on which the system abstains?the dropoff rate. Weight wi associated with ETCi is increased (decreased) by 0.1 whenever ETCi predicts\\nthe hand movement correctly (incorrectly). A constantly erring ETC would therefore be associated\\nwith an increasingly small and then increasingly negative weight.\\n3.5\\n\\nImplementation\\n\\nThe algorithm was implemented in MATLAB 2011a (MathWorks, Natick, MA) as well as in C++\\non Visual Studio 2008 (Microsoft, Redmond, WA) for enhanced performance. The neural signals\\nwere collected by the Digital Lynx S system using Cheetah 5.4.0 (Neuralynx, Redmond, WA). The\\nsimulated-ORT system was also implemented in MATLAB 2011a. The simulated-ORT analyses\\ncarried out in this paper used real patient data saved on the Digital Lynx system.\\n1\\n\\n0.9\\n\\nDrop rate:\\nNone\\n0.18\\n0\\u0011\\u0016\\u0013\\n\\nPrediction accuracy\\n\\n0.8\\n\\n0.7\\nSignificant accuracy\\n(p=0.05)\\n0.6\\n\\n0.5\\n\\n?5\\n\\n?4.5\\n\\n?4\\n\\n?3.5\\n\\n?3\\n\\n?2.5\\nTime (s)\\n\\n?2\\n\\n?1.5\\n\\n?1\\n\\n?0.5\\n\\n0\\nGo-signal\\nonset\\n\\nFigure 5: Across-subjects average of the prediction accuracy of simulated-ORT versus time before\\nthe go signal. The mean accuracies over time when the system predicts on every trial, is allowed\\nto drop 19% or 30% of the trials, are depicted in blue, green and red, respectively (?standard error\\nshaded). Values above the dashed horizontal line are significant at p = 0.05.\\n\\n4\\n\\nResults\\n\\nWe tested our prediction system in actual real time on 2 patients?P15CS and P19CS (a depth\\nand grid patient, respectively), with a prediction time of 0.5 s before the go signal (see Supplementary Movie). Because of computational limitations, the ORT system could only track 10\\nelectrodes with just 1 ETC per electrode in real time. For P15CS, we achieved an accuracy of\\n72?2% (?standard error; accuracy = number of accurately predicted trials / [total number of trials - number of dropped trials]; p = 10?8 , binomial test) without modifying the weights online during the prediction (see Section 3.4). For P19CS we did not run patient-specific training of the ORT system, and used parameter values that were good on average over previous patients instead. The prediction accuracy was significantly above chance 63?2% (?standard error; p = 7 ? 10?4 , binomial test). To understand how much we could improve our accuracy\\nwith optimized hardware/software, we ran the simulated-ORT at various prediction times along\\n7\\n\\n\\fAccuracy\\n\\nthe 5 s countdown leading to the go signal. We further tested 3 drop-off rates?0, 0.19 and\\n0.30 (Fig. 5; drop-off rate = number of dropped trials / total number of trials; these resulted\\nfrom 3 drop-off thresholds?0, 0.1 and 0.2?respectively, see Section 3.4:). Running offline,\\nwe were able to track 20?30 ETCs, which resulted in considerably higher accuracies (Figs. 5,6).\\nAveraged over all subjects, the accuracy rose from about 65% more than\\n1\\n4 s before the go signal to 83?92%\\nclose to go-signal onset, depending\\n0.9\\non the allowed drop-off rate. In particular, we found that for a predic0.8\\ntion time of 0.5 s before go-signal\\nonset, we could achieve accuracies\\n0.7\\nof 81?5% and 90?3% (?standard\\nerror) for P15CS and P19CS, re0.6\\nspectively, with no drop off (Fig. 6).\\nPatients:\\nP12CS\\nWe also analyzed the weights that\\nP15CS\\nour weighting system assigned to the\\n0.5\\nP16CS\\nP19CS\\ndifferent ETCs. We found that the\\nP22CS\\nempirical distribution of weights to\\nP29HMH\\n0.4\\nP30HMH\\nETCs associated with classifiers A to\\nG was, on average: 0.15, 0.12, 0.16,\\n?5 ?4.5 ?4 ?3.5 ?3 ?2.5 ?2 ?1.5 ?1 ?0.5 0\\n0.22, 0.01, 0.26 and 0.07, respecTime before go signal (at t=0) (seconds)\\ntively. This suggests that the linear\\nSVM and L2-norm comparisons (of\\naN to Lm and Rm ) together make up Figure 6: Simulated-ORT accuracy over time for individual\\nnearly half of the overall weights at- patients with no drop off.\\ntributed to the classifiers, while the\\ncurrent concave/convex measure is of\\nlittle use as a classifier.\\n\\n5\\n\\nDiscussion\\n\\nWe constructed an ORT system that, based on intracranial recordings, predicted which hand a person would raise well before movement onset at accuracies much greater than chance in a competitive environment. We further tested this system off-line, which suggested that with optimized\\nhardware/software, such action contents would be predictable in real time at relatively high accuracies already several seconds before movement onset. Both our prediction accuracy and drop-off\\nrates close to movement onset are superior to those achieved before movement onset with noninvasive methods like EEG and fMRI [7, 12?14]. Importantly, our subjects played a matching pennies game?a 2-choice version of rock-paper-scissors [15]?to keep their task realistic, with minor\\nthough real consequences, unlike the Libet-type paradigms whose outcome bears no consequences\\nfor the subjects. It was suggested that accurate online, real-time prediction before movement onset\\nis key to investigating the relation between the neural correlates of decisions, their awareness, and\\nvoluntary action [16, 17]. Such prediction capabilities would facilitate many types of experiments\\nthat are currently infeasible. For example, it would make it possible to study decision reversals on\\na single-trial basis, or to test whether subjects can guess above chance which of their action contents are predictable from their current brain activity, potentially before having consciously made up\\ntheir mind [16, 18]. Accurately decoding these preparatory motor signals may also result in earlier\\nand improved classification for brain-computer interfaces [13, 19, 20]. The work we present here\\nsuggests that such ORT analysis might well be possible.\\nAcknowledgements\\nWe thank Ueli Rutishauser, Regan Blythe Towel, Liad Mudrik and Ralph Adolphs for meaningful\\ndiscussions. This research was supported by the Ralph Schlaeger Charitable Foundation, Florida\\nState University?s ?Big Questions in Free Will? initiative and the G. Harold & Leila Y. Mathers\\nCharitable Foundation.\\n8\\n\\n\\fReferences\\n[1] B. Libet, C. Gleason, E. Wright, and D. Pearl. Time of conscious intention to act in relation to\\nonset of cerebral activity (readiness-potential): The unconscious initiation of a freely voluntary\\nact. Brain, 106:623, 1983.\\n[2] B. Libet. Unconscious cerebral initiative and the role of conscious will in voluntary action.\\nBehavioral and brain sciences, 8:529?539, 1985.\\n[3] P. Haggard and M. Eimer. On the relation between brain potentials and the awareness of\\nvoluntary movements. Experimental Brain Research, 126:128?133, 1999.\\n[4] A. Sirigu, E. Daprati, S. Ciancia, P. Giraux, N. Nighoghossian, A. Posada, and P. Haggard.\\nAltered awareness of voluntary action after damage to the parietal cortex. Nature Neuroscience,\\n7:80?84, 2003.\\n[5] H. Kornhuber and L. Deecke. Hirnpotenti?alanderungen bei Willk?urbewegungen und passiven\\nBewegungen des Menschen: Bereitschaftspotential und reafferente Potentiale. Pfl?ugers Archiv\\nEuropean Journal of Physiology, 284:1?17, 1965.\\n[6] H. Shibasaki and M. Hallett. What is the Bereitschaftspotential? Clinical Neurophysiology,\\n117:2341?2356, 2006.\\n[7] C. Soon, M. Brass, H. Heinze, and J. Haynes. Unconscious determinants of free decisions in\\nthe human brain. Nature Neuroscience, 11:543?545, 2008.\\n[8] I. Fried, R. Mukamel, and G. Kreiman. Internally generated preactivation of single neurons in\\nhuman medial frontal cortex predicts volition. Neuron, 69:548?562, 2011.\\n[9] M. Cerf, N. Thiruvengadam, F. Mormann, A. Kraskov, R. Quian Quiorga, C. Koch, and\\nI. Fried. On-line, voluntary control of human temporal lobe neurons. Nature, 467:1104?1108,\\n2010.\\n[10] T. Ball, M. Kern, I. Mutschler, A. Aertsen, and A. Schulze-Bonhage. Signal quality of simultaneously recorded invasive and non-invasive EEG. Neuroimage, 46:708?716, 2009.\\n[11] G. Schalk, J. Kubanek, K. Miller, N. Anderson, E. Leuthardt, J. Ojemann, D. Limbrick,\\nD. Moran, L. Gerhardt, and J. Wolpaw. Decoding two-dimensional movement trajectories\\nusing electrocorticographic signals in humans. Journal of Neural engineering, 4:264, 2007.\\n[12] O. Bai, V. Rathi, P. Lin, D. Huang, H. Battapady, D. Y. Fei, L. Schneider, E. Houdayer, X. Chen,\\nand M. Hallett. Prediction of human voluntary movement before it occurs. Clinical Neurophysiology, 122:364?372, 2011.\\n[13] O. Bai, P. Lin, S. Vorbach, J. Li, S. Furlani, and M. Hallett. Exploration of computational\\nmethods for classification of movement intention during human voluntary movement from\\nsingle trial EEG. Clinical Neurophysiology, 118:2637?2655, 2007.\\n[14] U. Maoz, A. Arieli, S. Ullman, and C. Koch. Using single-trial EEG data to predict laterality\\nof voluntary motor decisions. Society for Neuroscience, 38:289.6, 2008.\\n[15] C. Camerer. Behavioral game theory: Experiments in strategic interaction. Princeton University Press, 2003.\\n[16] J. D. Haynes. Decoding and predicting intentions. Annals of the New York Academy of Sciences, 1224:9?21, 2011.\\n[17] P. Haggard. Decision time for free will. Neuron, 69:404?406, 2011.\\n[18] J. D. Haynes. Beyond libet. In W. Sinnott-Armstrong and L. Nadel, editors, Conscious will\\nand responsibility, pages 85?96. Oxford University Press, 2011.\\n[19] A. Muralidharan, J. Chae, and D. M. Taylor. Extracting attempted hand movements from EEGs\\nin people with complete hand paralysis following stroke. Frontiers in neuroscience, 5, 2011.\\n[20] E. Lew, R. Chavarriaga, S. Silvoni, and J. R. Milln. Detection of self-paced reaching movement\\nintention from EEG signals. Frontiers in Neuroengineering, 5:13, 2012.\\n\\n9\\n\\n\\f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id  year                                              title event_type  \\\n",
              "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
              "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
              "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
              "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
              "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
              "\n",
              "                                            pdf_name          abstract  \\\n",
              "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
              "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
              "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
              "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
              "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
              "\n",
              "                                          paper_text  \n",
              "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
              "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
              "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
              "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
              "4  Neural Network Ensembles, Cross\\nValidation, a...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87b48a61-9fce-4ff8-925d-3b143d194004\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>event_type</th>\n",
              "      <th>pdf_name</th>\n",
              "      <th>abstract</th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1987</td>\n",
              "      <td>Self-Organization of Associative Database and ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1-self-organization-of-associative-database-an...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>1987</td>\n",
              "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100</td>\n",
              "      <td>1988</td>\n",
              "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000</td>\n",
              "      <td>1994</td>\n",
              "      <td>Bayesian Query Construction for Neural Network...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1001</td>\n",
              "      <td>1994</td>\n",
              "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
              "      <td>Abstract Missing</td>\n",
              "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87b48a61-9fce-4ff8-925d-3b143d194004')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-87b48a61-9fce-4ff8-925d-3b143d194004 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-87b48a61-9fce-4ff8-925d-3b143d194004');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d03f5ae6-1a04-4981-bcd3-30e8dd2241c4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d03f5ae6-1a04-4981-bcd3-30e8dd2241c4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d03f5ae6-1a04-4981-bcd3-30e8dd2241c4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "papers",
              "summary": "{\n  \"name\": \"papers\",\n  \"rows\": 6560,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1901,\n        \"min\": 1,\n        \"max\": 6603,\n        \"num_unique_values\": 6560,\n        \"samples\": [\n          3087,\n          78,\n          5412\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1987,\n        \"max\": 2016,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          1992,\n          1990,\n          2012\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6560,\n        \"samples\": [\n          \"Natural Actor-Critic for Road Traffic Optimisation\",\n          \"Learning Representations by Recirculation\",\n          \"Quantized Kernel Learning for Feature Matching\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"event_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Oral\",\n          \"Spotlight\",\n          \"Poster\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pdf_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6560,\n        \"samples\": [\n          \"3087-natural-actor-critic-for-road-traffic-optimisation.pdf\",\n          \"78-learning-representations-by-recirculation.pdf\",\n          \"5412-quantized-kernel-learning-for-feature-matching.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3244,\n        \"samples\": [\n          \"Tensor CANDECOMP/PARAFAC (CP) decomposition has wide applications in statistical learning of latent variable models and in data mining. In this paper, we propose fast and randomized tensor CP decomposition algorithms based on sketching. We build on the idea of count sketches, but introduce many novel ideas which are unique to tensors. We develop novel methods for randomized com- putation of tensor contractions via FFTs, without explicitly forming the tensors. Such tensor contractions are encountered in decomposition methods such as ten- sor power iterations and alternating least squares. We also design novel colliding hashes for symmetric tensors to further save time in computing the sketches. We then combine these sketching ideas with existing whitening and tensor power iter- ative techniques to obtain the fastest algorithm on both sparse and dense tensors. The quality of approximation under our method does not depend on properties such as sparsity, uniformity of elements, etc. We apply the method for topic mod- eling and obtain competitive results.\",\n          \"Many spectral unmixing methods rely on the non-negative decomposition of spectral data onto a dictionary of spectral templates. In particular, state-of-the-art music transcription systems decompose the spectrogram of the input signal onto a dictionary of representative note spectra. The typical measures of fit used to quantify the adequacy of the decomposition compare the data and template entries frequency-wise. As such, small displacements of energy from a frequency bin to another as well as variations of timber can disproportionally harm the fit. We address these issues by means of optimal transportation and propose a new measure of fit that treats the frequency distributions of energy holistically as opposed to frequency-wise. Building on the harmonic nature of sound, the new measure is invariant to shifts of energy to harmonically-related frequencies, as well as to small and local displacements of energy. Equipped with this new measure of fit, the dictionary of note templates can be considerably simplified to a set of Dirac vectors located at the target fundamental frequencies (musical pitch values). This in turns gives ground to a very fast and simple decomposition algorithm that achieves state-of-the-art performance on real musical data.\",\n          \"The problem of  multiclass boosting is considered. A new framework,based on multi-dimensional codewords and predictors is introduced. The optimal set of codewords is derived, and a margin enforcing loss proposed. The resulting risk is minimized by gradient descent on a multidimensional functional space. Two algorithms are proposed: 1) CD-MCBoost, based on coordinate descent, updates one predictor component at a time, 2) GD-MCBoost, based on gradient descent, updates all components jointly. The algorithms differ in the weak learners that they support but are both shown to be 1) Bayes consistent, 2) margin enforcing, and 3) convergent to the global minimum of the risk. They also reduce to AdaBoost when there are only two classes. Experiments show that both methods outperform previous multiclass boosting approaches on a number of datasets.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"paper_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6553,\n        \"samples\": [\n          \"550\\n\\nAckley and Littman\\n\\nGeneralization and scaling in reinforcement\\nlearning\\nDavid H. Ackley\\nMichael L. Littman\\nCognitive Science Research Group\\nBellcore\\nMorristown, NJ 07960\\n\\nABSTRACT\\nIn associative reinforcement learning, an environment generates input\\nvectors, a learning system generates possible output vectors, and a reinforcement function computes feedback signals from the input-output\\npairs. The task is to discover and remember input-output pairs that\\ngenerate rewards. Especially difficult cases occur when rewards are\\nrare, since the expected time for any algorithm can grow exponentially\\nwith the size of the problem. Nonetheless, if a reinforcement function\\npossesses regularities, and a learning algorithm exploits them, learning\\ntime can be reduced below that of non-generalizing algorithms. This\\npaper describes a neural network algorithm called complementary reinforcement back-propagation (CRBP), and reports simulation results\\non problems designed to offer differing opportunities for generalization.\\n\\n1\\n\\nREINFORCEMENT LEARNING REQUIRES SEARCH\\n\\nReinforcement learning (Sutton, 1984; Barto & Anandan, 1985; Ackley, 1988; Allen,\\n1989) requires more from a learner than does the more familiar supervised learning\\nparadigm. Supervised learning supplies the correct answers to the learner, whereas\\nreinforcement learning requires the learner to discover the correct outputs before\\nthey can be stored. The reinforcement paradigm divides neatly into search and\\nlearning aspects: When rewarded the system makes internal adjustments to learn\\nthe discovered input-output pair; when punished the system makes internal adjustments to search elsewhere.\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n1.1\\n\\nMAKING REINFORCEMENT INTO ERROR\\n\\nFollowing work by Anderson (1986) and Williams (1988), we extend the backpropagation algorithm to associative reinforcement learning. Start with a \\\"garden variety\\\" backpropagation network: A vector i of n binary input units propagates\\nthrough zero or more layers of hidden units, ultimately reaching a vector 8 of m\\nsigmoid units, each taking continuous values in the range (0,1). Interpret each 8j\\nas the probability that an associated random bit OJ takes on value 1. Let us call\\nthe continuous, deterministic vector 8 the search vector to distinguish it from the\\nstochastic binary output vector o.\\nGiven an input vector, we forward propagate to produce a search vector 8, and\\nthen perform m independent Bernoulli trials to produce an output vector o. The\\ni - 0 pair is evaluated by the reinforcement function and reward or punishment\\nensues. Suppose reward occurs. We therefore want to make 0 more likely given i.\\nBackpropagation will do just that if we take 0 as the desired target to produce an\\nerror vector (0 - 8) and adjust weights normally.\\nNow suppose punishment occurs, indicating 0 does not correspond with i. By choice\\nof error vector, backpropagation allows us to push the search vector in any direction;\\nwhich way should we go? In absence of problem-specific information, we cannot pick\\nan appropriate direction with certainty. Any decision will involve assumptions. A\\nvery minimal \\\"don't be like 0\\\" assumption-employed in Anderson (1986), Williams\\n(1988), and Ackley (1989)-pushes s directly away from 0 by taking (8 - 0) as the\\nerror vector. A slightly stronger \\\"be like not-o\\\" assumption-employed in Barto &\\nAnandan (1985) and Ackley (1987)-pushes s directly toward the complement of 0\\nby taking ((1 - 0) - 8) as the error vector. Although the two approaches always\\nagree on the signs of the error terms, they differ in magnitudes. In this work,\\nwe explore the second possibility, embodied in an algorithm called complementary\\nreinforcement back-propagation ( CRBP).\\nFigure 1 summarizes the CRBP algorithm. The algorithm in the figure reflects three\\nmodifications to the basic approach just sketched. First, in step 2, instead of using\\nthe 8j'S directly as probabilities, we found it advantageous to \\\"stretch\\\" the values\\nusing a parameter v. When v < 1, it is not necessary for the 8i'S to reach zero or\\none to produce a deterministic output. Second, in step 6, we found it important\\nto use a smaller learning rate for punishment compared to reward. Third, consider\\nstep 7: Another forward propagation is performed, another stochastic binary output vector 0* is generated (using the procedure from step 2), and 0* is compared\\nto o. If they are identical and punishment occurred, or if they are different and\\nreward occurred, then another error vector is generated and another weight update\\nis performed. This loop continues until a different output is generated (in the case\\nof failure) or until the original output is regenerated (in the case of success). This\\nmodification improved performance significantly, and added only a small percentage\\nto the total number of weight updates performed.\\n\\n551\\n\\n\\f552\\n\\nAckley and Littman\\n\\nO. Build a back propagation network with input dimensionality n and output\\ndimensionality m. Let t = 0 and te = O.\\n1. Pick random i E 2n and forward propagate to produce a/s.\\n2. Generate a binary output vector o. Given a uniform random variable ~ E [0,1]\\nand parameter 0 < v < 1,\\nOJ\\n\\n=\\n\\n{1,\\n\\n0,\\n\\nif(sj - !)/v+! ~ ~j\\notherwise.\\n\\n3. Compute reinforcement r = f(i,o). Increment t. If r < 0, let te = t.\\n4. Generate output errors ej. If r > 0, let tj = OJ, otherwise let tj = 1- OJ. Let\\nej = (tj - sj)sj(l- Sj).\\n5. Backpropagate errors.\\n6. Update weights. 1:::..Wjk = 1]ekSj, using 1] = 1]+ if r ~ 0, and 1] = 1]- otherwise,\\nwith parameters 1]+,1]- > o.\\n7. Forward propagate again to produce new Sj's. Generate temporary output\\nvector 0*. If (r > 0 and 0* #- 0) or (r < 0 and 0* = 0), go to 4.\\n8. If te ~ t, exit returning te, else go to 1.\\n\\nFigure 1: Complementary Reinforcement Back Propagation-CRBP\\n\\n2\\n\\nON-LINE GENERALIZATION\\n\\nWhen there are many possible outputs and correct pairings are rare, the computational cost associated with the search for the correct answers can be profound.\\nThe search for correct pairings will be accelerated if the search strategy can effectively generalize the reinforcement received on one input to others. The speed of\\nan algorithm on a given problem relative to non-generalizing algorithms provides a\\nmeasure of generalization that we call on-line generalization.\\nO. Let z be an array of length 2n. Set the z[i] to random numbers from 0 to\\n2m - 1. Let t = te = O.\\n1. Pick a random input i E 2n.\\n2. Compute reinforcement r = f(i, z[i]). Increment t.\\n3. If r < 0 let z[i] = (z[i] + 1) mod 2m , and let te = t.\\n4. If te <t:: t exit returning t e, else go to 1.\\n\\nFigure 2: The Table Lookup Reference Algorithm Tref(f, n, m)\\nConsider the table-lookup algorithm Tref(f, n, m) summarized in Figure 2. In this\\nalgorithm, a separate storage location is used for each possible input. This prevents\\nthe memorization of one i - 0 pair from interfering with any other. Similarly,\\nthe selection of a candidate output vector depends only on the slot of the table\\ncorresponding to the given input. The learning speed of T ref depends only on the\\ninput and output dimensionalities and the number of correct outputs associated\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n\\nwith each input. When a problem possesses n input bits and n output bits, and\\nthere is only one correct output vector for each input vector, Tre{ runs in about 4n\\ntime (counting each input-output judgment as one.) In such cases one expects to\\ntake at least 2n - 1 just to find one correct i - 0 pair, so exponential time cannot be\\navoided without a priori information. How does a generalizing algorithm such as\\nCRBP compare to Trer?\\n\\n3\\n\\nSIMULATIONS ON SCALABLE PROBLEMS\\n\\nWe have tested CRBP on several simple problems designed to offer varying degrees\\nand types of generalization. In all of the simulations in this section, the following\\ndetails apply: Input and output bit counts are equal (n). Parameters are dependent\\non n but independent of the reinforcement function f. '7+ is hand-picked for each\\nn,l 11- = 11+/10 and II = 0.5. All data points are medians of five runs. The stopping\\ncriterion te ~ t is interpreted as te +max(2000, 2n+l) < t. The fit lines in the figures\\nare least squares solutions to a x bn , to two significant digits.\\nAs a notational convenience, let c = ~\\n\\n3.1\\n\\nn\\n\\nE ij\\n\\n;=1\\n\\n-\\n\\nthe fraction of ones in the input.\\n\\nn-MAJORlTY\\n\\nConsider this \\\"majority rules\\\" problem: [if c > ~ then 0 = In else 0 = on]. The i-o\\nmapping is many-to-l. This problem provides an opportunity for what Anderson\\n(1986) called \\\"output generalization\\\": since there are only two correct output states,\\nevery pair of output bits are completely correlated in the cases when reward occurs.\\n\\nG)\\n\\n'iii\\nu\\nrn\\n\\nC)\\n\\n0\\n\\n::::.\\nG)\\n\\nE\\n\\n;\\n\\n10 7\\n10 6\\n10 5\\n10 4\\n\\nx\\n\\nTable\\n\\nD\\n\\nCRBP n-n-n\\n\\n+ CRBP n-n\\n\\n10 3\\n10 2\\n10 1\\n10 0\\n0\\n\\n1\\n\\n2\\n\\n3\\n\\n456\\n\\n78\\n\\n91011121314\\n\\nn\\nFigure 3: The n-majority problem\\n\\nFigure 3 displays the simulation results. Note that although Trer is faster than\\nCRBP at small values of n, CRBP's slower growth rate (1.6n vs 4.2n ) allows it to\\ncross over and begin outperforming Trer at about 6 bits. Note also--in violation of\\n1 For n = 1 to 12. we used '1+\\n0.219. 0.170. 0.121}.\\n\\n= {2.000. 1.550. 1.130.0.979.0.783.0.709.0.623.0.525.0.280.\\n\\n553\\n\\n\\f554\\n\\nAckley and Littman\\n\\nsome conventional wisdom-that although n-majority is a linearly separable problem, the performance of CRBP with hidden units is better than without. Hidden\\nunits can be helpful--even on linearly separable problems-when there are opportunities for output generalization.\\n\\n3.2\\n\\nn-COPY AND THE 2k -ATTRACTORS FAMILY\\n\\nAs a second example, consider the n-copy problem: [0 = i]. The i-o mapping is now\\n1-1, and the values of output bits in rewarding states are completely uncorrelated,\\nbut the value of each output bit is completely correlated with the value of the\\ncorresponding input bit. Figure 4 displays the simulation results. Once again, at\\n\\nG)\\n\\n'ii\\n\\ntA\\nQ\\n0\\n\\n::::.\\nG)\\n\\n-\\n\\n.5\\n\\n10 7\\n10 6\\n10 5\\n10 4\\n\\nx\\n150*2.0I\\\\n\\n\\nD\\n\\n10 3\\n10 2\\n\\n12*2.2I\\\\n\\n\\n+\\n\\nTable\\nCRBP n-n-n\\nCRBP n-n\\n\\n10 1\\n10 0\\n0\\n\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\n9\\n\\n10 1112\\n\\nn\\nFigure 4: The n-copy problem\\nlow values of n, Trer is faster, but CRBP rapidly overtakes Trer as n increases. In\\nn-copy, unlike n-majority, CRBP performs better without hidden units.\\nThe n-majority and n-copy problems are extreme cases of a spectrum. n-majority\\ncan be viewed as a \\\"2-attractors\\\" problem in that there are only two correct\\noutputs-all zeros and all ones-and the correct output is the one that i is closer\\nto in hamming distance. By dividing the input and output bits into two groups\\nand performing the majority function independently on each group, one generates\\na \\\"4-aUractors\\\" problem. In general, by dividing the input and output bits into\\n1 ~ Ie ~ n groups, one generates a \\\"2i:-attractors\\\" problem. When Ie = 1, nmajority results, and when Ie n, n-copy results.\\n\\n=\\n\\nFigure 5 displays simulation results on the n = 8-bit problems generated when Ie is\\nvaried from 1 to n. The advantage of hidden units for low values of Ie is evident,\\nas is the advantage of \\\"shortcut connections\\\" (direct input-to-output weights) for\\nlarger values of Ie. Note also that combination of both hidden units and shortcut\\nconnections performs better than either alone.\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n\\n105~--------------------------------~\\n\\nCASP 8-10-8\\n-+- CASP 8-8\\n.... CASP 8-10-Sls\\n-0-\\n\\n... Table\\n\\n3\\n\\n2\\n\\n1\\n\\n5\\n\\n4\\n\\n7\\n\\n6\\n\\n8\\n\\nk\\n\\nFigure 5: The 21:- attractors family at n = 8\\n\\n3.3\\n\\nn-EXCLUDED MIDDLE\\n\\nAll of the functions considered so far have been linearly separable. Consider this\\n\\\"folded majority\\\" function: [if\\n< c < then 0 on else 0 In]. Now, like\\nn-majority, there are only two rewarding output states, but the determination of\\nwhich output state is correct is not linearly separable in the input space. When\\nn = 2, the n-excluded middle problem yields the EQV (i.e., the complement of\\nXOR) function, but whereas functions such as n-parity [if nc is even then 0\\non\\nelse 0 = In] get more non-linear with increasing n, n-excluded middle does not.\\n\\ni\\n\\ni\\n\\n=\\n\\n=\\n\\n=\\n\\n107~------------------------------~~\\n\\n-\\n\\n10 6\\n10 5\\n\\nD)\\n\\n10 4\\n10 3\\n\\nI)\\n\\n'ii\\nu\\nf)\\n\\n.2\\n\\nI)\\n\\nE\\n\\n:::\\n\\nx\\nc\\n\\n17oo*1.6\\\"n\\n\\nTable\\n\\nCRSP n-n-n/s\\n\\n10 2\\n10 1\\n10 0\\n0\\n\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\n9\\n\\n10 1112\\n\\nn\\nFigure 6: The n-excluded middle problem\\nFigure 6 displays the simulation results. CRBP is slowed somewhat compared to\\nthe linearly separable problems, yielding a higher \\\"cross over point\\\" of about 8 bits.\\n\\n555\\n\\n\\f556\\n\\nAckley and Littman\\n\\n4\\n\\nSTRUCTURING DEGENERATE OUTPUT SPACES\\n\\nAll of the scaling problems in the previous section are designed so that there is\\na single correct output for each possible input. This allows for difficult problems\\neven at small sizes, but it rules out an important aspect of generalizing algorithms\\nfor associative reinforcement learning: If there are multiple satisfactory outputs\\nfor given inputs, a generalizing algorithm may impose structure on the mapping it\\nproduces.\\nWe have two demonstrations of this effect, \\\"Bit Count\\\" and \\\"Inverse Arithmetic.\\\"\\nThe Bit Count problem simply states that the number of I-bits in the output should\\nequal the number of I-bits in the input. When n = 9, Tref rapidly finds solutions\\ninvolving hundreds of different output patterns. CRBP is slower--especially with\\nrelatively few hidden units-but it regularly finds solutions involving just 10 output\\npatterns that form a sequence from 09 to 19 with one bit changing per step.\\n0+Ox4=0\\n1+0x4=1\\n2+0x4=2\\n3+0x4=3\\n\\n0+2x4=8\\n1+2x4=9\\n2 + 2 x 4 = 10\\n3+2x4=11\\n\\n4+0x4=4 4+ 2 x 4 =\\n5+0x4=5 5 + 2 x 4 =\\n6+0x4=6 6 + 2 x 4 =\\n7+0x4=7 7 + 2 x 4 =\\n\\n12\\n13\\n14\\n15\\n\\n2+2-4=0 2+2+4=8\\n3+2-4=1 3+2+4=9\\n2+2+4=2 2 + 2 x 4 = 10\\n3+2+4=3 3+2x4=1l\\n6+2-4=4\\n7+2-4=5\\n6+2+4=6\\n7+2-.;-4=7\\n\\n6+\\n7+\\n6+\\n7+\\n\\n2+ 4 =\\n2+ 4 =\\n2x4=\\n2x4=\\n\\n0+4 x 4 = 16 0+6 x 4 =\\n1+4x4=17 1 + 6 x 4 =\\n2 + 4 x 4 = 18 2 + 6 x 4 =\\n3 +4 x 4 = 19 3 + 6 x 4 =\\n\\n24\\n25\\n26\\n27\\n\\n4+4\\n5+ 4\\n6+ 4\\n7+ 4\\n\\n=\\n=\\n=\\n=\\n\\n28\\n29\\n30\\n31\\n24\\n25\\n26\\n27\\n\\nx\\nx\\nx\\nx\\n\\n4=\\n4=\\n4=\\n4=\\n\\n6+ 6 + 4 =\\n7+6+4=\\n2+ 4 x 4 =\\n3+ 4 x 4=\\n\\n12 4 x 4 +\\n13 5 + 4 x\\n14 6 + 4 x\\n15 7 +4 x\\n\\n4=\\n4=\\n4\\n4=\\n\\n=\\n\\n20 4 + 6 x\\n21 5 + 6 x\\n22 6 + 6 x\\n23 7 + 6 x\\n\\n4\\n4\\n4\\n4\\n\\n16\\n17\\n18\\n19\\n\\n0+6 x\\n1+ 6 x\\n2+ 6x\\n3+ 6x\\n\\n4=\\n4=\\n4=\\n4=\\n\\n20\\n21\\n22\\n23\\n\\n4+\\n5+\\n6+\\n7+\\n\\n4 = 28\\n4 = 29\\n4 30\\n4 = 31\\n\\n6\\n6\\n6\\n6\\n\\nx\\nx\\nx\\nx\\n\\n=\\n\\nFigure 7: Sample CRBP solutions to Inverse Arithmetic\\n\\nThe Inverse Arithmetic problem can be summarized as follows: Given i E 25 , find\\n:1:, y, z E 23 and 0, <> E {+(OO)' -(01)' X (10)' +(11)} such that :I: oy<>z = i. In all there are\\n13 bits of output, interpreted as three 3-bit binary numbers and two 2-bit operators,\\nand the task is to pick an output that evaluates to the given 5-bit binary input\\nunder the usual rules: operator precedence, left-right evaluation, integer division,\\nand division by zero fails.\\nAs shown in Figure 7, CRBP sometimes solves this problem essentially by discovering positional notation, and sometimes produces less-globally structured solutions,\\nparticularly as outputs for lower-valued i's, which have a wider range of solutions.\\n\\n\\fGeneralization and Scaling in Reinforcement Learning\\n\\n5\\n\\nCONCLUSIONS\\n\\nSome basic concepts of supervised learning appear in different guises when the\\nparadigm of reinforcement learning is applied to large output spaces. Rather than\\na \\\"learning phase\\\" followed by a \\\"generalization test,\\\" in reinforcement learning\\nthe search problem is a generalization test, performed simultaneously with learning.\\nInformation is put to work as soon as it is acquired.\\nThe problem of of \\\"overfitting\\\" or \\\"learning the noise\\\" seems to be less of an issue,\\nsince learning stops automatically when consistent success is reached. In experiments not reported here we gradually increased the number of hidden units on\\nthe 8-bit copy problem from 8 to 25 without observing the performance decline\\nassociated with \\\"too many free parameters.\\\"\\nThe 2 k -attractors (and 2 k -folds-generalizing Excluded Middle) families provide\\na starter set of sample problems with easily understood and distinctly different\\nextreme cases.\\nIn degenerate output spaces, generalization decisions can be seen directly in the\\ndiscovered mapping. Network analysis is not required to \\\"see how the net does it.\\\"\\nThe possibility of ultimately generating useful new knowledge via reinforcement\\nlearning algorithms cannot be ruled out.\\nReferences\\nAckley, D.H. (1987) A connectionist machine for genetic hillclimbing. Boston, MA: Kluwer\\nAcademic Press.\\nAckley, D.H. (1989) Associative learning via inhibitory search. In D.S. Touretzky (ed.),\\nAdvances in Neural Information Processing Systems 1, 20-28. San Mateo, CA: Morgan\\nKaufmann.\\nAllen, R.B. (1989) Developing agent models with a neural reinforcement technique. IEEE\\nSystems, Man, and Cybernetics Conference. Cambridge, MA.\\nAnderson, C.W. (1986) Learning and problem solving with multilayer connectionist systems. University of Mass. Ph.D. dissertation. COINS TR 86-50. Amherst, MA.\\nBarto, A.G. (1985) Learning by statistical cooperation of self-interested neuron-like computing elements. Human Neurobiology, 4:229-256.\\nBarto, A.G., & Anandan, P. (1985) Pattern recognizing stochastic learning automata.\\nIEEE Transactions on Systems, Man, and Cybernetics, 15, 360-374.\\nRumelhart, D.E., Hinton, G.E., & Williams, R.J. (1986) Learning representations by backpropagating errors. Nature, 323, 533-536.\\nSutton, R.S. (1984) Temporal credit assignment in reinforcement learning. University of\\nMass. Ph.D. dissertation. COINS TR 84-2. Amherst, MA.\\nWilliams, R.J. (1988) Toward a theory of reinforcement-learning connectionist systems.\\nCollege of Computer Science of Northeastern University Technical Report NU-CCS-88-3.\\nBoston, MA.\\n\\n557\\n\\n\\f\",\n          \"Dynamics of Supervised Learning with\\nRestricted Training Sets and Noisy Teachers\\n\\nA.C.C. Coolen\\nDept of Mathematics\\nKing's College London\\nThe Strand, London WC2R 2LS, UK\\ntcoolen@mth.kc1.ac.uk\\n\\nC.W.H.Mace\\nDept of Mathematics\\nKing's College London\\nThe Strand, London WC2R 2LS, UK\\ncmace@mth.kc1.ac.uk\\n\\nAbstract\\nWe generalize a recent formalism to describe the dynamics of supervised\\nlearning in layered neural networks, in the regime where data recycling\\nis inevitable, to the case of noisy teachers. Our theory generates reliable\\npredictions for the evolution in time of training- and generalization errors, and extends the class of mathematically solvable learning processes\\nin large neural networks to those situations where overfitting can occur.\\n\\n1 Introduction\\nTools from statistical mechanics have been used successfully over the last decade to study\\nthe dynamics of learning in layered neural networks (for reviews see e.g. [1] or [2]). The\\nsimplest theories result upon assuming the data set to be much larger than the number\\nof weight updates made, which rules out recycling and ensures that any distribution of\\nrelevance will be Gaussian. Unfortunately, both in terms of applications and in terms of\\nmathematical interest, this regime is not the most relevant one. Most complications and\\npeculiarities in the dynamics of learning arise precisely due to data recycling, which creates\\nfor the system the possibility to improve performance by memorizing answers rather than\\nby learning an underlying rule. The dynamics of learning with restricted training sets was\\nfirst studied analytically in [3] (linear learning rules) and [4] (systems with binary weights).\\nThe latter studies were ahead of their time, and did not get the attention they deserved just\\nbecause at that stage even the simpler learning dynamics without data recycling had not\\nyet been studied. More recently attention has moved back to the dynamics of learning\\nin the recycling regime. Some studies aimed at developing a general theory [5, 6, 7],\\nsome at finding exact solutions for special cases [8]. All general theories published so far\\nhave in common that they as yet considered realizable scenario's: the rule to be learned\\nwas implementable by the student, and overfitting could not yet occur. The next hurdle is\\nthat where restricted training sets are combined with unrealizable rules. Again some have\\nturned to non-typical but solvable cases, involving Hebbian rules and noisy [9] or 'reverse\\nwedge' teachers [10]. More recently the cavity method has been used to build a general\\ntheory [11] (as yet for batch learning only). In this paper we generalize the general theory\\nlaunched in [6,5,7], which applies to arbitrary learning rules, to the case of noisy teachers.\\nWe will mirror closely the presentation in [6] (dealing with the simpler case of noise-free\\nteachers), and we refer to [5, 7] for background reading on the ideas behind the formalism.\\n\\n\\fA. C. C. Coolen and C. W. H. Mace\\n\\n238\\n\\n2 Definitions\\nAs in [6, 5] we restrict ourselves for simplicity to perceptrons. A student perceptron operates a linear separation, parametrised by a weight vector J E iRN :\\nS:{-I,I}N -t{-I,I}\\n\\nS(e) = sgn[J?e]\\n\\nIt aims to emulate a teacher o~erating a similar rule, which, however, is characterized by a\\nvariable weight vector BE iR ,drawn at random from a distribution P(B) such as\\nP(B) = >'6[B+B*]\\n\\noutput noise:\\n\\n+ (1->')6[B-B*]\\n\\n(1)\\n\\nP(B) = [~~/NrN e- tN (B-B')2/E2\\n(2)\\nThe parameters>. and ~ control the amount of teacher noise, with the noise-free teacher\\nB = B* recovered in the limits>. -t 0 and ~ -t O. The student modifies J iteratively, using\\nexamples of input vectors which are drawn at random from a fixed (randomly composed)\\nE {-I, I}N with a> 0, and the corresponding\\ntraining set containing p = aN vectors\\nvalues of the teacher outputs. We choose the teacher noise to be consistent, i.e. the answer\\nwill remain the same when that particular question\\ngiven by the teacher to a question\\nre-appears during the learning process. Thus T(e?) = sgn[BJL . e], with p teacher weight\\nvectors BJL, drawn randomly and independently from P(B), and we generalize the training\\nl , B l ), . .. , (e, BP)}. Consistency of teacher noise is natural\\nset accordingly to jj =\\nin terms of applications, and a prerequisite for overfitting phenomena. Averages over the\\ntraining set will be denoted as ( ... ) b; averages over all possible input vectors E {-I, I}N\\nas ( ... )e. We analyze two classes of learning rules, of the form J (? + 1) = J (?) + f).J (?):\\n\\nGaussian weight noise:\\n\\ne\\n\\ne\\n\\ne\\n\\nHe\\n\\ne\\n\\n= 11 {e(?) 9 [J(?)?e(?), B(?)?e(?)] - ,J(?) }\\nf).J(?) = 11 {(e 9 [J(?)?e, B?eDl> - ,J(m) }\\n\\non-line:\\n\\nf).J(?)\\n\\nbatch :\\n\\n(3)\\n\\nIn on-line learning one draws at each step ? a question/answer pair (e (?), B (?)) at random from the training set. In batch learning one iterates a deterministic map which is an\\naverage over all data in the training set. Our performance measures are the training- and\\ngeneralization errors, defined as follows (with the step function O[x > 0] = 1, O[x < 0] = 0):\\nEt(J)\\n\\n= (O[-(J ?e)(B ?em b\\n\\nEg(J)\\n\\n= (O[-(J ?e)(B* ?e)])e\\n\\n(4)\\n\\nWe introduce macroscopic observables, taylored to the present problem, generalizing [5, 6]:\\nQ[J]=J 2,\\nR[J]=J?B*,\\nP[x,y,z;J]=(6[x-J?e]6[y-B*?e]6[z-B?eDl> (5)\\nAs in [5, 6] we eliminate technical subtleties by assuming the number of arguments (x, y, z)\\nfor which P[x, y, z; J] is evaluated to go to infinity after the limit N -t 00 has been taken.\\n\\n3 Derivation of Macroscopic Laws\\nUpon generalizing the calculations in [6, 5], one finds for on-line learning:\\n\\n!\\n!\\n\\nQ = 2'f} !dXdydZ P[x, y, z] xg[x, z] - 2'f},Q + 'f}2!dXdYdZ P[x, y, z] g2[x, z]\\n\\n(6)\\n\\nR = 'f} !dXdydZ P[x, y, z] y9[x, z]- 'f},R\\n\\n(7)\\n\\n:t\\n\\nP[x, y, z] =\\n\\n~\\n\\n!\\n\\ndx' P[x', y, z] {6[x-x' -'f}G[x', z]] -6[x-x']}\\n\\n-'f}! / dx'dy'dz' / dx'dy'dz'9[x', z]A[x, y, z; x',y', z']\\n\\n1\\n+'i'f}2\\n\\n!\\n\\n+ 'f}, :x\\n\\nEP2P[x, y, z]\\ndx'dy'dz' P[x', y', z']92[x', z'] 8x\\n\\n{xP[x , y, z]}\\n\\n(8)\\n\\n\\fSupervised Learning with Restricted Training Sets\\n\\n239\\n\\nThe complexity of the problem is concentrated in a Green's function:\\nA[x, y, Zj x', y', z'] = lim\\nN-+oo\\n\\n(( ([1-6ee , ]6[x-J?e]6[y-B*?e]6[z-B?e] (e?e')6[x' -J?e']6[y' - B*?e']6[y' - B?e'])i?i> )QW;t\\n\\nJ\\n\\nIt involves a conditional average of the form (K[J])QW;t = dJ Pt(JIQ,R,P)K[J], with\\nPt(J) 6[Q-Q[J]]6[R- R[J]] nXYZ 6[P[x, y, z] -P[x, y, Zj J]]\\nPt(JIQ,R,P)\\nJdJ Pt(J) 6[Q - Q[J]]6[R- R[J]] nXYZ 6[P[x, y, z] - P[x, y, z; J]]\\n\\n=\\n\\nin which Pt (J) is the weight probability density at time t. The solution of (6,7,8) can be\\nused to generate the N -+ 00 performance measures (4) at any time:\\nEt\\n\\n=/\\n\\ndxdydz P[x, y, z]O[-xz]\\n\\nEg\\n\\n= 11\\\"-1 arccos[RIVQ]\\n\\n(9)\\n\\nExpansion of these equations in powers of\\\"\\\" and retaining only the terms linear in \\\"\\\" gives\\nthe corresponding equations describing batch learning. So far this analysis is exact.\\n\\n4\\n\\nClosure of Macroscopic Laws\\n\\nAs in [6, 5] we close our macroscopic laws (6,7,8) by making the two key assumptions\\nunderlying dynamical replica theory:\\n(i) For N -+ 00 our macroscopic observables obey closed dynamic equations.\\n(ii) These equations are self-averaging with respect to the specific realization of D.\\n\\n(i) implies that probability variations within {Q, R, P} subshells are either absent or irrelevant to the macroscopic laws. We may thus make the simplest choice for Pt (J IQ, R, P):\\nPt(JIQ,R,P) -+ 6[Q-Q[J]] 6[R-R[J]]\\n\\nII 6[P[x,y,z]-P[x,y,ZjJ]]\\n\\n(10)\\n\\nxyz\\n\\nThe procedure (10) leads to exact laws if our observables {Q, R, P} indeed obey closed\\nequations for N -+ 00. It is a maximum entropy approximation if not. (ii) allows us\\nto average the macroscopic laws over all training sets; it is observed in simulations, and\\nproven using the formalism of [4]. Our assumptions (10) result in the closure of (6,7,8),\\nsince now the Green's function can be written in terms of {Q, R, Pl. The final ingredient\\nof dynamical replica theory is doing the average of fractions with the replica identity\\n\\n/ JdJ W[JID]GIJID])\\n\\n\\\\\\n\\nJdJ W[JID]\\n\\n= lim\\nsets\\n\\n/dJ I\\n\\n???\\n\\ndJn (G[J 1 ID]\\n\\nn-+O\\n\\nIT\\n\\nW[JO<ID])sets\\n\\na=1\\n\\nOur problem has been reduced to calculating (non-trivial) integrals and averages. One\\nfinds that P[x, y, z] P[x, zly]P[y] with Ply] (211\\\")-!exp[-!y 21With the short-hands\\nDy = P[y]dy and (f(x, y, z)) = Dydxdz P[x, zly]f(x, y, z) we can write the resulting\\nmacroscopic laws, for the case of output noise (1), in the following compact way:\\n\\n=\\n\\nd\\n\\ndt Q = 2\\\",(V - ,Q)\\n\\n[)\\n\\n[)tP[x,zly] =\\n\\n=\\n\\nJ\\n\\n+ rJ2 Z\\n\\nd\\n\\ndtR = \\\",(W - ,R)\\n\\n(11)\\n\\n1 [)x[)22P[x,zIY]\\na1/dx'P[x',zly] {6[x-x'-\\\",G[x',z]]-6[x-x'] }+2\\\",2Z\\n\\n-\\\",:x {P[x,zly]\\n\\n[U(x-RY)+Wy-,x+[V-RW-(Q-R2)U]~[x,y,z])}\\n\\n(12)\\n\\nwith\\n\\nU = (~[x, y, z]9[x, z]),\\n\\nv = (x9[x, z]),\\n\\nW = (y9[x, z]),\\n\\nZ = (9 2[x, z])\\n\\nThe solution of (12) is at any time of the following form:\\n\\nP[x,zly]\\n\\n= (1-,x)6[y-z]P+[xly] + ,x6[y+z]P-[xly]\\n\\n(13)\\n\\n\\fA. C. C. Coolen and C. W. H. Mace\\n\\n240\\n\\nFinding the function <I> [x, y, z] (in replica symmetric ansatz) requires solving a saddle-point\\nproblem for a scalar observable q and two functions M?[xly]. Upon introducing\\n\\nB = . . :. V. .,. .q.,-Q___R,-2\\nQ(I-q)\\n(with Jdx M?[xly]\\n\\nJdx M?[xly]eBxs J[x, y]\\nJdx M?[xly]eBxs\\n\\n(f[x, y])? =\\n*\\n\\n= 1 for all y) the saddle-point equations acquire the fonn\\np?[Xly] =\\n\\nfor all X, y :\\n\\n((x-Ry)2) + (qQ-R 2)[I-!:.]\\na\\n\\n!\\n\\nDs (O[X -xl);\\n\\n2 !DYDS S[(I-A)(X); + A(X);]\\n= qQ+Q-2R\\n..jqQ_R2\\n\\n(14)\\n(15)\\n\\nThe equations (14) which detennine M?[xly] have the same structure as the corresponding\\n(single) equation in [5, 6], so the proofs in [5, 6] again apply, and the solutions M?[xly],\\ngiven a q in the physical range q E [R2/Q, 1], are unique. The function <I> [x, y, z] is then\\ngiven by\\n<I> [X,\\n\\ny, z]\\n\\n=!\\n\\nDs s\\n{(I-A)O[Z-y](o[X -x)); + AO[Z+Y](o[X -xl);}\\n..jqQ_R2 P[X, zly]\\n(16)\\n\\nWorking out predictions from these equations is generally CPU-intensive, mainly due to\\nthe functional saddle-point equation (14) to be solved at each time step. However, as in [7]\\none can construct useful approximations of the theory, with increasing complexity:\\n\\n(i) Large a approximation (giving the simplest theory, without saddle-point equations)\\n(ii) Conditionally Gaussian approximation for M[xly] (with y-dependent moments)\\n(iii) Annealed approximation of the functional saddle-point equation\\n\\n5 Benchmark Tests: The Limits a --+ 00 and ,\\\\ --+ 0\\nWe first show that in the limit a --+ 00 our theory reduces to the simple (Q, R) formalism\\nof infinite training sets, as worked out for noisy teachers in [12]. Upon making the ansatz\\n\\np?[xly] = P[xly] = [27r(Q-R 2)]-t e- t [x- Rv]2/(Q-R 2)\\n\\n(17)\\n\\none finds\\n\\n<I>[x,y,Z] = (x-Ry)/(Q-R 2)\\n\\nM?[xly] = P[xly],\\n\\nInsertion of our ansatz into (12), followed by rearranging of terms and usage of the above\\nexpression for <I> [x, y, z], shows that (12) is satisfied. The remaining equations (11) involve\\nonly averages over the Gaussian distribution (17), and indeed reduce to those of [12]:\\n\\n~! Q =\\n\\n(I-A) { 2(x9[x, y))\\n1 d\\n--d R\\n1} t\\n\\n+ 1}{92[x, y)) } + A {2(x9[x,-y)) + 1}(92[x,-y)) } - 2,Q\\n\\n= (I-A)(y9[x,y)) + A(y9[x,-yl) -,R\\n\\nNext we turn to the limit A --+ 0 (restricted training sets & noise-free teachers) and show that\\nhere our theory reproduces the fonnalism of [6,5]. Now we make the following ansatz:\\n\\nP+[xly] = P[xly],\\n\\nP[x, zly]\\n\\n= o[z-y]P[xIY]\\n\\n(18)\\n\\nInsertion shows that for A = 0 solutions of this fonn indeed solve our equations, giving\\n<p[x, y, z]--+ <I> [x, y] and M+[xly]\\nM[xly), and leaving us exactly with the fonnalism\\nof [6, 5] describing the case of noise-free teachers and restricted training sets (apart from\\nsome new tenns due to the presence of weight decay, which was absent in [6, 5]).\\n\\n=\\n\\n\\f241\\n\\nSupervised Learning with Restricted Training Sets\\n0. , r------~--__,\\n\\n0..4\\n\\n~-------_____I\\n\\n0..4\\n\\n11>=0.'\\n\\n0..3\\n\\na=4\\n\\n0. ,\\n\\n0..0.\\n\\n--\\n\\n, 0.\\n\\n0.2\\n\\n_ __ ___ _____ _\\n\\na= 1\\n\\n0;=1\\n\\n------- ---- -- --- -\\n\\n0.\\n\\n0;=2\\n\\n=-=\\n-\\n\\n0;=2\\n\\n- - ----- -\\n\\na=4\\na=4\\n\\n= =-=\\n--=-=--=-=--=-=-=-- -=-=-_oed\\n\\na=4\\n\\n,\\n\\n0;=2\\n\\n':::::========:::j\\n\\n0..3\\n\\n-- - ----\\n\\n0;=1\\n\\n:::---- - -----1\\n\\n0;=2\\n\\n0..2\\n\\n11>=0.'\\n\\n~-------~\\n\\n0;=1\\n\\n0.,\\n\\n11>=0,\\n\\n\\\"\\n\\n,\\n\\nno. I\\n\\n0.\\n\\n, 0.\\n\\n\\\"\\n\\nFigure 1: On-line Hebbian learning: conditionally Gaussian approximation versus exact\\nsolution in [9] (.,., = 1, ,X = 0.2). Left: \\\"I = 0.1, right: \\\"I = 0.5. Solid lines: approximated\\ntheory, dashed lines: exact result. Upper curves: Eg as functions of time (here the two\\ntheories agree), lower curves: E t as functions of time.\\n\\n6\\n\\nBenchmark Tests: Hebbian Learning\\n\\nThe special case of Hebbian learning, i.e. Q[x, z] = sgn(z), can be solved exactly at any\\ntime, for arbitrary {a, ,x, \\\"I} [9], providing yet another excellent benchmark for our theory.\\nFor batch execution of Hebbian learning the macroscopic laws are obtained upon expanding\\n(11,12) and retaining only those terms which are linear in.,.,. All integrations can now be\\ndone and all equations solved explicitly, resulting in U =0, Z = 1, W = (I-2,X)J2/7r, and\\n\\nQ\\n\\n= Qo e-2rryt +\\n\\n2Ro(I-2'x) e-17\\\"Yt[I_e-rrrt]\\n\\\"I\\n\\nf{ + [~(I-2,X)2+.!.]\\n\\nV:;\\n\\n7r\\n\\na\\n\\n[I-e- 17 \\\"Y tF\\n\\\"12\\n\\nR = Ro e- 17\\\"Y t +(I-2'x)J2/7r[I-e- 17\\\"Y t ]/\\\"I\\nq = [aR2+(I_e- 17\\\"Yt)2 i'l]/aQ\\np?[xIY] = [27r(Q-R2)] -t e-tlz-RH sgn(y)[1-e-\\\"..,t]/a\\\"Y]2/(Q-R2)\\n(19)\\nFrom these results, in tum, follow the performance measures Eg = 7r- 1 arccos[ R/ JQ) and\\n\\nE = ! - !(1-,X)!D\\n2\\n\\nt\\n\\n2\\n\\nerf[IYIR+[I-e- 77\\\"Y t ]/a\\\"l] + !,X!D erf[IYIR-[I-e- 17\\\"Y t ]/a\\\"l]\\nY\\nJ2(Q-R2)\\n2\\ny\\nJ2(Q-R2)\\n\\nComparison with the exact solution, calculated along the lines of [9] or, equivalently, obtained upon putting t ?\\nin [9], shows that the above expressions are all exact.\\n\\n.,.,-2\\n\\nFor on-line execution we cannot (yet) solve the functional saddle-point equation in general.\\nHowever, some analytical predictions can still be extracted from (11,12,13):\\n\\nQ = Qo e-217\\\"Yt + 2Ro(I-2,X) e-77\\\"Yt[I_e-17\\\"Yt]\\n\\\"I\\n\\nR = Ro e- 17\\\"Y t + (I-2,X)J2/7r[I-e- 17\\\"Y t ]/\\\"I\\n\\nJ\\n\\nf{ + [~(I-2,X)2+.!.]\\n\\nV:;\\n\\n7r\\n\\na\\n\\n[I_e- 17\\\"Y t ]2\\n\\\"12\\n\\n+ !L[I_e- 217\\\"Y t ]\\n2\\\"1\\n\\ndx xP?[xIY] = Ry ? sgn(y)[I-e- 17\\\"Y t ]/a\\\"l\\n\\nwith U =0, W = (I-2,X)J2/7r, V = W R+[I-e- 17\\\"Y t ]/a\\\"l, and Z = 1. Comparison with the\\nresults in [9] shows that the above expressions, and thus also that of E g , are all fully exact,\\nat any time. Observables involving P[x, y, z] (including the training error) are not as easily\\nsolved from our equations. Instead we used the conditionally Gaussian approximation\\n(found to be adequate for the noiseless Hebbian case [5, 6, 7]). The result is shown in\\nfigure 1. The agreement is reasonable, but significantly less than that in [6]; apparently\\nteacher noise adds to the deformation of the field distribution away from a Gaussian shape.\\n\\n\\f242\\n\\nA. C. C. Coolen and C. W H. Mac\\n\\n~\\n\\n0.6\\n\\n000000\\n\\n0.4\\n\\n0.4\\n\\nE\\n\\n~\\n\\n0.2\\n\\nI\\ni\\n0.0\\n\\n0\\n\\n4\\n\\n2\\n\\n6\\n\\n10\\n\\n0.0\\n\\n-3\\n\\n-2\\n\\n-I\\n\\n0\\nX\\n\\n0.6\\n\\nf\\n\\n0.4\\n\\n0.4 [\\n\\nE\\n0.2\\n\\n0.2\\n\\n0.0\\n\\nL-o!i6iIII.\\\"\\\"\\\"\\\"\\\"',-\\\"--~_~~_ _--'\\n\\n-3\\n\\n-2\\n\\n-I\\n\\n0\\n\\n2\\n\\n3\\n\\nX\\n\\n,=\\n\\nFigure 2: Large a approximation versus numerical simulations (with N = 10,000), for\\n0 and A = 0.2. Top row: Perceptron rule, with.,., = ~. Bottom row: Adatron rule,\\nwith.,., = ~. Left: training errors E t and generalisation errors Eg as functions of time, for\\naE {~, 1, 2}. Lines: approximated theory, markers: simulations (circles: E t , squares: Eg) .\\nRight: joint distributions for student field and teacher noise p?[x] = dy P[x, y, z = ?y]\\n(upper: P+[x], lower: P-[x]). Histograms: simulations, lines: approximated theory.\\n\\nJ\\n\\n7\\n\\nNon-Linear Learning Rules: Theory versus Simulations\\n\\nIn the case of non-linear learning rules no exact solution is known against which to test our\\nformalism, leaving numerical simulations as the yardstick. We have evaluated numerically\\nthe large a approximation of our theory for Perceptron learning, 9[x, z] = sgn(z)O[-xz],\\nand for Adatron learning, 9[x, z] = sgn(z)lzIO[-xz]. This approximation leads to the\\nfollowing fully explicit equation for the field distributions:\\n\\n1/\\n\\nd\\n-p?[xly]\\n= dt\\na\\n.\\n\\nWith\\n\\nU=\\n\\n' +1\\n\\ndx' p?[x'ly]{o[x-x'-.,.,.1'[x', ?y]] -o[x-x]}\\n\\n_ ~ {P[ I ] [W _\\n.,., 8\\nx y\\ny\\n\\nJ\\n\\nX\\n\\n~ p?[xly]\\n\\n_.,.,2 Z!:I 2\\n2\\nuX\\n\\n,X + U[X?(y)-RY]+(V-RW)[X-X?(y)]]}\\nQ _ R2\\n\\nDydx {(I-A)P+[xly][x-P(y)]9[x,Y]+AP-[xly][x-x-(y)]9[x,-y])\\nV =\\nW=\\nZ=\\n\\n!\\n1\\n1\\n\\nDydx x {(I-A)P+[xly]9[x, Y]+AP-[xly]9[x,-y])\\nDydx y {(1-A)P+[xly]9[x, Y]+AP-[xly]9[x,-y])\\n\\nDydx {(I-A)P+[xly]92[x, Y]+AP-[xly]9 2[x,-yJ)\\n\\n\\fSupervised Learning with Restricted Training Sets\\n\\n243\\n\\nJ\\n\\nand with the short-hands X?(y) = dx xP?[xly). The result of our comparison is shown\\nin figure 2. Note: E t increases monotonically with a, and Eg decreases monotonically\\nwith a, at any t. As in the noise-free formalism [7], the large a approximation appears to\\ncapture the dominant terms both for a -7 00 and for a -7 O. The predicting power of our\\ntheory is mainly limited by numerical constraints. For instance, the Adatron learning rule\\ngenerates singularities at x = 0 in the distributions P?[xly) (especially for small \\\"I) which,\\nalthough predicted by our theory, are almost impossible to capture in numerical solutions.\\n\\n8 Discussion\\nWe have shown how a recent theory to describe the dynamics of supervised learning with\\nrestricted training sets (designed to apply in the data recycling regime, and for arbitrary online and batch learning rules) [5, 6, 7] in large layered neural networks can be generalized\\nsuccessfully in order to deal also with noisy teachers. In our generalized approach the joint\\ndistribution P[x, y, z) for the fields of student, 'clean' teacher, and noisy teacher is taken to\\nbe a dynamical order parameter, in addition to the conventional observables Q and R. From\\nthe order parameter set {Q, R, P} we derive the generalization error Eg and the training\\nerror E t . Following the prescriptions of dynamical replica theory one finds a diffusion\\nequation for P[x, y, z], which we have evaluated by making the replica-symmetric ansatz.\\nWe have carried out several orthogonal benchmark tests of our theory: (i) for a -7 00 (no\\ndata recycling) our theory is exact, (ii) for A -7 0 (no teacher noise) our theory reduces\\nto that of [5, 6, 7], and (iii) for batch Hebbian learning our theory is exact. For on-line\\nHebbian learning our theory is exact with regard to the predictions for Q, R, Eg and the\\ny-dependent conditional averages Jdx xP?[xly), at any time, and a crude approximation\\nof our equations already gives reasonable agreement with the exact results [9] for E t . For\\nnon-linear learning rules (Perceptron and Adatron) we have compared numerical solution\\nof a simple large a aproximation of our equations to numerical simulations, and found\\nsatisfactory agreement. This paper is a preliminary presentation of results obtained in the\\nsecond stage of a research programme aimed at extending our theoretical tools in the arena\\nof learning dynamics, building on [5, 6, 7]. Ongoing work is aimed at systematic application of our theory and its approximations to various types of non-linear learning rules, and\\nat generalization of the theory to multi-layer networks.\\n\\nReferences\\n[1]\\n[2]\\n[3]\\n[4]\\n[5]\\n[6]\\n[7]\\n[8]\\n[9]\\n[10]\\n[11]\\n[12]\\n\\nMace C.W.H. and Coolen AC.C (1998), Statistics and Computing 8, 55\\nSaad D. (ed.) (1998), On-Line Learning in Neural Networks (Cambridge: CUP)\\nHertz J.A., Krogh A and Thorgersson G.I. (1989), J. Phys. A 22, 2133\\nHomerH. (1992a), Z. Phys. B 86, 291 and Homer H. (1992b), Z. Phys. B 87,371\\nCoolen A.C.C. and Saad D. (1998), in On-Line Learning in Neural Networks, Saad\\nD. (ed.), (Cambridge: CUP)\\nCoolen AC.C. and Saad D. (1999), in Advances in Neural Information Processing\\nSystems 11, Kearns D., Solla S.A., Cohn D.A (eds.), (MIT press)\\nCoolen A.C.C. and Saad D. (1999), preprints KCL-MTH-99-32 & KCL-MTH-99-33\\nRae H.C., Sollich P. and Coolen AC.C. (1999), in Advances in Neural Information\\nProcessing Systems 11, Kearns D., Solla S.A., Cohn D.A. (eds.), (MIT press)\\nRae H.C., Sollich P. and Coolen AC.C. (1999),J. Phys. A 32, 3321\\nInoue J.I. (1999) private communication\\nWong K.YM., Li S. and Tong YW. (1999),preprint cond-mat19909004\\nBiehl M., Riegler P. and Stechert M. (1995), Phys. Rev. E 52, 4624\\n\\n\\f\",\n          \"Predicting Action Content On-Line and in\\nReal Time before Action Onset ? an\\nIntracranial Human Study\\n\\nShengxuan Ye\\nCalifornia Institute of Technology\\nPasadena, CA\\nsye@caltech.edu\\n\\nUri Maoz\\nCalifornia Institute of Technology\\nPasadena, CA\\nurim@caltech.edu\\nIan Ross\\nHuntington Hospital\\nPasadena, CA\\nianrossmd@aol.com\\n\\nAdam Mamelak\\nCedars-Sinai Medical Center\\nLos Angeles, CA\\nadam.mamelak@cshs.org\\n\\nChristof Koch\\nCalifornia Institute of Technology\\nPasadena, CA\\nAllen Institute for Brain Science\\nSeattle, WA\\nkoch@klab.caltech.edu\\n\\nAbstract\\nThe ability to predict action content from neural signals in real time before the action occurs has been long sought in the neuroscientific study of decision-making,\\nagency and volition. On-line real-time (ORT) prediction is important for understanding the relation between neural correlates of decision-making and conscious,\\nvoluntary action as well as for brain-machine interfaces. Here, epilepsy patients,\\nimplanted with intracranial depth microelectrodes or subdural grid electrodes for\\nclinical purposes, participated in a ?matching-pennies? game against an opponent.\\nIn each trial, subjects were given a 5 s countdown, after which they had to raise\\ntheir left or right hand immediately as the ?go? signal appeared on a computer\\nscreen. They won a fixed amount of money if they raised a different hand than\\ntheir opponent and lost that amount otherwise. The question we here studied was\\nthe extent to which neural precursors of the subjects? decisions can be detected in\\nintracranial local field potentials (LFP) prior to the onset of the action.\\nWe found that combined low-frequency (0.1?5 Hz) LFP signals from 10 electrodes\\nwere predictive of the intended left-/right-hand movements before the onset of the\\ngo signal. Our ORT system predicted which hand the patient would raise 0.5 s\\nbefore the go signal with 68?3% accuracy in two patients. Based on these results,\\nwe constructed an ORT system that tracked up to 30 electrodes simultaneously,\\nand tested it on retrospective data from 7 patients. On average, we could predict\\nthe correct hand choice in 83% of the trials, which rose to 92% if we let the system\\ndrop 3/10 of the trials on which it was less confident. Our system demonstrates?\\nfor the first time?the feasibility of accurately predicting a binary action on single\\ntrials in real time for patients with intracranial recordings, well before the action\\noccurs.\\n\\n1\\n\\n\\f1\\n\\nIntroduction\\n\\nThe work of Benjamin Libet [1, 2] and others [3, 4] has challenged our intuitive notions of the relation between decision making and conscious voluntary action. Using electrocorticography (EEG),\\nthese experiments measured brain potentials from subjects that were instructed to flex their wrist at a\\ntime of their choice and note the position of a rotating dot on a clock when they felt the urge to move.\\nThe results suggested that a slow cortical wave measured over motor areas?termed ?readiness potential? [5], and known to precede voluntary movement [6]?begins a few hundred milliseconds before the average reported time of the subjective ?urge? to move. This suggested that action onset and\\ncontents could be decoded from preparatory motor signals in the brain before the subject becomes\\naware of an intention to move and of the contents of the action. However, the readiness potential\\nwas computed by averaging over 40 or more trials aligned to movement onset after the fact. More\\nrecently, it was shown that action contents can be decoded using functional magnetic-resonance\\nimaging (fMRI) several seconds before movement onset [7]. But, while done on a single-trial basis,\\ndecoding the neural signals took place off-line, after the experiment was concluded, as the sluggish\\nnature of fMRI hemodynamic signals precluded real-time analysis. Moreover, the above studies\\nfocused on arbitrary and meaningless action?purposelessly raising the left or right hand?while\\nwe wanted to investigate prediction of reasoned action in more realistic, everyday situations with\\nconsequences for the subject.\\nIntracranial recordings are good candidates for single-trial, ORT analysis of action onset and contents [8, 9], because of the tight temporal pairing of LFP to the underlying neuronal signals. Moreover, such recordings are known to be cleaner and more robust, with signal-to-noise ratios up to\\n100 times larger than surface recordings like EEG [10, 11]. We therefore took advantage of a rare\\nopportunity to work with epilepsy patients implanted with intracranial electrodes for clinical purposes. Our ORT system (Fig. 1) predicts, with far above chance accuracy, which one of two future\\nactions is about to occur on this one trial and feeds the prediction back to the experimenter, all\\nbefore the onset of the go signal that triggers the patient?s movement (see Experimental Methods).\\nWe achieve relatively high prediction performance using only part of the data?learning from brain\\nactivity in past trials only (Fig. 2) to predict future ones (Fig. 3)?while still running the analysis\\nquickly enough to act upon the prediction before the subject moved.\\n\\n2\\n2.1\\n\\nExperimental Methods\\nSubjects\\n\\nSubjects in this experiment were 8 consenting intractable epilepsy patients that were implanted with\\nintracranial electrodes as part of their presurgical clinical evaluation (ages 18?60, 3 males). They\\nwere inpatients in the neuro-telemetry ward at the Cedars Sinai Medical Center or the Huntington\\nMemorial Hospital, and are designated with CS or HMH after their patient numbers, respectively. Six\\nof them?P12CS, P15CS, P22CS and P29?31HMH were implanted with intracortical depth electrodes targeting their bilateral anterior-cingulate cortex, amygdala, hippocampus and orbitofrontal\\ncortex. These electrodes had eight 40 ?m microwires at their tips, 7 for recording and 1 serving as\\na local ground. Two patients, P15CS and P22CS, had additional microwires in the supplementary\\nmotor area. We utilized the LFP recorded from the microwires in this study. Two other patients,\\nP16CS and P19CS, were implanted with an 8?8 subdural grid (64 electrodes) over parts of their\\ntemporal and prefrontal dorsolateral cortices. The data of one patient?P31HMH?was excluded\\nbecause microwire signals were too noisy for meaningful analysis. The institutional review boards\\nof Cedars Sinai Medical Center, the Huntington Memorial Hospital and the California Institute of\\nTechnology approved the experiments.\\nDuring the experiment, the subject sat in a hospital bed in a semi-inclined ?lounge chair? position.\\nThe stimulus/analysis computer (bottom left of Fig. 4) displaying the game screen (bottom right\\ninset of Fig. 4) was positioned to be easily viewable for the subject. When playing against the\\nexperimenter, the latter sat beside the bed. The response box was placed within easy reach of the\\nsubject (Fig. 4).\\n2\\n\\n\\f2.2\\n\\nExperiment Design\\n\\nAs part of our focus on purposeful, reasoned action, we had the subjects play a matching-pennies\\ngame?a 2-choice version of ?rock paper scissors??either against the experimenter or against a\\ncomputer. The subjects pressed down a button with their left hand and another with their right on a\\nresponse box. Then, in each trial, there was a 5 s countdown followed by a go signal, after which\\nthey had to immediately lift one of their hands. It was agreed beforehand that the patient would win\\nthe trial if she lifted a different hand than her opponent, and lose if she raised the same hand as her\\nopponent. Both players started off with a fixed amount of money, $5, and in each trial $0.10 was\\ndeducted from the loser and awarded to the winner. If a player lifted her hand before the go signal,\\ndid not lift her hand within 500 ms of the go signal, or lifted no hand or both hands at the go signal?\\nan error trial?she lost $0.10 without her opponent gaining any money. The subjects were shown the\\ncountdown, the go signal, the overall score, and various instructions on a stimulus computer placed\\nbefore them (Fig. 4). Each game consisted of 50 trials. If, at the end of the game, the subject had\\nmore money than her opponent, she received that money in cash from the experimenter.\\nBefore the experimental session began, the experimenter explained the rules of the game to the subject, and she could practice playing the game until she was familiar with it. Consequently, patients\\nusually made only few errors during the games (<6% of the trials). Following the tutorial, the subject played 1?3 games against the computer and then once against the experimenter, depending on\\ntheir availability and clinical circumstances. The first 2 games of P12CS were removed because\\nthe subject tended to constantly raise the right hand regardless of winning or losing. Two patients,\\nP15CS and P19CS, were tested in actual ORT conditions. In such sessions?3 games each?the\\nsubjects always played against the experimenter. These ORT games were different from the other\\ngames in two respects. First, a computer screen was placed behind the patient, in a location where\\nshe could not see it. Second, the experimenter was wearing earphones (Fig. 1,4). Half a second before go-signal onset, an arrow pointing towards the hand that the system predicted the experimenter\\nhad to raise to win the trial was displayed on that screen. Simultaneously, a monophonic tone was\\nplayed in the experimenter?s earphone ipsilateral to that hand. The experimenter then lifted that hand\\nat the go signal (see Supplemental Movie).\\n\\nCheetah Machine\\nCollect\\nand save\\ndata\\n\\nPatient\\nwith intracranial electrodes\\n\\nDown\\nsampling\\n\\nBuffer\\n\\n1Gbps\\nRouter\\n\\nTTL Signal\\n\\nThe winner is\\nPlayer 1\\nPLAYER 1 PLAYER 2\\nSCORE 1\\n\\nAnalysis/stimulus machine\\n\\nSCORE 2\\n\\nResponse Box Game Screen\\n\\n/\\nExperimenter\\n\\nResult\\nInterpreta\\ntion\\n\\nAnalysis\\n\\nFiltering\\n\\nDisplay/Sound\\n\\nFigure 1: A schematic diagram of the on-line real-time (ORT) system. Neural signals flow from\\nthe patient through the Cheetah machine to the analysis/stimulus computer, which controls the input\\nand output of the game and computes the prediction of the hand the patient would raise at the go\\nsignal. It displays it on a screen behind the patient and informs the experimenter which hand to raise\\nby playing a tone in his ipsilateral ear using earphones.\\n\\n3\\n\\n\\f3\\n3.1\\n\\nThe real-time system\\nHardware and software overview\\n\\n?V\\n\\n?V\\n\\n?V\\n\\nNeural data from the intracranial electrodes were transferred to a recording system (Neuralynx,\\nDigital Lynx), where it was collected and saved to the local Cheetah machine, down sampled\\nfrom 32 kHz to 2 kHz and buffered. The data were then transferred, through a dedicated 1 Gbps\\nlocal-area network, to the analysis/stimulus machine. This computer first band-pass-filtered the\\ndata to the 0.1?5 Hz range (delta and lower theta bands) using a second-order zero-lag elliptic\\nfilter with an attenuation of 40 dB (cf. Figs. 2a and 2b). We found that this frequency range?\\ngenerally comparable to that of the readiness potential?resulted in optimal prediction performance.\\nIt then ran the analysis algorithm (see below) on the filtered data. This computer also controlled\\nthe game screen, displaying the names of the players, their current scores and various instructions.\\nThe analysis/stimulus computer further\\ncontrolled the response box, which con- (a)\\n800\\nsisted of 4 LED-lit buttons. The buttons of the subject and her opponent\\n600\\nflashed red or blue whenever she or her\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nopponent won, respectively. Addition(b)100\\nally, the analysis/stimulus computer sent\\n0\\na unique transistor-transistor logic (TTL)\\n?100\\n?200\\npulse whenever the game screen changed\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nor a button was pressed on the response\\nbox, which synchronized the timing of (c) 100\\n0\\nthese events with the LFP recordings.\\n?100\\nIn real-time game sessions, the analy?200\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nsis/stimulus computer also displayed the\\nappropriate arrow on the computer screen (d) 1\\nbehind the subject and played the tone\\n0\\nto the appropriate ear of the experimenter\\n?1\\n0.5 s before go-signal onset (Figs. 1,4).\\n?5\\n?4\\n?3\\n?2\\n?1\\n0\\nThe analysis software was based on a\\nmachine-learning algorithm that trained\\non past-trials data to predict the current\\ntrial and is detailed below. The training phase included the first 70% of the\\ntrials, with the prediction carried out on\\nthe remaining 30% using the trained parameters, together with an online weighting system (see below). The system examined only neural activity, and had no\\naccess to the subject?s left/right-choice\\nhistory. After filtering all the training\\ntrials (Fig. 2b), the system found the\\nmean and standard error over all leftward\\nand rightward training trials, separately\\n(Fig. 2c, left designated in red). It then\\nfound the electrodes and time windows\\nwhere the left/right separation was high\\n(Fig. 2d,e; see below), and trained the classifiers on these time windows (Fig. 2f?g).\\nThe best electrode/time-window/classifier\\n(ETC) combinations were then used to\\npredict the current trial in the prediction\\nphase (Fig. 3). The number of ETCs that\\ncan be actively monitored is currently limited to 10 due to the computational power\\nof the real-time system.\\n\\nEl 49?T1\\n\\n(e)\\n\\nEl 49?T2\\n\\nEl 49?T3\\n\\n1\\n0\\n?1\\n?5\\n\\n?4\\n\\n?3\\n?2\\n?1\\nCountdown to go signal at t=0 (seconds)\\n\\n0\\n\\n(f)\\nClassifier\\nCf1\\n\\nClassifier\\nCf2\\n\\n...\\n\\nClassifier\\nCf6\\n\\nEl 49?T1?Cf1\\nEl 49?T1?Cf2\\nEl 49?T1?Cf6\\n...\\nEl 49?T2?Cf1\\nEl 49?T2?Cf2\\nEl 49?T2?Cf6\\nEl 49?T3?Cf1\\nEl 49?T3?Cf2\\nEl 49?T3?Cf6\\n\\n(g)\\nCombination\\nEl49-T1-Cf2\\n\\nCombination\\nEl49-T2-Cf2\\n\\n...\\n\\nCombination\\nEl49-T2-Cf6\\n\\nFigure 2: The ORT-system?s training phase. Left (in\\nred) and right (in blue) raw signals (a) are low-pass filtered (b). Mean?standard errors of signals preceeding left- and right-hand movments (c) are used to compute a left/right separability index (d), from which time\\nwindows with good separation are found (e). Seven\\nclassifiers are then applied to all the time windows (f)\\nand the best electrode/time-window/classifier combinations are selected (g) and used in the prediction phase\\n(Fig. 3).\\n\\n4\\n\\n\\f?V\\n\\n100\\n0\\n?100\\n?200\\n?5\\n\\n?4\\n\\n?3\\n\\n?2\\n\\n?1\\n\\n0\\n\\nTrained classifiers\\n\\nCombination\\nE l 49?T1?Cf2\\n\\nCombination\\nE l 49?T2?Cf2\\n\\nWeight = 1\\n\\nWeight = 1\\n\\nCombination\\nE l 49?T2?Cf6\\n\\n&\\n\\nWeight = 1\\n\\nPredicted result\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nL\\n\\nR\\n\\nL\\n\\n&\\n\\nR\\n\\nL\\nReal result\\n\\nAdjust the weights\\n\\nL\\n\\n==\\n\\nFigure 3: The ORT-system?s prediction phase. A new signal?from 5 to 0.5 seconds before the\\ngo signal?is received in real time, and each electrode/time-window/classifier combination (ETC)\\nclassifies it as resulting in left- or right-hand movement. These predictions are then compared to the\\nactual hand movement, with the weights associated with ETCs that correctly (incorrectly) predicted\\nincreasing (decreasing).\\n\\n3.2\\n\\nComputing optimal left/right-separating time windows\\n\\nThe algorithm focused on finding the time windows with the best left/right separation for the different recording electrodes over the training set (Fig. 2c?e). That is, we wanted to predict whether\\nthe signal aN (t) on trial N will result in a leftward or rightward movement?i.e., whether the label of the N th trial will be Lt or Rt, respectively. For each electrode, we looked at the N ? 1\\nprevious trials a1 (t), a2 (t), . . . , aN ?1 (t), and their associated labels as l1 , l2 , . . . , lN ?1 . Now, let\\nN ?1\\n?1\\nL(t) = {ai (t) | li = Lt}N\\ni=1 and R(t) = {ai (t) | li = Rt}i=1 be the set of previous leftward and\\nrightward trials in the training set, respectively. Furthermore, let Lm (t) (Rm (t)) and Ls (t) (Rs (t))\\nbe the mean and standard error of L(t) (R(t)), respectively. We can now define the normalized\\nrelative left/right separation for each electrode at time t (see Fig. 2d):\\n?\\n[Lm (t) ? Ls (t)] ? [Rm (t) + Rs (t)]\\n?\\n?\\nif [Lm (t) ? Ls (t)] ? [Rm (t) + Rs (t)] > 0\\n?\\n?\\nLm (t) ? Rm (t)\\n?\\n?\\n?\\n?\\n?\\n[Rm (t) ? Rs (t)] ? [Lm (t) + Ls (t)]\\n?(t) =\\n?\\nif [Rm (t) ? Rs (t)] ? [Lm (t) + Ls (t)] > 0\\n?\\n?\\n?\\nRm (t) ? Lm (t)\\n?\\n?\\n?\\n?\\n?\\n?\\n0\\notherwise\\nThus, ?(t) > 0 (?(t) < 0) means that the leftward trials tend to be considerably higher (lower)\\nthan rightward trials for that electrode at time t, while ?(t) = 0 suggests no left/right separation at\\ntime t. We define a consecutive time period of |?(t)| > 0 for t < prediction time (the time before\\nthe go signal when we want the system to output a prediction; -0.5 s for the ORT trials) as a time\\nwindow (Fig. 2e). After all time windows are found for all electrodes, time windows lessRthan M ms\\nt\\napart are combined into one. Then, for each time window from t1 to t2 we define a = t12 |?(t)|dt.\\nWe then eliminate all time windows satisfying a < A. We found the values M = 200 ms and\\nA = 4, 500 ?V ? ms to be optimal for real-time analysis. This resulted in 20?30 time windows over\\nall 64 electrodes that we monitored.\\n5\\n\\n\\f1\\n$4.80\\n\\n$5.20\\n\\nP15CS\\n\\nUri\\n\\nFigure 4: The experimental setup in the clinic. At 400 ms before the go signal, the patient and\\nexperimenter are watching the game screen (inset on bottom right) on the analysis/stimulus computer\\n(bottom left) and still pressing down the buttons of the response box. The realtime system already\\ncomputed a prediction, and thus displays an arrow on the screen behind the patient and plays a tone\\nin the experimenter?s ear ipsilateral to the hand it predicts he should raise to beat the patient (see\\nSupplemental Movie).\\n3.3\\n\\nClassifiers selection and ETC determination\\n\\nWe used ensemble learning with 7 types of relatively simple binary classifiers (due to real-time\\nprocessing considerations) on every electrode?s time windows (Fig. 2f). Classifiers A to G would\\nclassify aN (t) as Lt if:\\nP\\nP\\nP\\n(A) Defining aN,M , Lm,M and Rm,M as aN (t), Lm (t) and Rm (t) over time window M ,\\n\\u0001\\n\\u0001\\n\\u0001\\n(i) sign Rm,M 6= sign aN,M = sign Lm,M , or\\n\\f\\n\\f\\n\\f \\f\\n\\u0001\\n\\u0001\\n\\u0001\\n(ii) sign Rm,M = sign aN,M = sign Lm,M and \\fLm,M \\f > \\fRm,M \\f, or\\n\\f\\n\\f\\n\\f \\f\\n\\u0001\\n\\u0001\\n\\u0001\\n(iii) sign Rm (t) 6= sign SN,M 6= sign Lm (t) and \\fLm,M \\f < \\fRm,M \\f;\\n\\f\\n\\u0001\\n\\u0001\\f \\f\\n\\u0001\\n\\u0001\\f\\n(B) \\fmean aN (t) ? mean Lm (t) \\f < \\fmean aN (t) ? mean Rm (t) \\f;\\n\\f\\n\\f\\n\\u0001\\n\\u0001\\f\\n\\u0001\\n\\u0001\\f\\n(C) \\fmedian aN (t) ? median Lm (t) \\f < \\fmedian aN (t) ? median Rm (t) \\f over the time\\nwindow;\\n\\f\\n\\f\\n\\f\\n\\f\\n\\f\\n(D) aN (t) ? Lm (t)\\fL2 < \\faN (t) ? Rm (t)\\fL2 over the time window;\\n(E) aN (t) is convex/concave like Lm (t) while Rm (t) is concave/convex, respectively;\\n(F) Linear support-vector machine (SVM) designates it as so; and\\n(G) k-nearest neighbors (KNN) with Euclidean distance designates it as so.\\nEach classifier is optimized for certain types of features. To estimate how well its classification\\nwould generalize from the training to the test set, we trained and tested it using a 70/30 crossvalidation procedure within the training set. We tested each classifier on every time window of every\\nelectrode, discarding those with accuracy <0.68, which left 12.0 ? 1.6% of the original 232 ? 18\\nETCs, on average (?standard error). The training phase therefore ultimately output a set of S binary\\nETC combinations (Fig. 2g) that were used in the prediction phase (Fig. 3).\\n3.4\\n\\nThe prediction-phase weighting system\\n\\nIn the prediction phase, each of the overall S binary ETCs calculates a prediction, ci ? {?1, 1} (for\\nright and left, respectively), independently at the desired prediction time. All classifiers are initially\\n6\\n\\n\\fPS\\ngiven the same weight, w1 = w2 = ? ? ? = wS = 1. We then calculate ? = i=1 wi ? ci and predict\\nleft (right) if ? > d (? < ?d), or declare it an undetermined trial if ?d < ? < d. Here d is the\\ndrop-off threshold for the prediction. Thus the larger d is, the more confident the system needs to be\\nto make a prediction, and the larger the proportion of trials on which the system abstains?the dropoff rate. Weight wi associated with ETCi is increased (decreased) by 0.1 whenever ETCi predicts\\nthe hand movement correctly (incorrectly). A constantly erring ETC would therefore be associated\\nwith an increasingly small and then increasingly negative weight.\\n3.5\\n\\nImplementation\\n\\nThe algorithm was implemented in MATLAB 2011a (MathWorks, Natick, MA) as well as in C++\\non Visual Studio 2008 (Microsoft, Redmond, WA) for enhanced performance. The neural signals\\nwere collected by the Digital Lynx S system using Cheetah 5.4.0 (Neuralynx, Redmond, WA). The\\nsimulated-ORT system was also implemented in MATLAB 2011a. The simulated-ORT analyses\\ncarried out in this paper used real patient data saved on the Digital Lynx system.\\n1\\n\\n0.9\\n\\nDrop rate:\\nNone\\n0.18\\n0\\u0011\\u0016\\u0013\\n\\nPrediction accuracy\\n\\n0.8\\n\\n0.7\\nSignificant accuracy\\n(p=0.05)\\n0.6\\n\\n0.5\\n\\n?5\\n\\n?4.5\\n\\n?4\\n\\n?3.5\\n\\n?3\\n\\n?2.5\\nTime (s)\\n\\n?2\\n\\n?1.5\\n\\n?1\\n\\n?0.5\\n\\n0\\nGo-signal\\nonset\\n\\nFigure 5: Across-subjects average of the prediction accuracy of simulated-ORT versus time before\\nthe go signal. The mean accuracies over time when the system predicts on every trial, is allowed\\nto drop 19% or 30% of the trials, are depicted in blue, green and red, respectively (?standard error\\nshaded). Values above the dashed horizontal line are significant at p = 0.05.\\n\\n4\\n\\nResults\\n\\nWe tested our prediction system in actual real time on 2 patients?P15CS and P19CS (a depth\\nand grid patient, respectively), with a prediction time of 0.5 s before the go signal (see Supplementary Movie). Because of computational limitations, the ORT system could only track 10\\nelectrodes with just 1 ETC per electrode in real time. For P15CS, we achieved an accuracy of\\n72?2% (?standard error; accuracy = number of accurately predicted trials / [total number of trials - number of dropped trials]; p = 10?8 , binomial test) without modifying the weights online during the prediction (see Section 3.4). For P19CS we did not run patient-specific training of the ORT system, and used parameter values that were good on average over previous patients instead. The prediction accuracy was significantly above chance 63?2% (?standard error; p = 7 ? 10?4 , binomial test). To understand how much we could improve our accuracy\\nwith optimized hardware/software, we ran the simulated-ORT at various prediction times along\\n7\\n\\n\\fAccuracy\\n\\nthe 5 s countdown leading to the go signal. We further tested 3 drop-off rates?0, 0.19 and\\n0.30 (Fig. 5; drop-off rate = number of dropped trials / total number of trials; these resulted\\nfrom 3 drop-off thresholds?0, 0.1 and 0.2?respectively, see Section 3.4:). Running offline,\\nwe were able to track 20?30 ETCs, which resulted in considerably higher accuracies (Figs. 5,6).\\nAveraged over all subjects, the accuracy rose from about 65% more than\\n1\\n4 s before the go signal to 83?92%\\nclose to go-signal onset, depending\\n0.9\\non the allowed drop-off rate. In particular, we found that for a predic0.8\\ntion time of 0.5 s before go-signal\\nonset, we could achieve accuracies\\n0.7\\nof 81?5% and 90?3% (?standard\\nerror) for P15CS and P19CS, re0.6\\nspectively, with no drop off (Fig. 6).\\nPatients:\\nP12CS\\nWe also analyzed the weights that\\nP15CS\\nour weighting system assigned to the\\n0.5\\nP16CS\\nP19CS\\ndifferent ETCs. We found that the\\nP22CS\\nempirical distribution of weights to\\nP29HMH\\n0.4\\nP30HMH\\nETCs associated with classifiers A to\\nG was, on average: 0.15, 0.12, 0.16,\\n?5 ?4.5 ?4 ?3.5 ?3 ?2.5 ?2 ?1.5 ?1 ?0.5 0\\n0.22, 0.01, 0.26 and 0.07, respecTime before go signal (at t=0) (seconds)\\ntively. This suggests that the linear\\nSVM and L2-norm comparisons (of\\naN to Lm and Rm ) together make up Figure 6: Simulated-ORT accuracy over time for individual\\nnearly half of the overall weights at- patients with no drop off.\\ntributed to the classifiers, while the\\ncurrent concave/convex measure is of\\nlittle use as a classifier.\\n\\n5\\n\\nDiscussion\\n\\nWe constructed an ORT system that, based on intracranial recordings, predicted which hand a person would raise well before movement onset at accuracies much greater than chance in a competitive environment. We further tested this system off-line, which suggested that with optimized\\nhardware/software, such action contents would be predictable in real time at relatively high accuracies already several seconds before movement onset. Both our prediction accuracy and drop-off\\nrates close to movement onset are superior to those achieved before movement onset with noninvasive methods like EEG and fMRI [7, 12?14]. Importantly, our subjects played a matching pennies game?a 2-choice version of rock-paper-scissors [15]?to keep their task realistic, with minor\\nthough real consequences, unlike the Libet-type paradigms whose outcome bears no consequences\\nfor the subjects. It was suggested that accurate online, real-time prediction before movement onset\\nis key to investigating the relation between the neural correlates of decisions, their awareness, and\\nvoluntary action [16, 17]. Such prediction capabilities would facilitate many types of experiments\\nthat are currently infeasible. For example, it would make it possible to study decision reversals on\\na single-trial basis, or to test whether subjects can guess above chance which of their action contents are predictable from their current brain activity, potentially before having consciously made up\\ntheir mind [16, 18]. Accurately decoding these preparatory motor signals may also result in earlier\\nand improved classification for brain-computer interfaces [13, 19, 20]. The work we present here\\nsuggests that such ORT analysis might well be possible.\\nAcknowledgements\\nWe thank Ueli Rutishauser, Regan Blythe Towel, Liad Mudrik and Ralph Adolphs for meaningful\\ndiscussions. This research was supported by the Ralph Schlaeger Charitable Foundation, Florida\\nState University?s ?Big Questions in Free Will? initiative and the G. Harold & Leila Y. Mathers\\nCharitable Foundation.\\n8\\n\\n\\fReferences\\n[1] B. Libet, C. Gleason, E. Wright, and D. Pearl. Time of conscious intention to act in relation to\\nonset of cerebral activity (readiness-potential): The unconscious initiation of a freely voluntary\\nact. Brain, 106:623, 1983.\\n[2] B. Libet. Unconscious cerebral initiative and the role of conscious will in voluntary action.\\nBehavioral and brain sciences, 8:529?539, 1985.\\n[3] P. Haggard and M. Eimer. On the relation between brain potentials and the awareness of\\nvoluntary movements. Experimental Brain Research, 126:128?133, 1999.\\n[4] A. Sirigu, E. Daprati, S. Ciancia, P. Giraux, N. Nighoghossian, A. Posada, and P. Haggard.\\nAltered awareness of voluntary action after damage to the parietal cortex. Nature Neuroscience,\\n7:80?84, 2003.\\n[5] H. Kornhuber and L. Deecke. Hirnpotenti?alanderungen bei Willk?urbewegungen und passiven\\nBewegungen des Menschen: Bereitschaftspotential und reafferente Potentiale. Pfl?ugers Archiv\\nEuropean Journal of Physiology, 284:1?17, 1965.\\n[6] H. Shibasaki and M. Hallett. What is the Bereitschaftspotential? Clinical Neurophysiology,\\n117:2341?2356, 2006.\\n[7] C. Soon, M. Brass, H. Heinze, and J. Haynes. Unconscious determinants of free decisions in\\nthe human brain. Nature Neuroscience, 11:543?545, 2008.\\n[8] I. Fried, R. Mukamel, and G. Kreiman. Internally generated preactivation of single neurons in\\nhuman medial frontal cortex predicts volition. Neuron, 69:548?562, 2011.\\n[9] M. Cerf, N. Thiruvengadam, F. Mormann, A. Kraskov, R. Quian Quiorga, C. Koch, and\\nI. Fried. On-line, voluntary control of human temporal lobe neurons. Nature, 467:1104?1108,\\n2010.\\n[10] T. Ball, M. Kern, I. Mutschler, A. Aertsen, and A. Schulze-Bonhage. Signal quality of simultaneously recorded invasive and non-invasive EEG. Neuroimage, 46:708?716, 2009.\\n[11] G. Schalk, J. Kubanek, K. Miller, N. Anderson, E. Leuthardt, J. Ojemann, D. Limbrick,\\nD. Moran, L. Gerhardt, and J. Wolpaw. Decoding two-dimensional movement trajectories\\nusing electrocorticographic signals in humans. Journal of Neural engineering, 4:264, 2007.\\n[12] O. Bai, V. Rathi, P. Lin, D. Huang, H. Battapady, D. Y. Fei, L. Schneider, E. Houdayer, X. Chen,\\nand M. Hallett. Prediction of human voluntary movement before it occurs. Clinical Neurophysiology, 122:364?372, 2011.\\n[13] O. Bai, P. Lin, S. Vorbach, J. Li, S. Furlani, and M. Hallett. Exploration of computational\\nmethods for classification of movement intention during human voluntary movement from\\nsingle trial EEG. Clinical Neurophysiology, 118:2637?2655, 2007.\\n[14] U. Maoz, A. Arieli, S. Ullman, and C. Koch. Using single-trial EEG data to predict laterality\\nof voluntary motor decisions. Society for Neuroscience, 38:289.6, 2008.\\n[15] C. Camerer. Behavioral game theory: Experiments in strategic interaction. Princeton University Press, 2003.\\n[16] J. D. Haynes. Decoding and predicting intentions. Annals of the New York Academy of Sciences, 1224:9?21, 2011.\\n[17] P. Haggard. Decision time for free will. Neuron, 69:404?406, 2011.\\n[18] J. D. Haynes. Beyond libet. In W. Sinnott-Armstrong and L. Nadel, editors, Conscious will\\nand responsibility, pages 85?96. Oxford University Press, 2011.\\n[19] A. Muralidharan, J. Chae, and D. M. Taylor. Extracting attempted hand movements from EEGs\\nin people with complete hand paralysis following stroke. Frontiers in neuroscience, 5, 2011.\\n[20] E. Lew, R. Chavarriaga, S. Silvoni, and J. R. Milln. Detection of self-paced reaching movement\\nintention from EEG signals. Frontiers in Neuroengineering, 5:13, 2012.\\n\\n9\\n\\n\\f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Open the zip file\n",
        "with zipfile.ZipFile(\"./NIPS Papers.zip\", \"r\") as zip_ref:\n",
        "    # Extract the file to a temporary directory\n",
        "    zip_ref.extractall(\"temp\")\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "papers = pd.read_csv(\"temp/NIPS Papers/papers.csv\")\n",
        "\n",
        "# Print head\n",
        "papers.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9XmVkuA2Wpy"
      },
      "source": [
        "** **\n",
        "#### Step 2: Data Cleaning\n",
        "** **\n",
        "\n",
        "Since the goal of this analysis is to perform topic modeling, we will solely focus on the text data from each paper, and drop other metadata columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yGQKCxeh2Wpy",
        "outputId": "33d85bfe-3d67-4ce6-8bb4-87f514e35f4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             paper_text\n",
              "3412  Interval Estimation for Reinforcement-Learning...\n",
              "274   Effective Training of a Neural Network\\nCharac...\n",
              "2741  Privacy-preserving logistic regression\\n\\nKama...\n",
              "3338  Latent Variable Models for Predicting File\\nDe...\n",
              "3954  A Connectionist Learning Approach to Analyzing..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54642419-19e7-40cf-b41e-93bfd3aecaff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3412</th>\n",
              "      <td>Interval Estimation for Reinforcement-Learning...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>Effective Training of a Neural Network\\nCharac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2741</th>\n",
              "      <td>Privacy-preserving logistic regression\\n\\nKama...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3338</th>\n",
              "      <td>Latent Variable Models for Predicting File\\nDe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3954</th>\n",
              "      <td>A Connectionist Learning Approach to Analyzing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54642419-19e7-40cf-b41e-93bfd3aecaff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-54642419-19e7-40cf-b41e-93bfd3aecaff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-54642419-19e7-40cf-b41e-93bfd3aecaff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a030d563-8b11-430d-9f44-5dd7d7c9588f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a030d563-8b11-430d-9f44-5dd7d7c9588f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a030d563-8b11-430d-9f44-5dd7d7c9588f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "papers",
              "summary": "{\n  \"name\": \"papers\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"paper_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Learning continuous distributions:\\nSimulations with field theoretic priors\\n\\nlIya Nemenman1 ,2 and William Bialek2\\nof Physics, Princeton University, Princeton, New Jersey 08544\\n2NEC Research Institute, 4 Independence Way, Princeton, New Jersey 08540\\nnemenman@research.nj.nec.com, bialek@research.nj.nec.com\\n1 Department\\n\\nAbstract\\nLearning of a smooth but nonparametric probability density can be regularized using methods of Quantum Field Theory. We implement a field\\ntheoretic prior numerically, test its efficacy, and show that the free parameter of the theory (,smoothness scale') can be determined self consistently by the data; this forms an infinite dimensional generalization of\\nthe MDL principle. Finally, we study the implications of one's choice\\nof the prior and the parameterization and conclude that the smoothness\\nscale determination makes density estimation very weakly sensitive to\\nthe choice of the prior, and that even wrong choices can be advantageous\\nfor small data sets.\\nOne of the central problems in learning is to balance 'goodness of fit' criteria against the\\ncomplexity of models. An important development in the Bayesian approach was thus the\\nrealization that there does not need to be any extra penalty for model complexity: if we\\ncompute the total probability that data are generated by a model, there is a factor from the\\nvolume in parameter space-the 'Occam factor' -that discriminates against models with\\nmore parameters [1, 2]. This works remarkably welJ for systems with a finite number of\\nparameters and creates a complexity 'razor' (after 'Occam's razor') that is almost equivalent to the celebrated Minimal Description Length (MDL) principle [3]. In addition, if\\nthe a priori distributions involved are strictly Gaussian, the ideas have also been proven to\\napply to some infinite-dimensional (nonparametric) problems [4]. It is not clear, however,\\nwhat happens if we leave the finite dimensional setting to consider nonparametric problems which are not Gaussian, such as the estimation of a smooth probability density. A\\npossible route to progress on the nonparametric problem was opened by noticing [5] that\\na Bayesian prior for density estimation is equivalent to a quantum field theory (QFT). In\\nparticular, there are field theoretic methods for computing the infinite dimensional analog\\nof the Occam factor, at least asymptotically for large numbers of examples. These observations have led to a number of papers [6, 7, 8, 9] exploring alternative formulations and\\ntheir implications for the speed of learning. Here we return to the original formulation\\nof Ref. [5] and use numerical methods to address some of the questions left open by the\\nanalytic work [10]: What is the result of balancing the infinite dimensional Occam factor\\nagainst the goodness of fit? Is the QFT inference optimal in using alJ of the information\\nrelevant for learning [II]? What happens if our learning problem is strongly atypical of the\\nprior distribution?\\nFollowing Ref. [5], if N i. i. d. samples {Xi}, i\\n\\n= 1 ... N, are observed, then the probability\\n\\n\\fthat a particular density Q(x) gave rise to these data is given by\\n\\nP[Q(x)l{x.}] P[Q(x)] rr~1 Q(Xi)\\n? - J[dQ(x)]P[Q(x)] rr~1 Q(Xi) ,\\n\\n(1)\\n\\nwhere P[Q(x)] encodes our a priori expectations of Q. Specifying this prior on a space of\\nfunctions defines a QFf, and the optimal least square estimator is then\\n\\nQ (I{ .}) - (Q(X)Q(Xl)Q(X2) ... Q(XN)}(O)\\nest X X.\\n(Q(Xl)Q(X2) ... Q(XN ))(0) ,\\n\\n(2)\\n\\nwhere ( ... )(0) means averaging with respect to the prior. Since Q(x) ~ 0, it is convenient\\nto define an unconstrained field ?(x), Q(x)\\n(l/io)exp[-?(x)]. Other definitions are\\nalso possible [6], but we think that most of our results do not depend on this choice.\\n\\n=\\n\\nThe next step is to select a prior that regularizes the infinite number of degrees of freedom\\nand allows learning. We want the prior P[?] to make sense as a continuous theory, independent of discretization of x on small scales. We also require that when we estimate the\\ndistribution Q(x) the answer must be everywhere finite. These conditions imply that our\\nfield theory must be convergent at small length scales. For x in one dimension, a minimal\\nchoice is\\n\\nP[?(x)]\\n\\n1\\n\\n11 1\\n= Z exp [?2\\n--2-\\n\\nf (8\\ndx\\n\\n[1 f\\n\\n11\\n8xll?)2] c5 io\\n\\n]\\n\\ndxe-?(x) -1 ,\\n\\n(3)\\n\\nwhere'T/ > 1/2, Z is the normalization constant, and the c5-function enforces normalization\\nof Q. We refer to i and 'T/ as the smoothness scale and the exponent, respectively.\\nIn [5] this theory was solved for large Nand 'T/ = 1:\\n\\nN\\n\\n(II Q(Xi))(O)\\n\\n~\\n\\n(4)\\n\\n=\\n\\n(5)\\n\\n+\\n\\n(6)\\n\\ni=1\\nSeff\\n\\ni8;?c1 (x)\\n\\nwhere ?cl is the 'classical' (maximum likelihood, saddle point) solution. In the effective\\naction [Eq. (5)], it is the square root term that arises from integrating over fluctuations\\naround the classical solution (Occam factors). It was shown that Eq. (4) is nonsingular\\neven at finite N, that the mean value of ?c1 converges to the negative logarithm of the\\ntarget distribution P(x) very quickly, and that the variance of fluctuations 'Ij;(x)\\n?(x) [- log ioP( x)] falls off as ....., 1/ iN P( x). Finally, it was speculated that if the actual i is\\nunknown one may average over it and hope that, much as in Bayesian model selection [2],\\nthe competition between the data and the fluctuations will select the optimal smoothness\\nscale i*.\\n\\nJ\\n\\n=\\n\\nAt the first glance the theory seems to look almost exactly like a Gaussian Process [4]. This\\nimpression is produced by a Gaussian form of the smoothness penalty in Eq. (3), and by\\nthe fluctuation determinant that plays against the goodness of fit in the smoothness scale\\n(model) selection. However, both similarities are incomplete. The Gaussian penalty in\\nthe prior is amended by the normalization constraint, which gives rise to the exponential\\nterm in Eq. (6), and violates many familiar results that hold for Gaussian Processes, the\\n\\n\\frepresenter theorem [12] being just one of them. In the semi--classical limit of large N,\\nGaussianity is restored approximately, but the classical solution is extremely non-trivial,\\nand the fluctuation determinant is only the leading term of the Occam's razor, not the complete razor as it is for a Gaussian Process. In addition, it has no data dependence and is thus\\nremarkably different from the usual determinants arising in the literature.\\nThe algorithm to implement the discussed density estimation procedure numerically is\\nrather simple. First, to make the problem well posed [10, 11] we confine x to a box\\na ~ x ~ L with periodic boundary conditions. The boundary value problem Eq. (6) is\\nthen solved by a standard 'relaxation' (or Newton) method of iterative improvements to\\na guessed solution [13] (the target precision is always 10- 5 ). The independent variable\\nx E [0,1] is discretized in equal steps [10 4 for Figs. (l.a-2.b), and 105 for Figs. (3.a, 3.b)].\\nWe use an equally spaced grid to ensure stability of the method, while small step sizes are\\nneeded since the scale for variation of ?el (x) is [5]\\n(7)\\n\\nc5x '\\\" Jl/NP(x) ,\\nwhich can be rather small for large N or smalll.\\n\\nSince the theory is short scale insensitive, we can generate random probability densities\\nchosen from the prior by replacing ? with its Fourier series and truncating the latter at some\\nsufficiently high wavenumber kc [k c = 1000 for Figs. (l.a-2.b), and 5000 for Figs. (3.a,\\n3.b)]. Then Eq. (3) enforces the amplitude of the k'th mode to be distributed a priori\\nnormally with the standard deviation\\n21 / 2\\n\\nuk\\n\\n= l'l/-1/2\\n\\n(L)\\n\\n'1/\\n\\n27rk\\n\\n(8)\\n\\nCoded in such a way, the simulations are extremely computationally intensive. Therefore, Monte Carlo averagings given here are only over 500 runs, fluctuation determinants are calculated according to Eq. (5), not using numerical path integration, and\\nQcl = (l/lo) eXP[-?ed is always used as an approximation to Qest.\\nAs an example of the algorithm's performance, Fig. (l.a) shows one particular learning run\\nfor TJ = 1 and l = 0.2. We see that singularities and overfitting are absent even for N as\\nlow as 10. Moreover, the approach of Qel(X) to the actual distribution P(x) is remarkably\\nfast: for N = 10, they are similar; for N = 1000, very close; for N = 100000, one needs\\nto look carefully to see the difference between the two.\\nTo quantify this similarity of distributions, we compute the Kullback-Leibler divergence\\nDKL(PIIQest) between the true distribution P(x) and its estimate Qest(x), and then average over the realizations of the data points and the true distribution. As discussed in\\n[11], this learning curve A(N) measures the (average) excess cost incurred in coding the\\nN + 1 'st data point because of the finiteness of the data sample, and thus can be called the\\n\\\"universalleaming curve\\\". If the inference algorithm uses all of the information contained\\nin the data that is relevant for learning (\\\"predictive information\\\" [11]), then [5, 9, 11, 10]\\n\\nA(N) '\\\" (L/l)1/2'1/N1/2'1/- 1.\\n\\n(9)\\n\\nWe test this prediction against the learning curves in the actual simulations. For TJ = 1\\nand l = 0.4, 0.2, 0.05, these are shown on Fig. (l.b). One sees that the exponents are\\nextremely close to the expected 1/2, and the ratios of the prefactors are within the errors\\nfrom the predicted scaling'\\\" 1/Vi. All of this means that the proposed algorithm for\\nfinding densities not only works, but is at most a constant factor away from being optimal\\nin using the predictive information of the sample set.\\nNext we investigate how one's choice of the prior influences learning. We first stress that\\nthere is no such thing as a wrong prior. If one admits a possibility of it being wrong, then\\n\\n\\f(a)\\n\\n(b)\\n\\n3.5\\n3\\n\\n10'\\n\\nFit for 10 samples\\nFit for 1000 samples\\n- - - Fit for 100000 samples\\nActual distribution\\n\\n- e~\\n\\n, ..\\n\\n2.5\\n\\n:s::\\nCl\\n\\n10-'\\n2\\n\\n~\\nO'i ?5\\n\\n... . . .\\n\\n~'\\n\\n. \\\"0\\\",\\n\\n<\\n\\no.\\n\\n..\\n\\n.\\no?\\n\\n..\\n\\\"'-\\n\\n10-'\\n\\n'0.\\n\\n\\\".\\n? 0\\n\\n'.\\n\\n\\\".\\n\\n0.5\\n0\\n0\\n\\n-<>~.\\n\\n1=0.4, data and best fit\\n1=0.2 , data and best fit\\n1=0.05 , data and best fit\\n\\n10-'\\n0.2\\n\\n0.4\\n\\n0.6\\n\\nx\\n\\n0.8\\n\\n10'\\n\\n10'\\n\\n10'\\nN\\n\\n10'\\n\\n10'\\n\\nFigure 1: (a) QcJ found for different N at f = 0.2. (b) A as a function of N and f.\\nThe best fits are: for f = 0.4, A = (0.54 ? 0.07)N-o. 4 83?O.014; for f = 0.2, A =\\n(0.83 ? 0.08)N- o.493 ?O.09; for f = 0.05, A = (1.64 ? 0.16)N- o.50 7?O.09.\\n\\nit does not encode all of the a priori knowledge! It does make sense, however, to ask what\\nhappens if the distribution we are trying to learn is an extreme outlier in the prior P[?].\\nOne way to generate such an example is to choose a typical function from a different prior\\nPI[?], and this is what we mean by 'learning with a wrong prior.' If the prior is wrong\\nin this sense, and learning is described by Eqs. (2-6), then we still expect the asymptotic\\nbehavior, Eq. (9), to hold; only the prefactors of A should change, and those must increase\\nsince there is an obvious advantage in having the right prior; we illustrate this in Figs. (2.a,\\n2.b).\\nFor Fig. (2.a), both PI[?] and P[?] are given by Eq. (3), but pI has the 'actual' smoothness\\nscale fa = 0.4, 0.05, and for P the ' learning' smoothness scale is f = 0.2 (we show the\\ncase fa = f = 0.2 again as a reference). The A,...., l/VN behavior is seen unmistakably.\\nThe prefactors are a bit larger (unfortunately, insignificantly) than the corresponding ones\\nfrom Fig. (1.b), so we may expect that the 'right' f, indeed, provides better learning (see\\nlater for a detailed discussion).\\nFurther, Fig. (2.b) illustrates learning when not only f, but also 'fI is 'wrong' in the sense\\ndefined above. We illustrate this for 'fIa = 2, 0.8, 0.6, 0 (remember that only 'fIa > 0.5\\nremoves UV divergences). Again, the inverse square root decay of A should be observed,\\nand this is evident for 'fIa = 2. The 'fIa = 0.8,0.6,0 cases are different: even for N as high\\nas 105 the estimate of the distribution is far from the target, thus the asymptotic regime is\\nnot reached. This is a crucial observation for our subsequent analysis of the smoothness\\nscale determination from the data. Remarkably, A (both averaged and in the single runs\\nshown) is monotonic, so even in the cases of qualitatively less smooth distributions there\\nstill is no overfitting. On the other hand, A is well above the asymptote for 'fI = 2 and small\\nN , which means that initially too many details are expected and wrongfully introduced into\\nthe estimate, but then they are almost immediately (N ,...., 300) eliminated by the data.\\nFollowing the argument suggested in [5], we now view P[?], Eq. (3), as being a part of\\nsome wider model that involves a prior over l. The details of the prior are irrelevant,\\nhowever, if 8 e ff(f), Eq. (5), has a minimum that becomes more prominent as N grows. We\\nexplicitly note that this mechanism is not tuning of the prior's parameters, but Bayesian\\ninference at work: f* emerges in a competition between the smoothness, the data, and the\\nOccam terms to make 8 e ff smaller, and thus the total probability of the data is larger. In its\\n\\n\\f(a)\\n\\n(b)\\n\\n10'\\n0\\\"',\\n0,\\n\\n10-'\\n\\n'\\\"\\n\\n. .\\n0'\\n\\n<\\n\\n0 - _\\n\\n0,\\n'~\\n\\n'0\\n\\n0,\\n\\n'\\\",\\n\\n10-'\\n\\n- 0-\\n\\n- e-\\n\\n10-'\\n10'\\n\\n10'\\nN\\n\\n'0,\\n\\n10?\\n\\n'0- ,\\n\\n______ 11a=1, '.=0.2, data, best fit\\n10-3 - 9 - 11 a =2, '. =O.l , data, best fit\\nTJ. =0.8, '. =0.1, data, best fit\\n- 0TJ.=0.6, '. =0.1 , data, one run\\n10-4\\nTJ.=O, '. =0.12, data, one run\\n6\\n\\n\\\"',\\n\\n'.=0.2, data and best fit\\n'.=0.4, data and best fit\\n'. =0 .05 , data and best fit\\n\\n10'\\n\\n< 10-'\\n\\n'0\\n\\n'Q.\\n\\n10'\\n\\n10'\\n\\n10'\\n\\n10'\\n\\n''',\\n\\n10?\\n\\n\\\"'\\\"\\n\\n10'\\n\\nN\\n\\nFigure 2: (a) A as a function of N and fa. Best fits are: for fa = 0.4, A = (0.56 ?\\n0.08)N- o.47 7?O.015; for fa = 0.05, A = (1.90 ? 0.16)N- o.502 ?o.oo8. Learning is always\\nwith f = 0.2. (b) A as a function of N, 1/a and fa. Best fits: for 1/a = 2, fa = 0.1,\\nA = (0.40?0.05)N-o.4 93?O.013; for1/a = 0.8, fa = 0.1, A = (1.06?0.08)N-o.355?O.008.\\nf = 0.2 for all graphs, but the one with 1/a = 0, for which f = 0.1.\\nturn, larger probability means shorter total code length.\\nThe data term, on average, is equal to NDKL(PIIQc1), and, for very regular P(x) (an\\nimplicit assumption in [5]), it is small. Thus only the kinetic and the Occam terms matter,\\nand f* ,..., N 1 /3[5]. For less regular distributions P(x), this is not true [cf. Fig. (2.b)]. For\\n1/ = 1, Qc1(X) approximates large-scale features of P(x) very well, but details at scales\\nsmaller than,..., Jf/NL are averaged out. If P(x) is taken from the prior, Eq. (3), with\\nsome 1/a, then these details fall off with the wave number k as ,..., k-'T/a. Thus the data term\\nis,..., N1.5-'T/ a f'T/ a - O. 5 and is not necessarily small. For 1/a < 1.5 this dominates the kinetic\\nterm and competes with the fluctuations to set\\n\\nf* ,..., N('T/a- 1 )/'T/a,\\n\\n1/a\\n\\n< 1.5.\\n\\n(10)\\n\\nThere are two remarkable things about Eq. (10). First, for 1/a = 1, f* stabilizes at some\\nconstant value, which we expect to be equal to fa. Second, even for 1/ f:. 1/a, Eqs. (9, 10)\\nensure that A scales as ,..., N 1 / 2 'T/ a -1 , which is at worst a constant factor away from the best\\nscaling, Eq. (9), achievable with the 'right' prior, 1/ = 1/a. So, by allowing f* to vary with\\nN we can correctly capture the structure of models that are qualitatively different from our\\nexpectations (1/ f:. 1/a) and produce estimates of Q that are extremely robust to the choice\\nof the prior. To our knowledge, this feature has not been noted before in a reference to a\\nnonparametric problem.\\nWe present simulations relevant to these predictions in Figs. (3.a, 3.b). Unlike on the previous Figures, the results are not averaged due to extreme computational costs, so all our\\nfurther claims have to be taken cautiously. On the other hand, selecting f* in single runs\\nhas some practical advantages: we are able to ensure the best possible learning for any\\nrealization of the data. Fig. (3.a) shows single learning runs for various 1/a and fa . In addition, to keep the Figure readable, we do not show runs with 1/a = 0.6, 0.7, 1.2, 1.5,3,\\nand 1/a -+ 00, which is a finitely parameterizable distribution. All of these display a good\\nagreement with the predicted scalings: Eq. (10) for 1/a < 1.5, and f* ,..., N 1 /3 otherwise.\\nNext we calculate the KL divergence between the target and the estimate at f = f*; the\\naverage of this divergence over the samples and the prior is the learning curve [cf. Eq. (9)].\\nFor 1/a = 0.8,2 we plot the divergencies on Fig. (3.b) side by side with their fixed f = 0.2\\n\\n\\f(a)\\n\\n(b)\\n10' ,-----~-----~----~\\n\\n,-------:c---.----.--\\\".,-- - - - - - - - ,\\n0 .2\\n10-2 --+--11a- 1 ,\\n\\n'a-\\n\\n\\\"0.. - - -0- _ _\\n\\n~_\\n\\n~ '1.=0.8.1.=0.1. I=f\\n10-4 ~ '1.=0.8. 1.=0.1. 1=0.2\\n_ 0 _ '1.=2. 1.=0.1 . 1= f\\n_\\\" _ '1.=2 . 1.=0.1. 1=0.2\\n\\n\\\"\\\"-\\n\\n'1.=0.8. 1.=0.1\\n--<>- '1.=1. variable I?? mean 0.12\\no\\n'1.=2 . 1. =0 .1\\n\\n_ 0 -\\n\\n'0.\\n\\n10-3 l'=========='-_~_----.J\\n\\n1~\\n\\n1~\\n\\nN\\n\\n1~\\nN\\n\\nFigure 3: (a) Comparison of learning speed for the same data sets with different a priori\\nassumptions. (b) Smoothness scale selection by the data. The lines that go off the axis for\\nsmall N symbolize that Seff monotonically decreases as ? -+ 00.\\n\\nanalogues. Again, the predictions clearly are fulfilled. Note, that for 'TJa\\nqualitative advantage in using the data induced smoothness scale.\\n\\n:I\\n\\n'TJ there is a\\n\\nThe last four Figures have illustrated some aspects of learning with 'wrong' priors. However, all of our results may be considered as belonging to the 'wrong prior' class. Indeed,\\nthe actual probability distributions we used were not nonparametric continuous functions\\nwith smoothness constraints, but were composed of kc Fourier modes, thus had 2kc parameters. For finite parameterization, asymptotic properties of learning usually do not depend\\non the priors (cf. [3, 11]), and priorless theories can be considered [14]. In such theories\\nit would take well over 2kc samples to even start to close down on the actual value of the\\nparameters, and yet a lot more to get accurate results. However, using the wrong continuous parameterization [4>(x)] we were able to obtain good fits for as low as 1000 samples\\n[cf. Fig. (l.a)] with the help of the prior Eq. (3). Moreover, learning happened continuously\\nand monotonically without huge chaotic jumps of overfitting that necessarily accompany\\nany brute force parameter estimation method at low N. So, for some cases, a seemingly\\nmore complex model is actually easier to learn!\\nThus our claim: when data are scarce and the parameters are abundant, one gains even by\\nusing the regularizing powers of wrong priors. The priors select some large scale features\\nthat are the most important to learn first and fill in the details as more data become available\\n(see [11] on relation of this to the Structural Risk Minimization theory). If the global\\nfeatures are dominant (arguably, this is generic), one actually wins in the learning speed\\n[cf. Figs. (l.b, 2.a, 3.b)]. If, however, small scale details are as important, then one at least\\nis guaranteed to avoid overfitting [cf. Fig. (2.b)].\\nOne can summarize this in an Occam-like fashion [11]: if two models provide equally good\\nfits to data, a simpler one should always be used. In particular, the predictive information,\\nwhich quantifies complexity [11], and of which A is the derivative, in a QFT model is\\n......, N 1 / 2 TJ, and it is . . . , kc log N in the parametric case. So, for kc > N 1 / 2 TJ, one should\\nprefer a 'wrong' QFT formulation to the correct finite parameter model. These results are\\nvery much in the spirit of our whole program: not only is the value of ?* selected that\\nsimplifies the description of the data, but the continuous parameterization itself serves the\\nsame purpose. This is an unexpectedly neat generalization of the MDL principle [3] to\\nnon parametric cases.\\n\\n\\fSummary: The field theoretic approach to density estimation not only regularizes the learning process but also allows the self-consistent selection of smoothness criteria through an\\ninfinite dimensional version of the Occam factors. We have shown numerically that this\\nworks, even more clearly than was conjectured: for \\\"la < 1.5, the learning curve truly becomes a property of the data, and not of the Bayesian prior! If we can extend these results to\\nother \\\"la and combine this work with the reparameterization invariant formulation of [7, 8],\\nthis should give a complete theory of Bayesian learning for one dimensional distributions,\\nand this theory has no arbitrary parameters. In addition, if this theory properly treats the\\nlimit \\\"la -* 00, we should be able to see how the well-studied finite dimensional Occam\\nfactors and the MDL principle arise from a more general nonparametric formulation .\\n\\nReferences\\n[1] D. MacKay, Neural Compo 4,415-448 (1992).\\n[2] V. Balasubramanian, Neural Compo 9, 349-368 (1997),\\nhttp://xxx . lanl . gov/abs/ a d a p - org/9601001 .\\n\\n[3] J. Rissanen. Stochastic Complexity and Statistical Inquiry. World Scientific, Singapore (1989).\\n[4] D. MacKay, NIPS , Tutorial Lecture Notes (1997),\\nftp : //wol . ra . phy . c a m. ac . uk/pub/ma ckay/gp . ps . gz.\\n\\n[5] W. Bialek, C. Callan, and S. Strong, Phys. Rev. Lett. 77, 4693-4697 (1996),\\nhttp : //xxx.l a nl . gov/ a bs/cond-ma t/96071BO.\\n\\n[6] T. Holy, Phys. Rev. Lett. 79,3545-3548 (1997),\\nhttp : //xxx . l a nl . gov/ a bs/physics/9706015 .\\n\\n[7] V. Periwal, Phys. Rev. Lett. 78,4671-4674 (1997),\\nhttp://xxx . lanl . gov/he p - th/9703135 .\\n\\n[8] V. Periwal, Nuc!. Phys. B, 554 [FS], 719-730 (1999),\\nhttp://xxx.l a nl . gov/ a dap- org/9B01001 .\\n\\n[9] T. Aida, Phys. Rev. Lett. 83, 3554-3557 (1999),\\nhttp : //xxx . l a nl . gov/cond- ma t/9911474.\\n\\n[10] A more detailed version of our current analysis may be found in: I. Nemenman, Ph.D.\\nThesis, Princeton, (2000), http : //xxx . l a n l . gov/ a bs/phys i cs/OOO 9032 .\\n[11] W. Bialek, I. Nemenman, N. Tishby. Preprint\\nhttp : //xxx . l a nl . gov/ a bs/physics/0007070 .\\n\\n[12] G. Wahba. In B. Sh6lkopf, C. 1. S. Burges, and A. 1. Smola, eds., Advances in Kernel\\nMethods-Support Vector Learning, pp. 69-88. MIT Press, Cambridge, MA (1999),\\nftp : //ftp . st a t . wisc . edu/pub/wa hb a /nips97rr . ps .\\n\\n[13]\\n\\nw. Press et al. Numerical Recipes in C. Cambridge UP, Cambridge (1988).\\n\\n[14] Vapnik, V. Statistical Learning Theory. John Wiley & Sons, New York (1998).\\n\\n\\f\",\n          \"Effects of Spike Timing Underlying\\nBinocular Integration and Rivalry in a\\nNeural Model of Early Visual Cortex\\n\\nErik D. Lumer\\nWellcome department of Cognitive Neurology\\nInstitute of Neurology, University College of London\\n12 Queen Square, London, WC1N 3BG, UK\\n\\nAbstract\\nIn normal vision, the inputs from the two eyes are integrated into a single percept. When dissimilar images are\\npresented to the two eyes, however, perceptual integration gives way to alternation between monocular inputs,\\na phenomenon called binocular rivalry. Although recent\\nevidence indicates that binocular rivalry involves a modulation of neuronal responses in extrastriate cortex, the\\nbasic mechanisms responsible for differential processing of\\ncon:6.icting and congruent stimuli remain unclear. Using a\\nneural network that models the mammalian early visual\\nsystem, I demonstrate here that the desynchronized firing of cortical-like neurons that first receive inputs from\\nthe two eyes results in rivalrous activity patterns at later\\nstages in the visual pathway. By contrast, synchronization\\nof firing among these cells prevents such competition. The\\ntemporal coordination of cortical activity and its effects\\non neural competition emerge naturally from the network\\nconnectivity and from its dynamics. These results suggest\\nthat input-related differences in relative spike timing at\\nan early stage of visual processing may give rise to the\\nphenomena both of perceptual integration and rivalry in\\nbinocular vision.\\n\\n1\\n\\nIntroduction\\n\\nThe neural determinants of visual perception can be probed by subjecting the visual\\nsystem to ambiguous viewing conditions - stimulus configurations that admit more\\n\\n\\fE. D.Lumer\\n\\n188\\n\\nthan one perceptual interpretation. For example, when a left-tilted grating is shown\\nto the left eye and a right-tilted grating to the right eye, the two stimuli are momentarily perceived together as a plaid pattern, but soon only one line grating becomes\\nvisible, while the other is suppressed. This phenomenon, known as binocular rivalry,\\nhas long been thought to involve competition between monocular neurons within\\nthe primary visual cortex (VI), leading to the suppression of information from one\\neye (Lehky, 1988; Blake, 1989). It has recently been shown, however, that neurons\\nwhose activity covaries with perception during rivalry are found mainly in higher\\ncortical areas and respond to inputs from both eyes, thus suggesting that rivalry\\narises instead through competition between alternative stimulus interpretations in\\nextrastriate cortex (Leopold and Logothetis, 1996). Because eye-specific information appears to be lost at this stage, it remains unclear how the stimulus conditions\\n(i.e. conflicting monocular stimuli) yielding binocular rivalry are distinguished from\\nthe conditions (i.e. matched monocular inputs) that produce stable single vision.\\nI propose here that the degree of similarity between the images presented to the\\ntwo eyes is registered by the temporal coordination of neuronal activity in VI, and\\nthat changes in relative spike timing within this area can instigate the differential\\nresponses in higher cortical areas to conflicting or congruent visual stimuli. Stimulus and eye-specific synchronous activity has been described previously both in\\nthe lateral geniculate nucleus (LGN) and in the striate cortex (Gray et al., 1989;\\nSillito et al., 1994; Neuenschwander and Singer, 1996). It has been suggested that\\nsuch synchrony may serve to bind together spatially distributed neural events into\\ncoherent representations (Milner, 1974; von der Malsburg, 1981; Singer, 1993). In\\naddition, reduced synchronization of striate cortical responses in strabismic cats has\\nbeen correlated with their perceptual inability to combine signals from the two eyes\\nor to incorporate signals from an amblyopic eye (Konig et al., 1993; Roelfsema et\\nal., 1994). However, the specific influences of interocular input-similarity on spike\\ncoordination in the striate cortex, and of spike coordination on competition in other\\ncortical areas, remain unclear.\\nTo examine these influences, a simplified neural model of an early visual pathway\\nis simulated. In what follows, I first describe the anatomical and physiological constraints incorporated in the model, and then show that a temporal patterning of\\nneuronal activity in its primary cortical area emerges naturally. By manipulating\\nthe relative spike timing of neuronal discharges in this area, I demonstrate its role\\nin inducing differential responses in higher visual areas to conflicting or congruent visual stimulation. Finally, I discuss possible implications of these results for\\nunderstanding the neural basis of normal and ambiguous perception in vivo.\\n\\n2\\n\\nModel overview\\n\\nThe model has four stages based on the organization of the mammalian visual pathway (Gilbert, 1993). These stages represent: (i) sectors of an ipsilateral ('left eye')\\nand a contralateral ('right eye') lamina of the LGN, which relay visual inputs to\\nthe cortex; (ii) two corresponding monocular regions in layer 4 of VI with different\\nocular dominance; (iii) a primary cortical sector in which the monocular inputs are\\nfirst combined (called Vp in the model); and (iv) a secondary visual area of cortex\\nin which higher-order features are extracted (Vs in the model; Fig. 1). Each stage\\nconsists of 'standard' integrate-and-fire neurons that are incorporated in synaptic\\nnetworks. At the cortical stages, these units are grouped in local recurrent circuits\\nthat are similar to those used in previous modeling studies (Douglas et al., 1995;\\nSomers et al., 1995). Synaptic interactions in these circuits are both excitatory and\\ninhibitory between cells with similar orientation selectivity, but are restricted to in-\\n\\n\\fSpike Timing Effects in Binocular Integration and Rivalry\\n\\n189\\n\\n(L.L ___ , _.. ___ , ( )__ ... ___ -.. ,\\n\\n:9\\n\\n: : Exp' . ~1 ; ; ElI2p'\\nIaver 4 : Ex1\\nt-.~...J\\n. :?~...J :\\n- - ~ In~~~; :.~~~ ; : Inhl..1j :,~~ J\\n\\n(L)\\n\\nFigure 1: Architecture of the model. Excitatory and inhibitory connections are represented by lines with arrowheads and round terminals , respectively, Each lamina\\nin the LGN consists of 100 excitatory units (Ex) and 100 inhibitory units (Inh) ,\\ncoupled via local inhibition. Cortical units are grouped into local recurrent circuits\\n(stippled boxes) , each comprising 200 Ex units and 100 Inh units. In each monocular patch of layer 4, one cell group (Exl and Inh1) responds to left-tilted lines\\n(orientation 1), whereas a second group (Ex2 and Inh2) is selective for right-tilted\\nlines (orientation 2) . The same orientation selectivities are remapped onto Vp and\\nVs, although cells in these areas respond to inputs from both eyes. In addition,\\nconvergent inputs from Vp to Vs establish a third selectivity in Vs, namely for line\\ncrossings (Ex+ and Inh+) .\\n\\nhibition only between cell groups with orthogonal orientation preference (Kisvarday\\nand Eysel, 1993) . Two orthogonal orientations (orientation 1 and 2) are mapped\\nin each monocular sector of layer 4, and in Vp. To account for the emergence of\\nmore complex response properties at higher levels in the visual system (Van Essen\\nand Gallant, 1994), forward connectivity patterns from Vp to Vs are organized to\\nsupport three feature selectivities in Vs , one for orientation 1, one for orientation 2,\\nand one for the conjunction of these two orientations, i.e. for line crossings. These\\nforward projections are reciprocated by weaker backward projections from Vs to\\nVp. As a general rule , connections are established at random within and between\\ninterconnected populations of cells, with connection probabilities between pairs of\\ncells ranging from 1 to 10 %, consistent with experimental estimates (Thomson et\\nal., 1988; Mason et al., 1991) . Visual stimulation is achieved by applying a stochastic synaptic excitation independently to activated cells in the LGN . A quantitative\\ndescription of the model parameters will be reported elsewhere.\\n\\n\\f190\\n\\n3\\n\\nE. D. Lumer\\n\\nResults\\n\\nIn a first series of simulations, the responses of the model to conflicting and congruent visual stimuli are compared. When the left input consists of left-tilted lines\\n(orientation 1) and the right input of right-tilted lines (orientation 2), rivalrous response suppression occurs in the secondary visual area. At any moment, only one\\nof the three feature-selective cell groups in Vs can maintain elevated firing rates\\n(Fig. 2a). By contrast, when congruent plaid patterns are used to stimulate the\\ntwo monocular channels, these cell groups are forced in a regime in which they all\\nsustain elevated firing rates (Fig. 2b). This concurrent activation of cells selective\\nfor orthogonal orientations and for line crossings can be interpreted as a distributed\\nrepresentation of the plaid pattern in Vs 1. A quantitative assessment of the degree of competition in Vs is shown in Figure 2c. The rivalry index of two groups\\nof neurons is defined as the mean absolute value of the difference between their\\ninstantaneous group-averaged firing rates divided by the highest instantaneous firing rate among the two cell groups. This index varies between 0 for nonrivalrous\\ngroups of neurons and 1 for groups of neurons with mutually exclusive patterns of\\nactivity. Groups of cells with different selectivity in Vs have a significantly higher\\nrivalry index when stimulated by conflicting rather than by congruent visual inputs\\n(p < 0.0001) (Fig. 2c).\\nNote that, in the example shown in Figure 2a, the differential responses to conflicting\\ninputs develop from about 200 ms after stimulus onset and are maintained over\\nthe remainder of the stimulation epoch. In other simulations, alternation between\\ndominant and suppressed responses was also observed over the same epoch as a\\nresult of fluctuations in the overall network dynamics. A detailed analysis of the\\ndynamics of perceptual alternation during rivalry, however, is beyond the scope of\\nthis report.\\nAlthough Vp exhibits a similar distribution of firing rates during rivalrous and nonrivalrous stimulation, synchronization between the two cell groups in Vp is more\\npronounced in the nonrivalrous than in the rivalrous case (Fig. 2d, upper plots).\\nSubtraction of the shift predictor demonstrates that the units are not phase-locked\\nto the stimuli. The changes in spike coordination among Vp units reflects the\\ntemporal patterning of their layer 4 inputs. During rivalry, Vp cells with different\\norientation selectivity are driven by layer 4 units that belong to separate monocular\\npathways, and hence, are uncorrelated (Fig. 2d, lower left). By contrast, cells in Vp\\nreceive convergent inputs from both eyes during nonrivalrous stimulation. Because\\nof the synchronization of discharges among cells responsive to the same eye within\\nlayer 4 (Fig. 2d, lower right), the paired activities from the two monocular channels are also synchronized, a.nd provide synchronous inputs to cells with different\\norienta.tion selectivity in Vp.\\nTo establish unequivocally that changes in spike coordination within Vp are sufficient to trigger differential responses in Vs to conflicting and congruent stimuli,\\nthe model can be modified as follows. A single group of cells in layer 4 is used to\\ndrive with equal strength both orientation-selective populations of neurons in Vp.\\nThe outputs from layer 4, however, is relayed to these two target populations with\\naverage transmission delays that differ by either 10 ms or by 0 ms. In the first case,\\ncompetition prevails among cells in the secondary visual area. This contrasts with\\nthe nonrivalrous activity in this area when similar transmission delays are used at\\nan earlier stage (data not shown). This test confirms that changes in relative spike\\nlTo discount possible effects of binocular snmmmation, synaptic strengths from layer 4\\nto Vp are reduced during congruent stimulation so as to produce a feedforward activation\\nof Vp comparable to that elicited by conflicting monocular inputs.\\n\\n\\fSpike Timing Effects in Binocular Integration and Rivalry\\nconflicting visual inputs\\n\\na\\n\\n191\\ncongruent visual inputs\\n\\nb\\n\\n40~\\n.S\\n,\\n\\n30\\n\\n_6\\n\\nN\\n\\n3\\n\\n2\\n\\n-::~\\n\\n4\\n\\nN\\n\\nl:\\n\\nJ:\\n\\n40\\n\\n2\\n\\n3\\n\\nC)2\\n\\n-Vs+\\n\\nC)2\\n\\n2\\n\\n.s '\\nI-\\n\\n3\\n\\no\\n\\n1\\n\\n2\\n\\n<;'--t\\n\\n\\\" -\\\" - : - \\\"\\n\\n3\\n\\n4\\n\\nL41\\n-R42\\n-ee- L42\\nR41\\n2\\n\\n3\\n\\n..\\n\\nTime (ms)\\n\\nTime (ms)\\n\\nc\\n\\n-Yp1\\n-Yp2\\n\\n-3..-------:4\\n\\nir.\\n\\n:[4\\n:u~\\nat-.. . t.~ \\\" oC\\\"_ ~'\\n\\n'b'---~\\n1 -~2-\\n\\n-Ys1\\n-Ys2\\n\\n..\\n\\n4\\n\\nC\\n'C\\n\\nd\\n\\ncongruent\\n\\nconflicting\\n\\nfHdNkd\\n1m gAd~50\\n\\n><\\nCI)\\n\\n\\\"c\\n\\n~\\n\\nl\\na:\\n\\n1\\n\\nI-\\n\\n11.I\\\"'\\\\Jo/\\\"1IfV!1'Y\\n\\nI-\\n\\nu::\\n\\n'b\\n\\n~eo~vp\\n1U\\n\\nG)\\n\\n1&\\n\\n.\\n\\nCJ\\n\\n0.1\\n\\no\\nVs1:Vs2\\n\\nmax(Vs}:Vs+\\n\\n-80\\n\\n0\\n\\n80 -80\\n\\n0\\n\\n80\\n\\nTime lag (ms)\\nFigure 2: A, Instantaneous firing rates in response to conflicting inputs for cell\\ngroups in layer 4, in Vp, and in Vs (stimulus onset at t = 250ms). Discharge rates\\nof layer 4 cells driven by different 'eyes' are similar (lower plot). By contrast, Vs\\nexhi bi ts com peti ti ve firing pat terns soon after stimulus onset (upper plot). Feed back\\ninfluence from Vs to Vp results in comparatively weaker competition in Vp (middle\\nplot). B, Responses to congruent inputs. All cell groups in layer 4 are activated by\\nvisual inputs. Nonrivalrous firing patterns ensue in Vp and Vs. C, Rivalry indices\\nduring conflicting and congruent stimulation, are calculated for the two orientationselective cell groups and for the dominant and cross-selective cell group in Vs. D,\\nInterocular responses are uncorrelated in layer 4 (lower left), whereas intraocular\\nactivities are synchronous at this stage (lower right). Enhanced synchronization of\\ndischarges ensues between cell groups in Vp during congruent stimulation (upper\\nright), relative to the degree of coherence during conflicting stimulation (upper left).\\n\\n\\fE. D.Lumer\\n\\n192\\n\\ntiming are sufficient to switch the outcome of neural network interactions involving\\nstrong mutual inhibition from competitive to cooperative.\\n\\n4\\n\\nConclusion\\n\\nIn the present study, a simplified model of a visual pathway was used to gain\\ninsight into the neural mechanisms operating during binocular vision. Simulations of\\nneuronal responses to visual inputs revealed a stimulus-related patterning of relative\\nspike timing at an early stage of cortical processing. This patterning reflected\\nthe degree of similarity between the images presented to the two 'eyes', and, in\\nturn, it altered the outcome of competitive interactions at later stages along the\\nvisual pathway. These effects can help explaining how the same cortical networks\\ncan exhibit both rivalrous and nonrivalrous activity, depending on the temporal\\ncoordination of their synaptic inputs.\\nThese results bear on the interpretation of recent empirical findings about the neuronal correlates of rivalrous perception. In experiments with awake monkeys, Logothetis and colleagues (Sheinberg et al., 1995; Leopold and Logothetis, 1996) have\\nshown that neurons whose firing rate correlates with perception during rivalry are\\ndistributed at several levels along the primate visual pathways, including Vl/V2,\\nV4, and IT. Importantly, the fraction of modulated responses is lower in VI than in\\nextrastriate areas, and it increases with the level in the visual hierarchy. Simulations\\nof the present model exhibit a behavior that is consistent with these observations.\\nHowever, these simulations also predict that both rivalrous and nonrivalrous perception may have a clear neurophysiological correlate in VI, i.e. at the earliest\\nstage of visual cortical processing. Accordingly, congruent stimulation of both eyes\\nwill synchronize the firing of binocular cells with overlapping receptive fields in Vl.\\nBy contrast, conflicting inputs to the two eyes will cause a desynchronization between their corresponding neural events in Vl. Because this temporal registration\\nof stimulus dissimilarity instigates competition among binocular cells in higher visual areas and not between monocular pathways, the ensuing pattern of response\\nsuppression and dominance is independent of the eyes through which the stimuli are\\npresented. Thus, the model can in principle account for the psychophysical finding that a single phase of perceptual dominance during rivalry can span multiple\\ninterocular exchanges of the rival stimuli (Logothetis et al., 1996).\\nThe present results also reveal a novel property of canonical cortical-like circuits\\ninteracting through mutual inhibition, i.e. the degree of competition among such\\ncircuits exhibits a remarkable sensitivity to the relative timing of neuronal action\\npotentials. This suggests that the temporal patterning of cortical activity may be\\na fundamental mechanism for selecting among stimuli competing for the control of\\nattention and motor action.\\nAcknowledgements\\nThis work was supported in part by an IRSIA visiting fellowship at the Center\\nfor Nonlinear Phenomena and Complex Systems, Universite Libre de Bruxelles. I\\nthank Professor Gregoire Nicolis for his hospitality during my stay in Brussels; and\\nDavid Leopold and Daniele Piomelli for helpful discussions and comments on an\\nearlier version of the manuscript.\\nReferences\\nBlake R (1989) A neural theory of binocular vision. Psychol Rev 96:145-167.\\n\\n\\fSpike Timing Effects in Binocular Integration andRivalry\\n\\n193\\n\\nDouglas RJ, Koch C, Mahowald M, Martin K, Suarez H (1995) Recurrent excitation\\nin neocortical circuits. Science 269:981-985.\\nGilbert C (1993) Circuitry, architecture, and functional dynamics of visual cortex.\\nCereb Cortex 3:373-386.\\nGray CM, Konig P, Engel AK, Singer, W (1989) Oscillatory responses in cat visual cortex exhibit inter-columnar synchronization which reflects global stimulus\\nproperties. Nature 338 :334-337.\\nKisvarday ZF, Eysel UT (1993) Functional and structural topography of horizontal\\ninhibitory connections in cat visual cortex. Europ J Neurosci 5:1558-1572.\\nKonig P, Engel AK, Lowel S, Singer, W (1993) Squint affects synchronization of\\noscillatory responses in cat visual cortex. Eur J Neurosci 5:501-508.\\nLehky SR (1988) An astable multivibrator model of binocular rivalry. Perception\\n17: 215- 228.\\nLeopold DA, Logothetis NK (1996) Activity changes in early visual cortex reflect\\nmonkeys percepts during binocular rivalry. Nature 379:549-553.\\nLogothetis NK, Leopold DA, Sheinberg DL (1996) What is rivalling during rivalry?\\nNature 380:621-624.\\nNeuenschwander S, Singer W (1996) Long-range synchronization of oscillatory light\\nresponses in the cat retina and lateral geniculate nucleus. Nature 379:728-733.\\nMilner PM (1974) A model of visual shape recognition. Psychol Rev 81:521-535.\\nRoelfsema PR, Konig P, Engel AK, Sireteanu R , Singer W (1994) Reduced synchronization in the visual cortex of cats with strabismic amblyopia. Eur J Neurosci\\n6:1645-1655.\\nSheinberg DL, Leopold DA, Logothetis NK (1995) Effects of binocular rivalry on\\nface cell activity in monkey temporal cortex. Soc Neurosci Abstr 21:15.12.\\nSillito AM, Jones HE, Gerstein GL, West DC (1994) Feature-linked synchronization\\nof thalamic relay cell firing induced by feedback from the visual cortex. Nature\\n369:479-482.\\nSinger W (1993) Synchronization of cortical activity and its putative role in information processing. Annu Rev Physiol 55:349-374.\\nSomers D, Nelson S, Sur M (1995) An emergent model of orientation selectivity in\\ncat visual cortical simple cells. J Neurosci 15:5448-5465.\\nVan Essen DC, Gallant JL (1994) Neural mechanisms ofform and motion processing\\nin the primate visual system . Neuron 13:1-10.\\nvon der Malsburg C (1981) The correlation theory of the brain. Internal Report\\n81-2, Max Planck Institute for Biophysical Chemistry, Gottingen.\\n\\n\\f\",\n          \"Transition Point Dynamic Programming\\n\\nKenneth M. Buckland'\\\"\\nDept. of Electrical Engineering\\nUniversity of British Columbia\\nVancouver, B.C, Canada V6T 1Z4\\nbuckland@pmc-sierra.bc.ca\\n\\nPeter D. Lawrence\\nDept. of Electrical Engineering\\nUniversity of British Columbia\\nVancouver, B.C, Canada V6T 1Z4\\npeterl@ee.ubc.ca\\n\\nAbstract\\nTransition point dynamic programming (TPDP) is a memorybased, reinforcement learning, direct dynamic programming approach to adaptive optimal control that can reduce the learning\\ntime and memory usage required for the control of continuous\\nstochastic dynamic systems. TPDP does so by determining an\\nideal set of transition points (TPs) which specify only the control\\naction changes necessary for optimal control. TPDP converges to\\nan ideal TP set by using a variation of Q-Iearning to assess the merits of adding, swapping and removing TPs from states throughout\\nthe state space. When applied to a race track problem, TPDP\\nlearned the optimal control policy much sooner than conventional\\nQ-Iearning, and was able to do so using less memory.\\n\\n1\\n\\nINTRODUCTION\\n\\nDynamic programming (DP) approaches can be utilized to determine optimal control policies for continuous stochastic dynamic systems when the state spaces of\\nthose systems have been quantized with a resolution suitable for control (Barto et\\nal., 1991). DP controllers, in lheir simplest form, are memory-based controllers\\nthat operate by repeatedly updating cost values associated with every state in the\\ndiscretized state space (Barto et al., 1991). In a slate space of any size the required\\nquantization can lead to an excessive memory requirement, and a related increase\\nin learning time (Moore, 1991). This is the \\\"curse of dimensionality\\\".\\n?Nowat: PMC-Sierra Inc., 8501 Commerce Court, Burnaby, B.C., Canada V5A 4N3.\\n\\n639\\n\\n\\f640\\n\\nBuckland and Lawrence\\n\\nQ-Iearning (Watkins, 1989, Watkins et al., 1992) is a direct form of DP that avoids\\nexplicit system modeling - thereby reducing the memory required for DP control.\\nFurther reductions are possible if Q-Ieal'l1ing is modified so that its DP cost values\\n(Q-values) are associated only with states where control action changes need to be\\nspecified. Transition point dynamic programming (TPDP), the control approach\\ndescribed in this paper, is designed to take advantage of this DP memory reduction\\npossibility by determining the states where control action changes must be specified\\nfor optimal control, and what those optimal changes are.\\n\\n2\\n2.1\\n\\nGENERAL DESCRIPTION OF TPDP\\nTAKING ADVANTAGE OF INERTIA\\n\\nTPDP is suited to the control of continuous stochastic dynamic systems that have\\ninertia. In such systems \\\"uniform regions\\\" are likely to exist in the state space\\nwhere all of the (discretized) states have the same optimal control action (or the\\nsame set of optimal actions l ). Considering one such uniform region, if the optimal\\naction for that region is specified at the \\\"boundary states\\\" of the region and then\\nmaintained throughout the region until it is left and another uniform region is\\nentered (where another set of boundary states specify the next action), none of the\\n\\\"dormant states\\\" in the middle of the region need to specify any actions themselves.\\nThus dormant states do not have to be represented in memory. This is the basic\\npremise of TPDP.\\nThe association of optimal actions with boundary states is done by \\\"transition\\npoints\\\" (TPs) at those states. Boundary states include all of the states that can\\nbe reached from outside a uniform region when that region is entered as a result of\\nstochastic state transitions. The boundary states of anyone uniform region form a\\nhyper-surface of variable thickness which mayor may not be closed. The TPs at\\nboundary states must be represented in memory, but if they are small in number\\ncompared to the dormant states the memory savings can be significant.\\n\\n2.2\\n\\nILLUSTRATING THE TPDP CONCEPT\\n\\nFigure 1 illustrates the TPDP concept when movement control of a \\\"car\\\" on a\\none dimensional track is desired. The car, with some initial positive velocity to the\\nright, must pass Position A and return to the left. The TPs in Figure 1 (represented\\nby boxes) are located at boundary states. The shaded regions indicate all of the\\nstates that the system can possibly move through given the actions specified at the\\nboundary states and the stochastic response of the car. Shaded states without TPs\\nare therefore dormant states. Uniform regiolls consist of adjacent boundary states\\nwhere the same action is specified, as well as the shaded region through which that\\naction is maintained before another boundary is encountered. Boundary states that\\ndo not seem to be on the main sta.te transition routes (the one identified in Figure 1\\nfor example) ensure that any stochastic deviations from those routes are realigned.\\nUnshaded states are \\\"external states\\\" the system does not reach.\\nIThe simplifying assumption t.hat t.here is ouly oue optimal action in each uniform\\nregion will be made throughout this paper. TPDP operates the same regardless.\\n\\n\\fTransition Point Dynamic Programming\\n\\n+\\n\\n13\\n\\nEach\\nis a\\ntransition point (TP),\\n\\n~\\n\\n'0\\n\\n00\\nQ)\\n\\n>\\n\\nniform\\nRegion\\n\\nBoundary\\nState\\n\\nA\\nPosition\\nFigure 1: Application of TPDP to a One Dimension Movement Control Task\\n\\n2.3\\n\\nMINIMAL TP OPTIMAL CONTROL\\n\\nThe main benefit of the TPDP approach is that, where uniform regions exist, they\\ncan be represented by a relatively small number of DP elements (TPs) - depending\\non the shape of the boundaries and the size of the uniform regions they encompass. This reduction in memory usage results in an accompanying reduction in the\\nlearning time required to learn optimal control policies (Chapman et al., 1991).\\nTPDP operates by learning optimal points of transition in the control action specification, where those points can be accurately located in highly resolved state spaces.\\nTo do this TPDP must determine which states are boundary states that should\\nhave TPs, and what actions those TPs should specify. In other words, TPDP must\\nfind the right TPs for the right states. When it has done so, \\\"minimal TP optimal\\ncontrol\\\" has been achieved. That is, optimal control with a minimal set of TPs.\\n\\n3\\n3.1\\n\\nACHIEVING MINIMAL TP OPTIMAL CONTROL\\nMODIFYING A SET OF TPs\\n\\nGiven an arbitrary initial set of TPs, TPDP must modify that set so that it is\\ntransformed into a minimal TP optimal control set. Modifications can include the\\n\\\"addition\\\" and \\\"removal\\\" of TPs throughout the state space, and the \\\"swapping\\\"\\nof one TP for another (each specifying a different action) at the same state. These\\n\\n641\\n\\n\\f642\\n\\nBuckland and Lawrence\\n\\nmodifications are performed one at a time in arbitl'ary order, and can continue\\nindefinitely. TPDP operates so that each TP modification results in an incremental\\nmovement towards minimal TP optimal control (Buckland, 1994).\\n\\n3.2\\n\\nQ-LEARNING\\n\\nTPDP makes use of Q-Iearning (Watkins, 1989, Watkins et ai., 1992) to modify the\\nTP set. Normally Q-Iearning is used to determine the optimal control policy J-t for\\na stochastic dynamic system subjected to immediate costs c(i, u) when action u is\\napplied in each state i (Barto et ai., 1991). Q-learning makes use of \\\"Q-values\\\"\\nQ( i, u), which indicate the expected total infini te-horizon discounted cost if action\\nu is applied in state i, and actions defined by the existing policy J-t are applied in\\nall future states. Q-values are learned by using the following updating equation:\\n\\nQt+l(St, Ut) = (1 - Ctt)Qt(St, ud + at [c(St, ud + 'YVt(St+l)]\\n(1)\\nWhere at is the update rate, l' is the discount factor, and St and Ut are respectively\\nthe state at time step t and the action taken at that time step (all other Q-values\\nremain the same at time step t). The evaluation function value lit (i) is set to the\\nlowest Q-value action of all those possible U(i) in each state i:\\nVt(i) = min Qt(i, u)\\n(2)\\nUEU(i)\\n\\nIf Equations 1 and 2 are employed during exploratory movement of the system, it has\\nbeen proven that convergence to optimal Q-values Q* (i, u) and optimal evaluation\\nfunction values VI-'. (i) will result (given that the proper constraints are followed,\\nWatkins, 1989, Watkins et ai., 1992, Jaakkola et ai., 1994). From these values the\\noptimal action in each state can be determined (the action that fulfills Equation 2).\\n\\n3.3\\n\\nASSESSING TPs WITH Q-LEARNING\\n\\nTPDP uses Q-Iearning to determiue how an existing set of TPs should be modified\\nto achieve minimal TP optimal control. Q-values can be associated with TPs, and\\nthe Q-values of two TPs at the same \\\"TP state\\\", each specifying different actions,\\ncan be compared to determine which should be maintained at that state - that is,\\nwhich has the lower Q-value. This is how TPs are swapped (Buckland, 1994).\\nStates which do not have TPs, \\\"non-TP states\\\", have no Q-values from which\\nevaluation function values vt(i) can be determined (using Equation 2). As a result,\\nto learn TP Q-values, Equation 1 must be modified to facilitate Q-value updating\\nwhen the system makes d state transitions from one TP state through a number of\\nnon-TP states to another TP state:\\n\\nQt+.( St, Ut) = (1 - a,jQt (5t, Ut)\\n\\n+ \\\"t [ (~'Yn c( St+n, Ut)) + 'Y.v,( St+.)]\\n\\n(3)\\n\\n=\\n\\nWhen d 1, Equation 3 takes the form of Equation 1. When d > 1, the intervening\\nnon-TP states are effectively ignored and treated as inherent parts of the stochastic\\ndynamic behavior of the system (Buckla.nd, 1994).\\nIf Equation 3 is used to determine the costs incurred when no action is specified\\nat a state (when the action specified at some previous state is maintained), an \\\"Rvalue\\\" R( i) is the result. R-values can be used to expediently add and remove TPs\\n\\n\\fTransition Point Dynamic Programming\\n\\nfrom each state. If the Q-value of a TP is less than the R-value of the state it is\\nassociated with, then it is worthwhile having that TP at that state; otherwise it is\\nnot (Buckland, 1994).\\n\\n3.4\\n\\nCONVERGENCE TO MINIMAL TP OPTIMAL CONTROL\\n\\nIt has been proven that a random sequence of TP additions, swaps and removals\\n\\nattempted at states throughout the state space will result in convergence to minimal TP optimal control (Buckland, 1994). This proof depends mainly on all TP\\nmodifications \\\"locking-in\\\" any potential cost reductions which are discovered as the\\nresult of learning exploration.\\nThe problem with this proof of convergence, and the theoretical form of TPDP\\ndescribed up to this point, is that each modification to the existing set of TPs (each\\naddition, swap and removal) requires the determination of Q-values and R-values\\nwhich are negligibly close to being exact. This means that a complete session of\\nQ-Iearning must occur for every TP modification. 2 The result is excessive learning\\ntimes - a problem circumvented by the practical form of TPDP described next.\\n\\n4\\n4.1\\n\\nPRACTICAL TPDP\\nCONCURRENT TP ASSESSMENT\\n\\nTo solve the problem of the protracted learning time required by the theoretical\\nform of TPDP, many TP modifications can be assessed concurrently. That is,\\nQ-Iearning can be employed not just to determine the Q-values and R-values for a\\nsingle TP modification, but instead to learn these values for a number of concurrent\\nmodifications. Further, the modification attempts, and the learning of the values\\nrequired for them, need not be initiated simultaneously. The determination of each\\nvalue can be made part of the Q-Iearning process whenever new modifications are\\nrandomly attempted. This approa.ch is called \\\"Pra.ctical TPDP\\\". Practical TPDP\\nconsists of a continually running Q-Ieal'l1ing process (based on Equations 2 and 3),\\nwhere the Q-values and R-values of a constantly changing set of TPs are learned.\\n\\n4.2\\n\\nUSING WEIGHTS FOR CONCURRENT TP ASSESSMENT\\n\\nThe main difficulty that arises when TPs are assessed concurrently is that of determining when an assessment is complete. That is, when the Q-values and R-values\\nassociated with each TP ha.ve been learned well enough for a TP modification to\\nbe made based on them. The technique employed to address this problem is to\\nassociate a \\\"weight\\\" wei, u) with ea.ch TP that indicates the general merit of that\\nTP. The basic idea of weights is to facilita.te the random addition of trial TPs to\\na TP \\\"assessment group\\\" with a low initial weight Winitial. The Q-values and Rvalues of the TPs in the assessment group are learned in an ongoing Q-Iearning\\nprocess, and the weights of the TPs are adjusted heuristically using those values.\\nOf those TPs at any state i whose weights wei, u) have been increased above Wthr\\n2The TPDP proof allows for more than one TP swap to be assessed simultaneously,\\nbut this does little to reduce the overall problem being described (Buckland, 1994).\\n\\n643\\n\\n\\f644\\n\\nBuckland and Lawrence\\n\\n100\\nConventional\\nQ-Iearning\\n\\n-\\n\\n..c\\n\\nC>\\nC\\nQ)\\n\\n.....J\\n\\n-\\n\\n..c\\n\\nCU\\n\\na...\\n\\n50\\n\\nQ)\\n\\nC>\\n\\n~\\n\\nQ)\\n\\n~\\n\\nPractical TPDP\\n\\no\\n\\no\\n\\n2500\\nEpoch Number\\n\\nFigure 2: Performance of Practical TPDP on a Race Track Problem\\n(Winitial < Wthr < w max ), the one with the lowest Q-value Q(i, u) is swapped into\\nthe \\\"policy TP\\\" role for that state. The heuristic weight adjustment rules are:\\n\\n1. New, trial TPs are given an initial weight of Wjnitial (0 < Winitial < Wthr).\\n2. Each time the Q-value of a TP is updated, the weight w(i, u) of that TP is\\nincremented if Q(i, u) < R(i) and decremented otherwise.\\n\\n3. Each TP weight w( i, u) is limited to a maximum value of w max . This\\nprevents anyone weight from becoming so large that it cannot readily be\\nreduced again.\\n4. If a TP weight w(i, u) is decremented to 0 the TP is removed.\\nAn algorithm for Practical TPDP implementation is described in Buckland (1994).\\n\\n4.3\\n\\nPERFORMANCE OF PRACTICAL TPDP\\n\\nPractical TPDP was applied to a continuous version of a control task described by\\nBarto et al. (1991) - that of controlling the acceleration of a car down a race track\\n(specifically the track shown in Figures 3 and 4) when that car randomly experiences\\ncontrol action non-responsiveness. As shown in Figure 2 (each epoch in this Figure\\nconsisted of 20 training trials and 500 testing trials), Practical TPD P learned the\\noptimal control policy much sooner than conventional Q-Iearning, and it was able\\nto do so when limited to only 15% of the possible number of TPs (Buckland, 1994).\\nThe possible number of TPs is the full set of Q-values required by conventional\\nQ-Iearning (one for each possible state and action combination).\\nThe main advantage of Practical TPDP is that it facilitates rapid learning of preliminary control policies. Figure 3 shows typical routes followed by the car early\\n\\n\\fTransition Point Dynamic Programming\\n\\nFinishing\\nPositions\\n\\nStarting\\nPositions\\n\\nFigure 3: Typical Race Track Routes After 300 Epochs\\nFinishing\\nPositions\\n\\nStarting\\nPositions\\n\\nFigure 4: Typical Race Track Routes After 1300 Epochs\\nin the learning process. With the addition of relatively few TPs, the policy of accelerating wildly down the track, smashing into the wall and continuing on to the\\nfinishing positions was learned. Further learning centered around this preliminary\\npolicy led to the optimal policy of sweeping around the left turn. Figure 4 shows\\ntypical routes followed by the car during this shift in the learned policy - a shift\\nindicated by a slight drop in the learning curve shown in Figure 2 (around 1300\\nepochs). After this shift, learning progressed rapidly until roughly optimal policies\\nwere consistently followed.\\nA problem which occurs in Practical TPDP is that of the addition of superfluous\\nTPs after the optimal policy has bac;ically been learned. The reasons this occurs\\nare described in Buckland (1994), ac; well as a number of solutions to the problem.\\n\\n5\\n\\nCONCLUSION\\n\\nThe practical form of TPDP performs very well when compared to conventional\\nQ-Iearning. When applied to a race track problem it was able to learn optimal\\npolicies more quickly while using less memory. Like Q-learning, TPDP has all the\\n\\n645\\n\\n\\f646\\n\\nBuckland and Lawrence\\n\\nadvantages and disadvantages that result from it being a direct control approach\\nthat develops no explicit system model (Watkins, 1989, Buckland, 1994).\\nIn order to take advantage of the sparse memory usage that occurs in TPDP, TPs\\nare best represented by ACAMs (associative content addressable memories, Atkeson, 1989). A localized neural network design which operates as an ACAM and\\nwhich facilitates Practical TPDP control is described in Buckland et al. (1993) and\\nBuckland (1994).\\nThe main idea of TPDP is to, \\\"try this for a while and see what happens\\\". This\\nis a potentially powerful approach, and the use of TPs associated with abstracted\\ncontrol actions could be found to have substantial utility in hierarchical control\\nsystems.\\nAcknowledgements\\n\\nThanks to John Ip for his help on this work. This work was supported by an NSERC\\nPostgraduate Scholarship, and NSERC Operating Grant A4922.\\nReferences\\n\\nAtkeson, C. G. (1989), \\\"Learning arm kinematics and dynamics\\\", Annual Review\\nof Neuroscience, vol. 12, 1989, pp. 157-183.\\nBarto, A. G., S. J. Bradtke and S. P. Singh (1991), \\\"Real-time learning and control using asynchronous dynamic programming\\\", COINS Technical Report 91-57,\\nUniversity of Massachusetts, Aug. 1991.\\nBuckland, K. M. and P. D. Lawrence (1993), \\\"A connectionist approach to direct\\ndynamic programming control\\\" , Proc. of the IEEE Pacific Rim Conf. on Communications, Computers and Signal Processing, Victoria, 1993, vol. 1, pp. 284-287.\\nBuckland, K. M. (1994), Optimal Control of Dynamic Systems Through the Reinforcement Learning of Transition Points, Ph.D. Thesis, Dept. of Electrical Engineering, University of British Columbia, 1994.\\nChapman, D. and L. P. Kaelbling (1991), \\\"Input generalization in delayed\\nreinforcement-learning: an algorithm a.nd performance comparisons\\\", Proc. of the\\n12th Int. Joint Con/. on Artificial Intelligence, Sydney, Aug. 1991, pp. 726-731.\\nJaakkola, T., M. I. Jordan and S. P. Singh (1994), \\\"Stocha'ltic convergence of iterative DP algorithms\\\", A dvances in N eM'al Information Processing Systems 6, eds.:\\nJ. D. Cowen, G. Tesauro and J. Alspector, San Francisco, CA: Morgan Kaufmann\\nPublishers, 1994.\\nMoore, A. W. (1991), \\\"Variable resolution dynamic programming: efficiently learning action maps in multivariate real-valued state-spaces\\\", Machine Learning: Proc.\\nof the 8th Int. Workshop, San Mateo, CA: Morgan Kaufmann Publishers, 1991.\\nWatkins, C. J. C. H. (1989), Learning from Delayed Rewards, Ph.D. Thesis, Cambridge University, Cambridge, England, 1989.\\nWatkins, C. J. C. H. and P. Dayan (1992), \\\"Q-Iearning\\\", Machine Learning, vol. 8,\\n1992, pp. 279-292.\\n\\n\\f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Remove the columns\n",
        "papers = papers.drop(columns=['id', 'title', 'abstract',\n",
        "                              'event_type', 'pdf_name', 'year'], axis=1)\n",
        "\n",
        "# sample only 100 papers\n",
        "papers = papers.sample(100)\n",
        "\n",
        "# Print out the first rows of papers\n",
        "papers.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8b_nDqD2Wpy"
      },
      "source": [
        "##### Remove punctuation/lower casing\n",
        "\n",
        "Next, let’s perform a simple preprocessing on the content of paper_text column to make them more amenable for analysis, and reliable results. To do that, we’ll use a regular expression to remove any punctuation, and then lowercase the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "KvGwCWmH2Wpy",
        "outputId": "cd3a18d3-9c69-452d-c1f9-352f52522a10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3412    interval estimation for reinforcement-learning...\n",
              "274     effective training of a neural network\\ncharac...\n",
              "2741    privacy-preserving logistic regression\\n\\nkama...\n",
              "3338    latent variable models for predicting file\\nde...\n",
              "3954    a connectionist learning approach to analyzing...\n",
              "Name: paper_text_processed, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paper_text_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3412</th>\n",
              "      <td>interval estimation for reinforcement-learning...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>effective training of a neural network\\ncharac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2741</th>\n",
              "      <td>privacy-preserving logistic regression\\n\\nkama...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3338</th>\n",
              "      <td>latent variable models for predicting file\\nde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3954</th>\n",
              "      <td>a connectionist learning approach to analyzing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Load the regular expression library\n",
        "import re\n",
        "\n",
        "# Remove punctuation\n",
        "papers['paper_text_processed'] = papers['paper_text'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
        "\n",
        "# Convert the titles to lowercase\n",
        "papers['paper_text_processed'] = papers['paper_text_processed'].map(lambda x: x.lower())\n",
        "\n",
        "# Print out the first rows of papers\n",
        "papers['paper_text_processed'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYBW67DJ2Wpy"
      },
      "source": [
        "##### Tokenize words and further clean-up text\n",
        "\n",
        "Let’s tokenize each sentence into a list of words, removing punctuations and unnecessary characters altogether."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNBDE6om2Wpy",
        "outputId": "638a1f56-f8ae-48a2-d07e-3375637d6ee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['interval', 'estimation', 'for', 'reinforcement', 'learning', 'algorithms', 'in', 'continuous', 'state', 'domains', 'adam', 'white', 'department', 'of', 'computing', 'science', 'university', 'of', 'alberta', 'awhite', 'csualbertaca', 'martha', 'white', 'department', 'of', 'computing', 'science', 'university', 'of', 'alberta']\n"
          ]
        }
      ],
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data = papers.paper_text_processed.values.tolist()\n",
        "data_words = list(sent_to_words(data))\n",
        "\n",
        "print(data_words[:1][0][:30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KymBsb2U2Wpy"
      },
      "source": [
        "** **\n",
        "#### Step 3: Phrase Modeling: Bigram and Trigram Models\n",
        "** **\n",
        "\n",
        "Bigrams are two words frequently occurring together in the document. Trigrams are 3 words frequently occurring. Some examples in our example are: 'back_bumper', 'oil_leakage', 'maryland_college_park' etc.\n",
        "\n",
        "Gensim's Phrases model can build and implement the bigrams, trigrams, quadgrams and more. The two important arguments to Phrases are min_count and threshold.\n",
        "\n",
        "*The higher the values of these param, the harder it is for words to be combined.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "j1vwN33S2Wpz"
      },
      "outputs": [],
      "source": [
        "# Build the bigram and trigram models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhfqqpAk2Wpz"
      },
      "source": [
        "#### Remove Stopwords, Make Bigrams and Lemmatize\n",
        "\n",
        "The phrase models are ready. Let’s define the functions to remove the stopwords, make trigrams and lemmatization and call them sequentially."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZA56KlA2Wpz",
        "outputId": "413b7e13-508e-4ced-ec8a-836cbd2a95b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# NLTK Stop words\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_l4YgEvD2Wpz"
      },
      "outputs": [],
      "source": [
        "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent))\n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIdQxrp62Wpz"
      },
      "source": [
        "Let's call the functions in order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTlQqZkw2Wpz",
        "outputId": "05887721-59b3-4341-cc41-fb424c3c996e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOmaBQQK2Wpz",
        "outputId": "587b3970-12cf-4448-e7fc-7c311e43ad6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['interval', 'estimation', 'reinforcement_learning', 'algorithm', 'continuous', 'state', 'domain', 'awhite', 'abstract', 'reinforcement_learne', 'community', 'explore', 'many', 'approach', 'obtain', 'value', 'estimate', 'model', 'guide', 'decision_make', 'approach', 'however', 'usually', 'provide', 'measure', 'confidence', 'estimate', 'accurate', 'estimate', 'agent']\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Remove Stop Words\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized[:1][0][:30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCBs9JRm2Wpz"
      },
      "source": [
        "** **\n",
        "#### Step 4: Data transformation: Corpus and Dictionary\n",
        "** **\n",
        "\n",
        "The two main inputs to the LDA topic model are the dictionary(id2word) and the corpus. Let’s create them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikJ3U5cu2Wpz",
        "outputId": "91094d22-4fa1-4fc7-d2e9-738af03e31e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 1), (1, 1), (2, 1), (3, 2), (4, 3), (5, 1), (6, 1), (7, 3), (8, 1), (9, 1), (10, 25), (11, 3), (12, 1), (13, 2), (14, 1), (15, 3), (16, 1), (17, 8), (18, 23), (19, 2), (20, 1), (21, 9), (22, 1), (23, 1), (24, 1), (25, 6), (26, 1), (27, 1), (28, 1), (29, 2)]\n"
          ]
        }
      ],
      "source": [
        "import gensim.corpora as corpora\n",
        "\n",
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1][0][:30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Me-A3oG2Wpz"
      },
      "source": [
        "** **\n",
        "#### Step 5: Base Model\n",
        "** **\n",
        "\n",
        "We have everything required to train the base LDA model. In addition to the corpus and dictionary, you need to provide the number of topics as well. Apart from that, alpha and eta are hyperparameters that affect sparsity of the topics. According to the Gensim docs, both defaults to 1.0/num_topics prior (we'll use default for the base model).\n",
        "\n",
        "chunksize controls how many documents are processed at a time in the training algorithm. Increasing chunksize will speed up training, at least as long as the chunk of documents easily fit into memory.\n",
        "\n",
        "passes controls how often we train the model on the entire corpus (set to 10). Another word for passes might be \"epochs\". iterations is somewhat technical, but essentially it controls how often we repeat a particular loop over each document. It is important to set the number of \"passes\" and \"iterations\" high enough."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Z_moaIzp2Wpz"
      },
      "outputs": [],
      "source": [
        "# Build LDA model\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=10,\n",
        "                                       random_state=100,\n",
        "                                       chunksize=100,\n",
        "                                       passes=10,\n",
        "                                       per_word_topics=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izJGQUUn2Wp0"
      },
      "source": [
        "** **\n",
        "The above LDA model is built with 10 different topics where each topic is a combination of keywords and each keyword contributes a certain weightage to the topic.\n",
        "\n",
        "You can see the keywords for each topic and the weightage(importance) of each keyword using `lda_model.print_topics()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyVyIk-i2Wp0",
        "outputId": "3b75b09c-b590-4bff-a18e-9bc7aab5edde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0,\n",
            "  '0.022*\"model\" + 0.012*\"use\" + 0.011*\"network\" + 0.010*\"learn\" + '\n",
            "  '0.009*\"neuron\" + 0.008*\"input\" + 0.008*\"time\" + 0.007*\"neural\" + '\n",
            "  '0.006*\"layer\" + 0.006*\"datum\"'),\n",
            " (1,\n",
            "  '0.029*\"image\" + 0.011*\"use\" + 0.010*\"model\" + 0.010*\"network\" + '\n",
            "  '0.008*\"domain\" + 0.008*\"feature\" + 0.007*\"learn\" + 0.007*\"object\" + '\n",
            "  '0.006*\"set\" + 0.006*\"show\"'),\n",
            " (2,\n",
            "  '0.009*\"problem\" + 0.009*\"matrix\" + 0.008*\"function\" + 0.008*\"set\" + '\n",
            "  '0.007*\"feature\" + 0.007*\"use\" + 0.007*\"result\" + 0.006*\"let\" + 0.005*\"give\" '\n",
            "  '+ 0.005*\"follow\"'),\n",
            " (3,\n",
            "  '0.010*\"model\" + 0.009*\"use\" + 0.007*\"method\" + 0.007*\"system\" + '\n",
            "  '0.006*\"image\" + 0.006*\"problem\" + 0.006*\"distribution\" + 0.006*\"give\" + '\n",
            "  '0.005*\"time\" + 0.005*\"value\"'),\n",
            " (4,\n",
            "  '0.009*\"function\" + 0.008*\"use\" + 0.008*\"set\" + 0.008*\"learn\" + '\n",
            "  '0.007*\"information\" + 0.006*\"problem\" + 0.006*\"value\" + 0.006*\"datum\" + '\n",
            "  '0.005*\"pattern\" + 0.005*\"model\"'),\n",
            " (5,\n",
            "  '0.012*\"state\" + 0.009*\"model\" + 0.009*\"value\" + 0.008*\"learn\" + 0.008*\"set\" '\n",
            "  '+ 0.008*\"use\" + 0.007*\"action\" + 0.007*\"function\" + 0.007*\"problem\" + '\n",
            "  '0.007*\"distribution\"'),\n",
            " (6,\n",
            "  '0.014*\"model\" + 0.011*\"datum\" + 0.007*\"set\" + 0.007*\"use\" + '\n",
            "  '0.007*\"distribution\" + 0.006*\"figure\" + 0.006*\"mismatch_error\" + '\n",
            "  '0.006*\"result\" + 0.005*\"show\" + 0.005*\"cluster\"'),\n",
            " (7,\n",
            "  '0.012*\"network\" + 0.009*\"learn\" + 0.009*\"datum\" + 0.009*\"set\" + '\n",
            "  '0.009*\"model\" + 0.009*\"method\" + 0.008*\"point\" + 0.008*\"metric\" + '\n",
            "  '0.007*\"function\" + 0.007*\"use\"'),\n",
            " (8,\n",
            "  '0.012*\"feature\" + 0.010*\"action\" + 0.010*\"belief\" + 0.008*\"agent\" + '\n",
            "  '0.008*\"model\" + 0.008*\"learn\" + 0.008*\"reward\" + 0.008*\"local\" + '\n",
            "  '0.007*\"sample\" + 0.007*\"set\"'),\n",
            " (9,\n",
            "  '0.009*\"use\" + 0.008*\"problem\" + 0.008*\"set\" + 0.007*\"learn\" + 0.006*\"error\" '\n",
            "  '+ 0.006*\"show\" + 0.005*\"function\" + 0.005*\"datum\" + 0.005*\"algorithm\" + '\n",
            "  '0.005*\"matrix\"')]\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Print the Keyword in the 10 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuGyZac_2Wp0"
      },
      "source": [
        "#### Compute Model Perplexity and Coherence Score\n",
        "\n",
        "Let's calculate the baseline coherence score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yYG1wHd2Wp0",
        "outputId": "ccb09d48-d50b-41c2-a5b4-462ae1efcf1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence Score:  0.27904207726822483\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('Coherence Score: ', coherence_lda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_4Lhvwd2Wp0"
      },
      "source": [
        "** **\n",
        "#### Step 6: Hyperparameter tuning\n",
        "** **\n",
        "First, let's differentiate between model hyperparameters and model parameters :\n",
        "\n",
        "- `Model hyperparameters` can be thought of as settings for a machine learning algorithm that are tuned by the data scientist before training. Examples would be the number of trees in the random forest, or in our case, number of topics K\n",
        "\n",
        "- `Model parameters` can be thought of as what the model learns during training, such as the weights for each word in a given topic.\n",
        "\n",
        "Now that we have the baseline coherence score for the default LDA model, let's perform a series of sensitivity tests to help determine the following model hyperparameters:\n",
        "- Number of Topics (K)\n",
        "- Dirichlet hyperparameter alpha: Document-Topic Density\n",
        "- Dirichlet hyperparameter beta: Word-Topic Density\n",
        "\n",
        "We'll perform these tests in sequence, one parameter at a time by keeping others constant and run them over the two difference validation corpus sets. We'll use `C_v` as our choice of metric for performance comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "iK11HhgX2Wp0"
      },
      "outputs": [],
      "source": [
        "# supporting function\n",
        "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
        "\n",
        "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                           id2word=dictionary,\n",
        "                                           num_topics=k,\n",
        "                                           random_state=100,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha=a,\n",
        "                                           eta=b)\n",
        "\n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "\n",
        "    return coherence_model_lda.get_coherence()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHQFqG_W2Wp0"
      },
      "source": [
        "Let's call the function, and iterate it over the range of topics, alpha, and beta parameter values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a25LEZf72Wp0",
        "outputId": "e60643a7-eedb-4fb9-d860-3b3064ecec5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 540/540 [1:58:31<00:00, 13.17s/it]\n",
            "100%|██████████| 540/540 [1:43:54<00:00, 11.54s/it]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "grid = {}\n",
        "grid['Validation_Set'] = {}\n",
        "\n",
        "# Topics range\n",
        "min_topics = 2\n",
        "max_topics = 11\n",
        "step_size = 1\n",
        "topics_range = range(min_topics, max_topics, step_size)\n",
        "\n",
        "# Alpha parameter\n",
        "alpha = list(np.arange(0.01, 1, 0.3))\n",
        "alpha.append('symmetric')\n",
        "alpha.append('asymmetric')\n",
        "\n",
        "# Beta parameter\n",
        "beta = list(np.arange(0.01, 1, 0.3))\n",
        "beta.append('symmetric')\n",
        "\n",
        "# Validation sets\n",
        "num_of_docs = len(corpus)\n",
        "corpus_sets = [gensim.utils.ClippedCorpus(corpus, int(num_of_docs*0.75)),\n",
        "               corpus]\n",
        "\n",
        "corpus_title = ['75% Corpus', '100% Corpus']\n",
        "\n",
        "model_results = {'Validation_Set': [],\n",
        "                 'Topics': [],\n",
        "                 'Alpha': [],\n",
        "                 'Beta': [],\n",
        "                 'Coherence': []\n",
        "                }\n",
        "\n",
        "# Can take a long time to run\n",
        "if 1 == 1:\n",
        "    pbar = tqdm.tqdm(total=(len(beta)*len(alpha)*len(topics_range)*len(corpus_title)))\n",
        "\n",
        "    # iterate through validation corpuses\n",
        "    for i in range(len(corpus_sets)):\n",
        "        # iterate through number of topics\n",
        "        for k in topics_range:\n",
        "            # iterate through alpha values\n",
        "            for a in alpha:\n",
        "                # iterare through beta values\n",
        "                for b in beta:\n",
        "                    # get the coherence score for the given parameters\n",
        "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word,\n",
        "                                                  k=k, a=a, b=b)\n",
        "                    # Save the model results\n",
        "                    model_results['Validation_Set'].append(corpus_title[i])\n",
        "                    model_results['Topics'].append(k)\n",
        "                    model_results['Alpha'].append(a)\n",
        "                    model_results['Beta'].append(b)\n",
        "                    model_results['Coherence'].append(cv)\n",
        "\n",
        "                    pbar.update(1)\n",
        "    pd.DataFrame(model_results).to_csv('./results/lda_tuning_results.csv', index=False)\n",
        "    pbar.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjPvti4y2Wp0"
      },
      "source": [
        "** **\n",
        "#### Step 7: Final Model\n",
        "** **\n",
        "\n",
        "Based on external evaluation (Code to be added from Excel based analysis), let's train the final model with parameters yielding highest coherence score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQsRy0HC2Wp0"
      },
      "outputs": [],
      "source": [
        "num_topics = 8\n",
        "\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=num_topics,\n",
        "                                           random_state=100,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha=0.01,\n",
        "                                           eta=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6l2ZcBS2Wp0"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Print the Keyword in the 10 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WgXquyB2Wp0"
      },
      "source": [
        "** **\n",
        "#### Step 8: Visualize Results\n",
        "** **"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxRr2MEvtA63",
        "outputId": "4f754c8f-1b2f-416d-e260-8f48ee92fc9f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.4.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.4)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.10.1)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.5.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (75.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.5.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pyLDAvis) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.16.0)\n",
            "Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-2.0 pyLDAvis-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "oGsqCWl52Wp0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "outputId": "a6347c38-db7a-4e00-e1ab-338f7598ae85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "5      0.095123  0.042318       1        1  30.862750\n",
              "0      0.055989 -0.056043       2        1  19.046482\n",
              "7      0.047643  0.023374       3        1  17.425151\n",
              "4      0.014556  0.004819       4        1  11.459484\n",
              "3      0.014947 -0.026600       5        1  10.981769\n",
              "1     -0.021957 -0.031103       6        1   6.606653\n",
              "2     -0.064875  0.049092       7        1   3.171181\n",
              "6     -0.141425 -0.005856       8        1   0.446530, topic_info=             Term         Freq        Total Category  logprob  loglift\n",
              "440       network   665.000000   665.000000  Default  30.0000  30.0000\n",
              "965         image   638.000000   638.000000  Default  29.0000  29.0000\n",
              "422         model  1420.000000  1420.000000  Default  28.0000  28.0000\n",
              "2123       neuron   222.000000   222.000000  Default  27.0000  27.0000\n",
              "335   information   338.000000   338.000000  Default  26.0000  26.0000\n",
              "...           ...          ...          ...      ...      ...      ...\n",
              "587      response     0.736714   136.302579   Topic8  -7.0007   0.1910\n",
              "1066        phase     0.695120    95.590942   Topic8  -7.0588   0.4877\n",
              "634          show     0.678984   729.839649   Topic8  -7.0823  -1.5686\n",
              "719          time     0.657417   637.900603   Topic8  -7.1145  -1.4662\n",
              "592        result     0.621481   649.955457   Topic8  -7.1708  -1.5411\n",
              "\n",
              "[565 rows x 6 columns], token_table=      Topic      Freq      Term\n",
              "term                           \n",
              "7546      1  0.221355  abruptly\n",
              "7546      2  0.221355  abruptly\n",
              "7546      3  0.221355  abruptly\n",
              "7546      4  0.221355  abruptly\n",
              "7546      5  0.221355  abruptly\n",
              "...     ...       ...       ...\n",
              "1219      3  0.255443      word\n",
              "1219      4  0.275092      word\n",
              "1219      5  0.137546      word\n",
              "1219      6  0.072048      word\n",
              "1219      7  0.006550      word\n",
              "\n",
              "[2598 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[6, 1, 8, 5, 4, 2, 3, 7])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1631363616018563683800250488\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1631363616018563683800250488_data = {\"mdsDat\": {\"x\": [0.0951233222248219, 0.055988655589287846, 0.047642752933557755, 0.014555763969202216, 0.014946829708565526, -0.021956999248125133, -0.06487525626474698, -0.1414250689125628], \"y\": [0.042317750829281596, -0.056043498514897004, 0.023374059373271548, 0.0048187544217579625, -0.026599976261261673, -0.03110308265890866, 0.049091669676170735, -0.005855676865414386], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [30.86275041867869, 19.046481950724502, 17.425151035963133, 11.459483880778519, 10.981768696788102, 6.606652996380957, 3.1711808219377637, 0.44653019874834166]}, \"tinfo\": {\"Term\": [\"network\", \"image\", \"model\", \"neuron\", \"information\", \"policy\", \"action\", \"matrix\", \"problem\", \"feature\", \"error\", \"input\", \"algorithm\", \"metric\", \"pattern\", \"column\", \"frequency\", \"agent\", \"bind\", \"belief\", \"bound\", \"layer\", \"result\", \"decrease\", \"regret\", \"reward\", \"response\", \"output\", \"use\", \"arm\", \"policy\", \"agent\", \"belief\", \"reinforcement_learning\", \"pomdp\", \"route\", \"action\", \"tps\", \"environment\", \"reward\", \"robot\", \"exploration\", \"reinforcement_learne\", \"confidence_interval\", \"equivalence_relation\", \"pq_route\", \"bootstrap\", \"pomdps\", \"bregman_divergence\", \"tp\", \"mrbcd\", \"nonparametric\", \"variance_asymptotic\", \"stop\", \"weighted_classification\", \"tpdp\", \"coordinate_descent\", \"coverage_error\", \"network_load\", \"spvrg\", \"state\", \"goal\", \"joint\", \"transition\", \"divergence\", \"tree\", \"node\", \"communication\", \"path\", \"variance\", \"value\", \"estimation\", \"observation\", \"method\", \"step\", \"problem\", \"sample\", \"estimate\", \"optimal\", \"space\", \"iteration\", \"function\", \"consider\", \"give\", \"mean\", \"probability\", \"distribution\", \"set\", \"parameter\", \"model\", \"use\", \"result\", \"follow\", \"base\", \"number\", \"time\", \"learn\", \"approach\", \"datum\", \"show\", \"bird\", \"spike\", \"hsld\", \"neuron\", \"rosetta\", \"fisher_vector\", \"lar\", \"neuronal\", \"linear_dynamical\", \"plasticity\", \"dynamic_texture\", \"native\", \"layered_dynamic\", \"firing\", \"spike_time\", \"texture\", \"firing_rate\", \"activity\", \"orientation\", \"excitability\", \"residue\", \"caption\", \"dbn\", \"gpfa\", \"beak\", \"gmm\", \"visible\", \"decoy\", \"proposed_scfvc\", \"visible_neuron\", \"ip\", \"keypoint\", \"response\", \"cortical\", \"intensity\", \"energy\", \"stimulus\", \"video\", \"feature\", \"rule\", \"image\", \"layer\", \"model\", \"visual\", \"text\", \"trial\", \"direction\", \"group\", \"neural\", \"input\", \"dynamic\", \"network\", \"structure\", \"use\", \"time\", \"pattern\", \"learn\", \"local\", \"figure\", \"show\", \"datum\", \"weight\", \"different\", \"distribution\", \"variable\", \"set\", \"result\", \"performance\", \"method\", \"give\", \"parameter\", \"sample\", \"value\", \"function\", \"privacy\", \"isomap\", \"private\", \"rac\", \"submodular\", \"privacy_preserving\", \"bayes_error\", \"preference_graph\", \"isoform\", \"bep\", \"domain_adaptation\", \"metric\", \"manifold\", \"alternative_splice\", \"order_optimality\", \"exon\", \"victim\", \"mlb\", \"gi\", \"anchor_point\", \"matrix_completion\", \"landmark\", \"unsupervised_domain\", \"prl\", \"stroke\", \"splice\", \"differential_privacy\", \"minkowski\", \"logistic_regression\", \"label_ranking\", \"character\", \"domain\", \"loss\", \"probe\", \"satisfie\", \"task\", \"error\", \"penalize\", \"instance\", \"classifier\", \"label\", \"scenario\", \"training\", \"function\", \"rank\", \"learn\", \"target\", \"set\", \"curve\", \"learning\", \"example\", \"problem\", \"prediction\", \"class\", \"test\", \"matrix\", \"use\", \"distance\", \"local\", \"point\", \"datum\", \"network\", \"give\", \"case\", \"show\", \"number\", \"model\", \"method\", \"result\", \"value\", \"figure\", \"stress\", \"lpmrf\", \"mismatch_error\", \"reeb_graph\", \"syllable\", \"primary_stress\", \"tumor\", \"patient\", \"orl_cf\", \"registration\", \"chip\", \"transaction\", \"stock\", \"anatomical_registration\", \"pmrf\", \"relevance_relation\", \"file\", \"hopf_bifurcation\", \"condensation\", \"starter_file\", \"principal_curve\", \"lpmrf_topic\", \"constraint_satisfaction\", \"functional_connectivity\", \"topic\", \"linguistic\", \"wealth\", \"bifurcation\", \"quantization\", \"kl_distance\", \"codeword\", \"language\", \"functional\", \"regret\", \"multinomial\", \"learner\", \"subspace\", \"alignment\", \"anneal\", \"software\", \"point\", \"contour\", \"distribution\", \"kernel\", \"dependency\", \"set\", \"region\", \"system\", \"map\", \"model\", \"datum\", \"use\", \"pattern\", \"type\", \"parameter\", \"show\", \"base\", \"word\", \"learn\", \"result\", \"time\", \"give\", \"number\", \"function\", \"space\", \"vector\", \"weight\", \"value\", \"method\", \"figure\", \"problem\", \"adversarial_example\", \"primitive\", \"audio\", \"short_dot\", \"searchlight\", \"aud\", \"lucid\", \"familiarity\", \"recollection\", \"driven_searchlight\", \"robustness\", \"memorized\", \"cn\", \"flow_graph\", \"brief\", \"voxel\", \"neural_net\", \"straggler\", \"processor\", \"descriptor\", \"mri\", \"power_iteration\", \"dot_product\", \"pattern_age\", \"permutation\", \"repetition\", \"mds_code\", \"cayley\", \"bike\", \"adversarial_severity\", \"sound\", \"transform\", \"cone\", \"reconstruction\", \"event\", \"net\", \"memory\", \"row\", \"recall\", \"category\", \"semantic\", \"image\", \"brain\", \"activation\", \"pattern\", \"vector\", \"layer\", \"use\", \"matrix\", \"datum\", \"compute\", \"constraint\", \"figure\", \"show\", \"time\", \"learn\", \"approach\", \"neural\", \"number\", \"set\", \"system\", \"error\", \"model\", \"method\", \"example\", \"give\", \"parameter\", \"result\", \"sample\", \"feature\", \"mixed_membership\", \"advertisement\", \"mmsb\", \"attacker\", \"triangle\", \"subsample\", \"budget\", \"memorability\", \"advertiser\", \"acoustic_signal\", \"ptr_net\", \"speech_signal\", \"collective_information\", \"revenue\", \"community\", \"triangular_motif\", \"opt\", \"invocation\", \"budget_constraint\", \"bxyz_bxyz\", \"query_phrase\", \"mmtm\", \"bmix\", \"vowel\", \"forget\", \"pol\", \"subsampling\", \"community_detection\", \"codebook\", \"attractor\", \"memorable\", \"vertex\", \"ad\", \"hidden_unit\", \"synchronization\", \"mutual\", \"network\", \"information\", \"speech\", \"attention\", \"output\", \"degree\", \"input\", \"sequence\", \"edge\", \"visual\", \"bandit\", \"image\", \"model\", \"use\", \"weight\", \"unit\", \"figure\", \"neural\", \"vector\", \"training\", \"problem\", \"signal\", \"probability\", \"show\", \"set\", \"learn\", \"region\", \"number\", \"well\", \"performance\", \"train\", \"different\", \"time\", \"reflectance\", \"adaptive_sampling\", \"copeland_winner\", \"adaptive_sample\", \"condorcet_winner\", \"copeland\", \"rating\", \"arm\", \"paint\", \"dueling_bandit\", \"cpld\", \"shading\", \"ccb\", \"beat\", \"lc\", \"trimmed_graphical\", \"copeland_duele\", \"scb\", \"armed_duele\", \"cssp\", \"round\", \"copeland_score\", \"ranker_evaluation\", \"armed\", \"expban\", \"clique_partition\", \"ect\", \"continued_sample\", \"winner\", \"ggm\", \"column\", \"bandit\", \"singular_value\", \"regret\", \"eigenvalue\", \"residual\", \"preference\", \"relative\", \"ai\", \"bind\", \"matrix\", \"algorithm\", \"bound\", \"log\", \"result\", \"problem\", \"shape\", \"number\", \"image\", \"set\", \"rank\", \"sample\", \"probability\", \"graph\", \"guarantee\", \"use\", \"give\", \"error\", \"choose\", \"well\", \"follow\", \"habituation\", \"vor\", \"anastasio\", \"nystagmus\", \"pan\", \"velocity_storage\", \"prolong\", \"vor_gain\", \"periodic_alternate\", \"eye_velocity\", \"purkinje_cell\", \"central_adaptation\", \"vestibular\", \"darkness\", \"cerebellum\", \"habituate\", \"eye_movement\", \"resonance\", \"temporary\", \"furman\", \"cerebellar\", \"robinson\", \"resonant\", \"vestibulo\", \"canal\", \"goldfish\", \"superimpose\", \"unstable\", \"lesion\", \"abruptly\", \"rotation\", \"frequency\", \"decrease\", \"loop\", \"head\", \"pathway\", \"oscillation\", \"eye\", \"gain\", \"increase\", \"cause\", \"low\", \"model\", \"produce\", \"response\", \"phase\", \"show\", \"time\", \"result\"], \"Freq\": [665.0, 638.0, 1420.0, 222.0, 338.0, 286.0, 389.0, 375.0, 849.0, 595.0, 404.0, 383.0, 343.0, 191.0, 326.0, 80.0, 67.0, 207.0, 134.0, 211.0, 183.0, 247.0, 649.0, 70.0, 68.0, 235.0, 136.0, 235.0, 1258.0, 52.0, 272.9950782068662, 196.24404642058934, 199.07334402799984, 61.22550298675405, 45.91385336000868, 44.097469222981, 352.50854982784386, 31.25443779875888, 71.34320200616655, 210.39485373776236, 47.47894190972052, 98.52008000008068, 29.10912161622411, 31.36924023130081, 26.54038588307487, 24.869180621876804, 24.053714845981435, 25.440963216421828, 23.09495500060424, 23.28935187825953, 19.535886069841045, 26.702911807491123, 18.65589942090971, 25.212360112088813, 17.829658212002713, 17.81645481015825, 24.144961264763417, 17.793323243729425, 17.733214346208175, 16.867145016279782, 446.6227234221674, 153.65927496103848, 91.31116244921306, 78.50702080842589, 36.78811214696031, 70.29999828295027, 72.05070529386754, 56.385014553444314, 93.4497330090294, 118.5266407567348, 414.2146182625907, 121.47499177493842, 165.90012783260806, 411.23751540984955, 235.47419433300556, 430.63610496483403, 313.51835613995706, 225.81526921278478, 131.22587072615974, 238.85330247407668, 116.81804022205313, 387.8184566554092, 162.6672897710416, 305.4197319336518, 160.41648948242982, 185.50478087503132, 260.73477556487416, 368.78107340544716, 233.91553266395505, 425.79627353045834, 393.21620377861154, 260.0265957634193, 186.93677835355817, 203.7875000227229, 231.62355610551919, 238.91866411059996, 301.5588159010593, 193.2255721498259, 221.35321867040017, 216.7885071658728, 50.56484010972212, 43.17613288429591, 38.04952648942917, 199.44325680630718, 33.16023889665894, 24.385613391524227, 26.856082992610016, 27.520010808771872, 21.36835089713184, 22.241366066036072, 27.726836032582707, 30.090102400212757, 18.986042100776398, 18.946311328752525, 19.561843234827105, 43.84311768569533, 19.9674889174275, 100.21628594875138, 43.255534211956835, 14.933142056020651, 14.957895005429481, 16.6025129189814, 18.102958751995853, 14.2149351887792, 14.174756808279968, 14.125597153686522, 36.590611898404504, 13.377809990026167, 13.34220102968013, 14.59038737142157, 26.836299902326736, 34.740519615319414, 96.88712264276006, 32.846379045275455, 41.669021097260476, 45.03671084753927, 62.1796457661017, 51.16654231895703, 336.83537363041245, 84.6398161025, 300.2717266300259, 136.17903763948635, 555.5559351861187, 92.36786675421195, 50.10333369228166, 57.40863720753631, 92.36274434690645, 68.01035434320374, 167.18930463948342, 156.90962875495543, 82.36472860451636, 217.46342003363836, 114.7872304524752, 300.53577950065767, 186.0867162477123, 122.21247296699804, 221.80010786619962, 118.87691066630063, 154.93795155802908, 176.15295540448497, 177.5223723869919, 116.07965877721978, 105.99182427224889, 123.16035115520985, 89.27046427781364, 138.36961344578094, 118.07261243082256, 89.83901134446543, 111.83942153864106, 107.87356227382081, 99.997427483641, 101.25349313959785, 97.78922031928548, 97.2308779229868, 33.924263119775944, 40.6900595830215, 32.107254560141484, 22.933488560654197, 20.55245091865826, 20.486465390502378, 19.738441485022687, 18.220337286378435, 18.14298108529401, 17.250493441342854, 16.33315632289735, 153.0021883209088, 40.27480231385538, 12.593763989697809, 13.085746674071256, 11.797809539304062, 11.800257392503957, 11.797446860379097, 20.053099883973804, 11.031120982718802, 11.55262940428242, 14.501371581137649, 10.829410900921383, 10.245044253527029, 10.251786408833414, 10.220278332911597, 10.210656782393334, 10.190626805815807, 28.000440012542548, 9.472119455781348, 29.875440473191752, 113.34634212397005, 106.14147829059075, 27.636398516628528, 34.35085800758883, 163.068333619757, 211.96689888430217, 28.932076780551125, 80.82295619254455, 78.13240376511055, 96.56840004019293, 37.0960932351627, 154.96871241507841, 299.9019392139984, 52.867444294322034, 308.67974613582567, 67.31663142811685, 256.15575786527154, 68.09926133025972, 95.6252365095919, 127.16259852505588, 194.34278187803025, 81.10452725544488, 95.06337248268629, 87.72209730114427, 105.94495956738005, 207.88531209908894, 66.18825373867014, 95.70891526023914, 110.0314971494627, 143.46204682594478, 130.08005757874022, 129.75074878756948, 94.22809812777932, 122.18694483576253, 111.17161278163539, 151.98295586986333, 113.79162002637837, 106.91597683941843, 108.5541396984947, 93.28031434312658, 57.33958518238584, 36.98855664104019, 27.625055468890363, 29.355471447308506, 32.272787555243696, 20.394666031811745, 19.688973878192307, 19.609945989261906, 21.32119765328899, 24.291839078903408, 31.024091599436996, 26.840283497074733, 16.8991429101133, 12.442111994942286, 12.92195894101327, 13.46937673079265, 45.34232584665905, 11.693269036766356, 11.137019648830707, 11.107035932295245, 11.043011978206014, 10.982482984470158, 9.845356452383793, 9.814838347473637, 52.17343961268264, 12.474081100151192, 11.055407373184263, 11.0408406103016, 12.42808626254971, 8.485508318469087, 18.009935266157605, 32.23751913017114, 47.38579800771862, 41.2525121306907, 31.2632198301115, 16.66447576566733, 35.68924293531939, 24.97095310969731, 19.719139950986705, 18.252024672639465, 113.99361710501987, 26.920875302265543, 118.82925101283224, 47.393169548146055, 30.35242881445523, 125.75129171559614, 50.7436409462633, 70.47702763093652, 47.29809310077197, 130.99769336174853, 93.09332909644532, 116.8993372871385, 59.84728082645778, 43.700742727146796, 68.40876951054982, 75.48064667529162, 63.24582664812277, 41.50840506061384, 78.19259099063025, 66.91566061553152, 65.72758664307615, 63.70722904357969, 59.095958547754734, 64.91521970095138, 54.694385673132345, 52.03991135547736, 50.24084488768533, 54.44806222000262, 53.15823103974647, 50.845465782875344, 46.873635358781016, 37.16949980911982, 52.372317410954345, 36.4087676576404, 27.61198494827416, 25.824394127123426, 25.15838112901034, 21.25983687975196, 23.56947554821475, 15.659972575294411, 14.534811710142227, 42.06428484620772, 13.87413276923389, 18.784129532921746, 11.814657796002445, 33.277630943232445, 31.793994584251557, 14.562284014313702, 10.486209055324085, 48.03910941577287, 32.1194102650816, 11.818485031232669, 11.836064620935453, 24.958126571760072, 9.731365314141419, 29.26798692752983, 15.126920992702951, 8.503988219777298, 7.931322380060659, 7.930593272653631, 7.910425351655897, 17.177627002723206, 30.97585506163211, 17.059402815330298, 60.17510452037938, 48.91620016553389, 39.760772994590646, 64.24292667790944, 39.03136931534653, 28.447213359738328, 34.523312105453, 25.21750826778027, 136.40249695207473, 35.183455210282844, 41.67730703933094, 81.07370687128936, 94.43385248065556, 62.41696397550884, 147.36471708718045, 77.65162389670363, 109.91171485731459, 65.43526495345583, 49.31928314491257, 84.31638776046583, 91.56090080026961, 78.2809338594096, 93.13468029565273, 62.675206875198064, 57.908321165063, 61.56735710305274, 68.53863772072948, 53.654722440222216, 53.53962531348612, 65.75104484337965, 58.6169394966401, 52.286338287965584, 54.87161890493865, 51.384744900075056, 51.824588780528074, 51.04792505354842, 50.35221308038906, 21.390665440458935, 27.11274911933247, 16.5657020023067, 15.988957479090244, 33.700760008620556, 14.951796531930846, 13.23633164579709, 16.4718945440381, 12.258426455598254, 10.016122970522797, 10.038008638900603, 10.011750571292264, 9.058675456532686, 12.722389535859719, 28.354744438087927, 7.4514761882887575, 8.221786407695827, 8.60177366178015, 7.598016313009821, 6.379368074413206, 7.062045108860012, 5.841794121373478, 6.5683406626860075, 5.7594506343676715, 8.640607250869687, 6.05644968143226, 5.306440483802886, 6.378693415996901, 8.486640313633956, 9.558621711480853, 6.663286476486764, 23.000095467800737, 22.58539011059052, 15.428805793208515, 13.851114649835367, 12.12743689406413, 145.08990851003372, 85.45686084032745, 14.700155208826768, 13.86301063920685, 49.90239293576136, 20.792819217261737, 59.039454092130114, 44.55433876889959, 33.08093760559652, 33.035910248425, 19.96591218877013, 65.17639212398382, 85.47599356817062, 75.23154015012297, 39.96322488793788, 29.677414700098236, 44.70447637559902, 38.72191745619513, 38.13442574276808, 35.05260002193062, 45.41714403056418, 25.343654110916933, 32.37155064253809, 38.18464427966298, 40.16481198723916, 38.59590602435819, 26.38783596155415, 32.029459139682864, 27.870148924896895, 26.96706467592579, 24.860595899875747, 25.708704887183956, 25.50011080924317, 9.890216090419564, 7.771473256458643, 7.426203919548663, 6.704161371268726, 6.359984851321916, 6.359214198136268, 5.9810300163631, 30.511882728157122, 5.269074469428534, 4.936426667150984, 4.581997385242982, 5.57080925363476, 4.226527420759044, 5.984463533635152, 4.927895342552878, 4.371199676943268, 3.8712569705647124, 3.8710795131312437, 3.5154668474719926, 3.5108489438643216, 20.8612368464789, 3.1601492758122767, 3.1599173446280444, 2.78948364132624, 4.489727540514109, 4.185042484702115, 2.44656703573758, 2.446364847889654, 4.22682050958984, 2.6333825917149545, 28.244264135943855, 21.62352847848249, 4.202313671447262, 20.2881435793051, 13.337198070558946, 6.684614986393529, 6.720435320760632, 16.126160535110245, 12.671111761130799, 19.9098938953531, 25.56078958845394, 24.142859912935517, 16.134397768293184, 19.11015373196572, 23.767521733993654, 25.952024745164636, 13.494653277459152, 19.978986663008648, 20.166780072941446, 22.353185320856884, 10.895501422592853, 17.68875645130667, 14.989109549540997, 11.717494948654108, 9.90581095609827, 17.303959223029768, 14.709151900432953, 12.947101849692435, 11.301419761595245, 11.845269647868362, 11.234715818298334, 1.8023352659146512, 1.4087088507828684, 1.1725299147271557, 0.8572917186537533, 0.936683111006002, 0.7786588472848928, 0.6210705719570517, 0.6210505254318999, 0.6210009267522987, 0.6209574455568988, 0.542430500779862, 0.5424080072610296, 0.5423709258952557, 0.38491175301284714, 0.3848946711146543, 0.3848344844816279, 0.5425960963714336, 0.47775292848610623, 0.3061594024717785, 0.3061491909789194, 0.30615166150138534, 0.3061339207972016, 0.30612961502947533, 0.3060974276510624, 0.3060894043352446, 0.30608500445237674, 0.3061621082820983, 0.788887139696723, 0.30598065428917415, 0.2275038964113732, 1.9987285317189099, 2.39500033524961, 1.9468533950737419, 1.0050567260814596, 0.6741293947375968, 0.7168870799867456, 0.6105948508380651, 0.860752426523989, 0.8885811445010429, 1.1976650573528147, 0.6783348827805531, 1.0729225899682109, 1.5901302798680526, 0.7853616335515244, 0.7367141756860942, 0.6951195182987505, 0.6789840890270215, 0.6574169455329745, 0.6214811492620993], \"Total\": [665.0, 638.0, 1420.0, 222.0, 338.0, 286.0, 389.0, 375.0, 849.0, 595.0, 404.0, 383.0, 343.0, 191.0, 326.0, 80.0, 67.0, 207.0, 134.0, 211.0, 183.0, 247.0, 649.0, 70.0, 68.0, 235.0, 136.0, 235.0, 1258.0, 52.0, 286.7498481268228, 207.38660606023413, 211.84356471695685, 65.40747295284898, 50.113272976539264, 48.19450504654272, 389.64406762751963, 34.91391409755304, 79.86092343487095, 235.89361387356723, 53.40978475641798, 111.4097652677603, 33.06096404037621, 35.84521110875114, 30.342862647941693, 28.59042500986812, 27.713045227178025, 29.456044736358812, 26.798735472115787, 27.540287243535307, 23.21294754827984, 31.73988271692783, 22.309152788585454, 30.178040981941994, 21.426942581514552, 21.421287849214412, 29.06497896604837, 21.419316287632043, 21.40046301709802, 20.51425053216023, 586.9902052792141, 200.64027444962167, 118.83919026317534, 101.92883431743165, 46.81588134693638, 95.13128936665296, 97.83179037201535, 74.77354808616339, 131.82541575770705, 173.37565185105026, 733.9705698352228, 180.26955301465887, 264.38750187506145, 773.6568131708286, 404.2825692136, 849.5510425109094, 601.2961399913487, 412.69175580128496, 214.3238387408712, 479.35277081870964, 190.8208681700106, 915.6523271026248, 294.85761107789693, 694.2431842239229, 290.2287403143229, 358.64345398744047, 610.5474230576322, 1020.3401348624913, 527.8734810944537, 1420.2775795581913, 1258.8475499099432, 649.9554574175487, 386.8748368071465, 461.14280360720346, 589.0595709124458, 637.9006026017897, 1045.5018854076484, 438.99339179638224, 769.1462498713181, 729.8396493853038, 54.61652839716412, 47.468390658560196, 41.882943705465635, 222.1712546102894, 37.09392454490604, 28.254595067460173, 31.365878351963417, 32.172225932564245, 25.1042411233102, 26.223022768643382, 32.83467877918708, 35.9148289567544, 22.71002374746265, 22.7104173590905, 23.487559433004616, 52.74073241758894, 24.414946590051144, 123.23673394218635, 53.689907460441276, 18.679349649637775, 18.715131978300125, 20.86323694924826, 22.78599488127785, 17.914540489020457, 17.903090716732244, 17.887567410538825, 46.70209277642885, 17.114996758859782, 17.092790130800516, 18.724785776069982, 34.6804261312336, 45.35185279992051, 136.3025792068915, 43.77679620533549, 57.067680251321235, 62.509497949404455, 88.83750661560293, 72.09428244816375, 595.352585432944, 129.86309848113677, 638.3578134278343, 247.88853853108583, 1420.2775795581913, 157.43993851556993, 74.92392799389921, 90.5921458350629, 171.39406694685138, 116.2861749484296, 403.7536339281289, 383.86212770626804, 156.3595725452792, 665.7275972191946, 279.7729841949456, 1258.8475499099432, 637.9006026017897, 326.2881169832089, 1045.5018854076484, 348.9866754015906, 574.798325634433, 729.8396493853038, 769.1462498713181, 394.37035733377223, 384.08518906946864, 610.5474230576322, 285.35927508979364, 1020.3401348624913, 649.9554574175487, 314.8043278230141, 773.6568131708286, 694.2431842239229, 527.8734810944537, 601.2961399913487, 733.9705698352228, 915.6523271026248, 37.95405738467431, 45.780795978453696, 36.824372403828036, 26.77136995819783, 24.367340280326935, 24.349026186938858, 23.577510616882638, 21.96592614704849, 21.92306410145751, 21.172500312678306, 20.280320315747577, 191.78216841020577, 51.69194044190668, 16.32287999130631, 17.108080187653393, 15.524714652940238, 15.552482258978118, 15.553612215908743, 26.775132990616015, 14.743311018898178, 15.511635811983115, 19.56454392288114, 14.69354421854144, 13.924365929102535, 13.944974607188868, 13.928094425171418, 13.940265874162725, 13.967393970657028, 38.6441755706175, 13.150297734074988, 41.75572368723436, 176.37432895379087, 167.05720713118788, 40.385524906242956, 52.20795681347983, 299.39548946591697, 404.0928849398798, 44.35888497216018, 148.28996113733336, 144.08553652891027, 193.1142786592099, 63.6843232053697, 379.90909239395677, 915.6523271026248, 101.4873450824068, 1045.5018854076484, 141.81991157804836, 1020.3401348624913, 154.92577426290364, 259.11911930249096, 416.1243548989033, 849.5510425109094, 222.13074859775975, 293.1708936546784, 263.5188732242156, 375.4979157392713, 1258.8475499099432, 174.0526764776763, 348.9866754015906, 465.03113880945557, 769.1462498713181, 665.7275972191946, 694.2431842239229, 388.52022116058, 729.8396493853038, 589.0595709124458, 1420.2775795581913, 773.6568131708286, 649.9554574175487, 733.9705698352228, 574.798325634433, 63.35554767054667, 41.776745948328006, 31.629389556774903, 33.6946113637849, 37.763867520221, 24.330450976272324, 23.657244021229957, 23.684142410200653, 25.794749984584193, 30.588331807730263, 39.53172489794623, 34.6179819941769, 21.884356428792604, 16.329949130654015, 17.045280757886168, 17.770737701627365, 59.938404704338375, 15.621963610233536, 14.994681877612784, 15.003424756868563, 15.01341242355988, 15.034834824121218, 13.661284650469023, 13.664575972261988, 73.98167918493088, 17.757973749912804, 15.779039461541071, 15.76264558726426, 17.760372643404533, 12.338425628585217, 26.333841801659403, 47.93150386996899, 80.10694358145228, 68.59372156823171, 50.545579146232164, 25.215069812294594, 66.51575859990261, 43.62495240979133, 32.13104656653122, 29.92145354687811, 465.03113880945557, 57.764618261404124, 610.5474230576322, 146.45993132441004, 71.72561044028939, 1020.3401348624913, 194.54099276687552, 374.54788839042493, 178.065010877162, 1420.2775795581913, 769.1462498713181, 1258.8475499099432, 326.2881169832089, 165.55233326195292, 527.8734810944537, 729.8396493853038, 461.14280360720346, 152.67593209039723, 1045.5018854076484, 649.9554574175487, 637.9006026017897, 694.2431842239229, 589.0595709124458, 915.6523271026248, 479.35277081870964, 421.7672143594984, 394.37035733377223, 733.9705698352228, 773.6568131708286, 574.798325634433, 849.5510425109094, 41.21482660210419, 59.22817396027167, 41.34596962357205, 31.838039004073252, 29.81046574345373, 29.14614555393424, 25.12994088386287, 27.895924678231637, 19.825190687201975, 18.414226547786587, 53.413861172995226, 17.74037852702883, 24.963685798790006, 15.759492371335488, 44.44631382481885, 42.503186193250514, 19.504044024188747, 14.397332430161958, 66.54085445445925, 44.562003801128526, 16.425743602109755, 16.57783945957841, 35.25765284980078, 13.768894863779344, 41.864488570043385, 21.865492600030777, 12.38584055231271, 11.71341549098657, 11.713206340181966, 11.712401279570054, 25.785900031735626, 48.04693755131211, 26.01986789451883, 99.73566295435099, 88.24439758280474, 78.77818129597578, 149.51697511647268, 79.486397020756, 52.58223515295151, 73.10540080867327, 46.745243076663456, 638.3578134278343, 79.35676711641383, 106.26478777340047, 326.2881169832089, 421.7672143594984, 247.88853853108583, 1258.8475499099432, 375.4979157392713, 769.1462498713181, 296.0110921515946, 163.6024665877806, 574.798325634433, 729.8396493853038, 637.9006026017897, 1045.5018854076484, 438.99339179638224, 403.7536339281289, 589.0595709124458, 1020.3401348624913, 374.54788839042493, 404.0928849398798, 1420.2775795581913, 773.6568131708286, 416.1243548989033, 694.2431842239229, 527.8734810944537, 649.9554574175487, 601.2961399913487, 595.352585432944, 25.42665406524564, 33.283355595572196, 20.5585403922387, 20.03102800778227, 43.10589698377181, 20.634153577001555, 18.28511231043742, 22.9628384495939, 17.139852955096963, 14.07670016763302, 14.110132121723268, 14.074836592489788, 12.982928800474461, 18.525511593593283, 43.241653752293736, 11.368260562831328, 12.647196257303346, 13.292553471325016, 12.165435381561656, 10.28613425169309, 11.625368198107994, 9.745895006617472, 11.056472065801563, 9.757175504894207, 14.857656831783357, 10.49942707289089, 9.205562827915193, 11.08299449902034, 14.849003515405457, 16.743670748666695, 11.731086815521513, 46.275038607275114, 48.36435043837115, 32.876097655093595, 28.972289242179222, 24.884066541814605, 665.7275972191946, 338.5260543158843, 32.80246029806032, 30.957154127091954, 235.6128271721294, 63.824878145508855, 383.86212770626804, 240.21389359000963, 148.48543340498546, 157.43993851556993, 63.089290299897954, 638.3578134278343, 1420.2775795581913, 1258.8475499099432, 394.37035733377223, 205.09030316449244, 574.798325634433, 403.7536339281289, 421.7672143594984, 379.90909239395677, 849.5510425109094, 153.71627418230923, 358.64345398744047, 729.8396493853038, 1020.3401348624913, 1045.5018854076484, 194.54099276687552, 589.0595709124458, 386.1425026517742, 314.8043278230141, 194.87516673262593, 384.08518906946864, 637.9006026017897, 14.125450893312706, 11.937858852286434, 11.569991687317225, 10.855667759929068, 10.485544828126484, 10.487341254651309, 10.150602449179999, 52.410354566622686, 9.430002182245518, 9.042978928483368, 8.680375737278748, 10.653307743019447, 8.318195611548626, 11.949488760119147, 9.95008621053239, 8.964914018687981, 7.957484776889835, 7.958435282609527, 7.596991293049319, 7.598872504340129, 46.51498928882699, 7.2354934811337355, 7.235151233472882, 6.894957566862124, 11.504433966435657, 11.064817667424405, 6.514552231476215, 6.51444755628795, 11.318374987250614, 7.111181286035659, 80.04328686259373, 63.089290299897954, 11.622840345384699, 68.59372156823171, 51.477531556946836, 21.149915768287954, 21.540020352821116, 83.69355076473727, 64.8497013788773, 134.9634858801165, 375.4979157392713, 343.9473186637472, 183.2468540102048, 377.5194831983176, 649.9554574175487, 849.5510425109094, 180.9581706283755, 589.0595709124458, 638.3578134278343, 1020.3401348624913, 101.4873450824068, 601.2961399913487, 358.64345398744047, 188.00857719616263, 99.3867464127145, 1258.8475499099432, 694.2431842239229, 404.0928849398798, 232.6916050074918, 386.1425026517742, 386.8748368071465, 6.193635591287912, 5.773525655953176, 5.521897198532816, 5.188641357575691, 6.065915341970007, 5.104651971268295, 4.9375157205147335, 4.9381474987709595, 4.938306157875139, 4.938391070727085, 4.853249196903503, 4.853386228075484, 4.854041931163194, 4.685775273197039, 4.685764058778872, 4.686402639689713, 6.6433788686988375, 6.530999161943915, 4.601998257493353, 4.60222589720189, 4.602325486560758, 4.60235059492604, 4.602465689287583, 4.602448583972959, 4.60255199332167, 4.602753201568188, 5.4954744331084555, 14.939331969112537, 5.951769073498461, 4.517636959164073, 46.58123693152868, 67.53249729367823, 70.01414854427935, 30.106243621050186, 21.641937920939984, 27.006277421448843, 19.62113814664949, 41.22198016853144, 57.81113723757906, 142.87557512067173, 40.1270523394872, 223.46397577506875, 1420.2775795581913, 119.77514405535337, 136.3025792068915, 95.59094164506793, 729.8396493853038, 637.9006026017897, 649.9554574175487], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.3215, -5.6515, -5.6372, -6.8163, -7.1041, -7.1445, -5.0658, -7.4887, -6.6634, -5.5819, -7.0706, -6.3406, -7.5599, -7.4851, -7.6522, -7.7173, -7.7506, -7.6945, -7.7913, -7.7829, -7.9587, -7.6461, -8.0047, -7.7036, -8.05, -8.0508, -7.7468, -8.0521, -8.0555, -8.1055, -4.8292, -5.8962, -6.4166, -6.5677, -7.3257, -6.6781, -6.6535, -6.8987, -6.3935, -6.1558, -4.9045, -6.1312, -5.8195, -4.9117, -5.4693, -4.8656, -5.1831, -5.5112, -6.054, -5.4551, -6.1703, -4.9704, -5.8392, -5.2092, -5.8531, -5.7078, -5.3674, -5.0207, -5.4759, -4.8769, -4.9565, -5.3701, -5.7001, -5.6138, -5.4858, -5.4548, -5.2219, -5.6671, -5.5311, -5.552, -6.525, -6.683, -6.8094, -5.1527, -6.9469, -7.2542, -7.1577, -7.1333, -7.3863, -7.3463, -7.1258, -7.044, -7.5045, -7.5066, -7.4747, -6.6676, -7.4541, -5.8409, -6.6811, -7.7447, -7.743, -7.6387, -7.5522, -7.7939, -7.7968, -7.8003, -6.8484, -7.8546, -7.8573, -7.7679, -7.1585, -6.9003, -5.8747, -6.9564, -6.7185, -6.6408, -6.3182, -6.5132, -4.6286, -6.0098, -4.7436, -5.5343, -4.1283, -5.9225, -6.5342, -6.398, -5.9225, -6.2286, -5.3291, -5.3926, -6.0371, -5.0662, -5.7052, -4.7427, -5.222, -5.6425, -5.0465, -5.6702, -5.4052, -5.2769, -5.2691, -5.694, -5.7849, -5.6348, -5.9566, -5.5183, -5.6769, -5.9502, -5.7312, -5.7673, -5.8431, -5.8306, -5.8654, -5.8712, -6.8351, -6.6533, -6.8902, -7.2267, -7.3363, -7.3395, -7.3767, -7.4567, -7.461, -7.5114, -7.5661, -5.3288, -6.6635, -7.8261, -7.7877, -7.8914, -7.8912, -7.8914, -7.3609, -7.9586, -7.9124, -7.685, -7.977, -8.0325, -8.0318, -8.0349, -8.0358, -8.0378, -7.0271, -8.1109, -6.9622, -5.6288, -5.6945, -7.0401, -6.8226, -5.2651, -5.0028, -6.9943, -5.967, -6.0009, -5.789, -6.7458, -5.316, -4.6558, -6.3915, -4.627, -6.1499, -4.8135, -6.1383, -5.7988, -5.5138, -5.0896, -5.9635, -5.8047, -5.8851, -5.6964, -5.0223, -6.1668, -5.798, -5.6585, -5.3932, -5.4911, -5.4937, -5.8136, -5.5537, -5.6482, -5.3355, -5.6249, -5.6872, -5.672, -5.8237, -5.8912, -6.3296, -6.6215, -6.5607, -6.466, -6.9249, -6.9601, -6.9641, -6.8805, -6.75, -6.5054, -6.6503, -7.1129, -7.4191, -7.3812, -7.3398, -6.1259, -7.4812, -7.5299, -7.5326, -7.5384, -7.5439, -7.6532, -7.6563, -5.9856, -7.4165, -7.5373, -7.5386, -7.4202, -7.8018, -7.0493, -6.467, -6.0819, -6.2205, -6.4977, -7.1269, -6.3653, -6.7225, -6.9586, -7.0359, -5.204, -6.6473, -5.1625, -6.0817, -6.5273, -5.1059, -6.0134, -5.6849, -6.0837, -5.065, -5.4066, -5.1789, -5.8484, -6.1628, -5.7147, -5.6163, -5.7931, -6.2143, -5.581, -5.7367, -5.7547, -5.7859, -5.861, -5.7671, -5.9384, -5.9882, -6.0233, -5.9429, -5.9669, -6.0114, -6.0927, -6.2821, -5.9392, -6.3028, -6.5793, -6.6463, -6.6724, -6.8408, -6.7376, -7.1465, -7.221, -6.1584, -7.2676, -6.9646, -7.4283, -6.3927, -6.4383, -7.2192, -7.5475, -6.0256, -6.4281, -7.4279, -7.4264, -6.6804, -7.6222, -6.5211, -7.1811, -7.7571, -7.8268, -7.8269, -7.8294, -7.054, -6.4644, -7.0609, -5.8003, -6.0075, -6.2147, -5.7349, -6.2332, -6.5495, -6.356, -6.6701, -4.982, -6.337, -6.1676, -5.5022, -5.3497, -5.7638, -4.9047, -5.5454, -5.1979, -5.7165, -5.9993, -5.463, -5.3806, -5.5373, -5.3635, -5.7596, -5.8387, -5.7775, -5.6702, -5.915, -5.9172, -5.7117, -5.8266, -5.9409, -5.8926, -5.9583, -5.9497, -5.9648, -5.9786, -6.3265, -6.0894, -6.5821, -6.6175, -5.8719, -6.6846, -6.8065, -6.5878, -6.8832, -7.0852, -7.0831, -7.0857, -7.1857, -6.8461, -6.0446, -7.381, -7.2826, -7.2375, -7.3615, -7.5364, -7.4347, -7.6244, -7.5072, -7.6386, -7.233, -7.5883, -7.7205, -7.5365, -7.2509, -7.132, -7.4928, -6.2539, -6.2721, -6.6532, -6.7611, -6.894, -4.4121, -4.9414, -6.7016, -6.7602, -5.4794, -6.3548, -5.3112, -5.5927, -5.8905, -5.8918, -6.3954, -5.2123, -4.9412, -5.0689, -5.7015, -5.999, -5.5894, -5.733, -5.7483, -5.8326, -5.5735, -6.1569, -5.9122, -5.747, -5.6964, -5.7363, -6.1165, -5.9228, -6.0619, -6.0948, -6.1762, -6.1426, -6.1508, -6.3639, -6.605, -6.6504, -6.7527, -6.8054, -6.8056, -6.8669, -5.2373, -6.9936, -7.0588, -7.1333, -6.9379, -7.2141, -6.8663, -7.0606, -7.1804, -7.3019, -7.3019, -7.3983, -7.3996, -5.6176, -7.5048, -7.5049, -7.6296, -7.1537, -7.2239, -7.7608, -7.7609, -7.214, -7.6872, -5.3146, -5.5817, -7.2198, -5.6454, -6.0649, -6.7557, -6.7503, -5.875, -6.1161, -5.6642, -5.4144, -5.4715, -5.8745, -5.7052, -5.4871, -5.3992, -6.0532, -5.6608, -5.6514, -5.5485, -6.2671, -5.7825, -5.9481, -6.1944, -6.3623, -5.8045, -5.967, -6.0946, -6.2305, -6.1835, -6.2365, -6.106, -6.3524, -6.5359, -6.8491, -6.7605, -6.9453, -7.1714, -7.1715, -7.1715, -7.1716, -7.3068, -7.3068, -7.3069, -7.6499, -7.6499, -7.6501, -7.3065, -7.4338, -7.8788, -7.8788, -7.8788, -7.8788, -7.8789, -7.879, -7.879, -7.879, -7.8788, -6.9322, -7.8793, -8.1757, -6.0026, -5.8217, -6.0289, -6.6901, -7.0894, -7.0279, -7.1884, -6.8451, -6.8132, -6.5147, -7.0832, -6.6247, -6.2313, -6.9367, -7.0007, -7.0588, -7.0823, -7.1145, -7.1708], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.1265, 1.1204, 1.1134, 1.1095, 1.0881, 1.0868, 1.0755, 1.0649, 1.0628, 1.0612, 1.0579, 1.0527, 1.0483, 1.0422, 1.0417, 1.0362, 1.034, 1.0291, 1.0269, 1.008, 1.0032, 1.0028, 0.9968, 0.9958, 0.9918, 0.9914, 0.9902, 0.9902, 0.9876, 0.9799, 0.9023, 0.9088, 0.9121, 0.9145, 0.9346, 0.8731, 0.8697, 0.8934, 0.8316, 0.7953, 0.6035, 0.7809, 0.7096, 0.5437, 0.6351, 0.4962, 0.5244, 0.5726, 0.6851, 0.479, 0.6849, 0.3165, 0.5808, 0.3545, 0.5827, 0.5164, 0.3248, 0.1579, 0.3617, -0.029, 0.012, 0.2595, 0.4483, 0.359, 0.2422, 0.1936, -0.0677, 0.355, -0.0699, -0.0383, 1.5812, 1.5635, 1.5623, 1.5504, 1.5462, 1.511, 1.5031, 1.5021, 1.4972, 1.4936, 1.4892, 1.4813, 1.4792, 1.4771, 1.4754, 1.4735, 1.4572, 1.4515, 1.4422, 1.4345, 1.4342, 1.4299, 1.4282, 1.427, 1.4248, 1.4222, 1.4143, 1.4119, 1.4106, 1.4088, 1.4019, 1.3917, 1.317, 1.371, 1.3438, 1.3304, 1.3015, 1.3154, 1.0887, 1.2302, 0.9041, 1.0593, 0.7196, 1.125, 1.2559, 1.2021, 1.04, 1.1219, 0.7766, 0.7637, 1.0173, 0.5394, 0.7674, 0.2259, 0.4263, 0.6763, 0.1078, 0.5813, 0.3473, 0.2368, 0.1921, 0.4353, 0.3708, 0.0574, 0.4962, -0.3397, -0.0473, 0.4044, -0.2758, -0.2036, -0.0054, -0.1232, -0.3574, -0.5843, 1.635, 1.6294, 1.6102, 1.5925, 1.577, 1.5745, 1.5695, 1.5603, 1.558, 1.5424, 1.5308, 1.5213, 1.4977, 1.4879, 1.4792, 1.4727, 1.4712, 1.4708, 1.4582, 1.4572, 1.4526, 1.4478, 1.4421, 1.4404, 1.4396, 1.4377, 1.4359, 1.432, 1.4251, 1.4192, 1.4125, 1.3051, 1.2937, 1.3679, 1.3286, 1.1397, 1.102, 1.3199, 1.1403, 1.1353, 1.0542, 1.2068, 0.8505, 0.6311, 1.0951, 0.5273, 1.0021, 0.3651, 0.9253, 0.7504, 0.5617, 0.2722, 0.7397, 0.621, 0.6473, 0.4819, -0.0537, 0.7804, 0.4535, 0.3059, 0.068, 0.1145, 0.07, 0.3306, -0.04, 0.0798, -0.4876, -0.1695, -0.0576, -0.164, -0.0712, 2.0666, 2.0446, 2.031, 2.0285, 2.0092, 1.9899, 1.9827, 1.9776, 1.9759, 1.9359, 1.924, 1.9119, 1.9078, 1.8944, 1.8894, 1.8892, 1.8873, 1.8767, 1.8689, 1.8657, 1.8592, 1.8523, 1.8388, 1.8354, 1.8171, 1.8132, 1.8106, 1.8103, 1.8093, 1.792, 1.7864, 1.7697, 1.6413, 1.6579, 1.6859, 1.7522, 1.5438, 1.6084, 1.6781, 1.6721, 0.7604, 1.4029, 0.5297, 1.0381, 1.3064, 0.0728, 0.8225, 0.4959, 0.8407, -0.2171, 0.0547, -0.2103, 0.4704, 0.8344, 0.123, -0.1026, 0.1797, 0.8639, -0.4267, -0.1071, -0.1063, -0.2222, -0.133, -0.4802, -0.0043, 0.0739, 0.1059, -0.4349, -0.5115, -0.2589, -0.7309, 2.1056, 2.0859, 2.0818, 2.0665, 2.0654, 2.0618, 2.0417, 2.0404, 1.9731, 1.9724, 1.9701, 1.9631, 1.9245, 1.9208, 1.9195, 1.9186, 1.9167, 1.892, 1.8831, 1.8815, 1.8797, 1.872, 1.8635, 1.8619, 1.851, 1.8405, 1.8329, 1.819, 1.8189, 1.8165, 1.8027, 1.77, 1.7868, 1.7037, 1.6189, 1.5252, 1.3642, 1.4977, 1.5946, 1.4587, 1.5918, 0.6656, 1.3956, 1.273, 0.8165, 0.7124, 0.8298, 0.0639, 0.6329, 0.2633, 0.6996, 1.0098, 0.2895, 0.1331, 0.1111, -0.2093, 0.2624, 0.267, -0.0495, -0.4916, 0.2658, 0.1877, -0.8638, -0.3712, 0.1347, -0.3289, -0.1206, -0.3201, -0.2574, -0.2612, 2.5442, 2.512, 2.5012, 2.4917, 2.471, 2.395, 2.394, 2.3849, 2.3819, 2.3768, 2.3766, 2.3765, 2.3572, 2.3413, 2.2951, 2.2947, 2.2864, 2.2819, 2.2464, 2.2394, 2.2186, 2.2053, 2.1963, 2.1899, 2.1751, 2.1669, 2.1662, 2.1646, 2.1577, 2.1565, 2.1515, 2.018, 1.9556, 1.9606, 1.9791, 1.9983, 1.1936, 1.3405, 1.9144, 1.9137, 1.165, 1.5956, 0.845, 1.0323, 1.2156, 1.1556, 1.5666, 0.4353, -0.0933, -0.1003, 0.4278, 0.784, 0.1631, 0.3727, 0.3138, 0.334, -0.2117, 0.9145, 0.312, -0.2333, -0.5178, -0.582, 0.7194, -0.1948, 0.0884, 0.2598, 0.658, 0.0131, -0.5024, 3.0946, 3.0218, 3.0077, 2.9691, 2.9511, 2.9508, 2.9221, 2.9101, 2.869, 2.8457, 2.8121, 2.8027, 2.774, 2.7595, 2.7484, 2.7328, 2.7305, 2.7304, 2.6805, 2.6789, 2.6492, 2.6227, 2.6227, 2.5461, 2.5101, 2.4788, 2.4717, 2.4716, 2.4661, 2.4577, 2.4094, 2.3803, 2.4337, 2.2329, 2.1005, 2.2992, 2.2863, 1.8043, 1.8183, 1.5373, 0.7639, 0.7946, 1.0212, 0.4677, 0.1425, -0.0374, 0.8551, 0.0672, -0.0038, -0.3699, 1.2195, -0.0751, 0.2761, 0.6757, 1.1452, -0.836, -0.4033, 0.0103, 0.4263, -0.0332, -0.088, 4.177, 4.0008, 3.8619, 3.611, 3.5433, 3.5311, 3.3382, 3.3381, 3.338, 3.3379, 3.2201, 3.22, 3.2198, 2.9121, 2.9121, 2.9118, 2.9064, 2.7962, 2.7013, 2.7012, 2.7012, 2.7011, 2.7011, 2.701, 2.7009, 2.7009, 2.5239, 2.4703, 2.4435, 2.4228, 2.2627, 2.0722, 1.8289, 2.0117, 1.9425, 1.7825, 1.9415, 1.5425, 1.2361, 0.6298, 1.3313, 0.0726, -1.3834, 0.3842, 0.191, 0.4877, -1.5686, -1.4662, -1.5411]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 8, 1, 2, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7], \"Freq\": [0.22135466152752487, 0.22135466152752487, 0.22135466152752487, 0.22135466152752487, 0.22135466152752487, 0.07103937628076572, 0.07103937628076572, 0.07103937628076572, 0.07103937628076572, 0.07103937628076572, 0.7103937628076572, 0.9059550223601773, 0.03079733787060093, 0.02053155858040062, 0.02823089304805085, 0.005132889645100155, 0.0025664448225500773, 0.007699334467650232, 0.028231364903275522, 0.16938818941965314, 0.07528363974206806, 0.29172410400051374, 0.3952391086458573, 0.03764181987103403, 0.009410454967758507, 0.07303017300200557, 0.8114463666889506, 0.016228927333779015, 0.016228927333779015, 0.05680124566822655, 0.02434339100066852, 0.18608747803753423, 0.12405831869168948, 0.020676386448614914, 0.04135277289722983, 0.04135277289722983, 0.475556888318143, 0.12405831869168948, 0.0921177786677707, 0.0921177786677707, 0.0921177786677707, 0.0921177786677707, 0.0921177786677707, 0.6448244506743949, 0.08376711539092055, 0.08376711539092055, 0.08376711539092055, 0.08376711539092055, 0.08376711539092055, 0.6701369231273644, 0.024263113118349156, 0.024263113118349156, 0.024263113118349156, 0.024263113118349156, 0.8977351853789188, 0.024263113118349156, 0.08537958836368596, 0.08537958836368596, 0.08537958836368596, 0.08537958836368596, 0.6830367069094877, 0.09013514251547103, 0.03004504750515701, 0.03004504750515701, 0.03004504750515701, 0.03004504750515701, 0.8112162826392393, 0.11668711541689453, 0.05834355770844726, 0.05834355770844726, 0.05834355770844726, 0.05834355770844726, 0.7001226925013672, 0.9450947856443199, 0.004821912171654693, 0.03375338520158286, 0.004821912171654693, 0.004821912171654693, 0.004821912171654693, 0.4934486870347096, 0.16962298616818142, 0.07710135734917338, 0.015420271469834676, 0.03084054293966935, 0.03084054293966935, 0.20046352910785079, 0.41866876752942084, 0.08431523790523059, 0.24422344772549548, 0.07268554991830223, 0.07850039391176641, 0.03198164196405298, 0.06977812792157013, 0.06876798332796967, 0.06876798332796967, 0.22922661109323222, 0.5730665277330805, 0.02292266110932322, 0.04584532221864644, 0.02292266110932322, 0.061263698595628205, 0.061263698595628205, 0.7964280817431666, 0.061263698595628205, 0.061263698595628205, 0.061263698595628205, 0.18109717802528139, 0.18109717802528139, 0.18109717802528139, 0.18109717802528139, 0.18109717802528139, 0.18109717802528139, 0.061237177899276775, 0.061237177899276775, 0.061237177899276775, 0.7348461347913213, 0.061237177899276775, 0.061237177899276775, 0.06782736921972184, 0.06782736921972184, 0.7461010614169402, 0.06782736921972184, 0.06782736921972184, 0.06782736921972184, 0.15561273392221742, 0.09336764035333045, 0.06224509356888697, 0.6224509356888697, 0.031122546784443483, 0.031122546784443483, 0.43964215317737393, 0.13439837843246144, 0.14351013290245884, 0.07972785161247713, 0.14351013290245884, 0.04328083373248759, 0.015945570322495425, 0.038160398198750056, 0.019080199099375028, 0.019080199099375028, 0.019080199099375028, 0.019080199099375028, 0.30528318559000045, 0.5914861720806258, 0.14503352490609991, 0.14503352490609991, 0.14503352490609991, 0.14503352490609991, 0.14503352490609991, 0.43510057471829977, 0.13163105779980627, 0.13163105779980627, 0.13163105779980627, 0.13163105779980627, 0.13163105779980627, 0.5265242311992251, 0.049922550136293015, 0.049922550136293015, 0.049922550136293015, 0.049922550136293015, 0.049922550136293015, 0.7987608021806882, 0.06460542179649882, 0.19381626538949648, 0.16151355449124705, 0.09690813269474824, 0.03230271089824941, 0.45223795257549176, 0.03230271089824941, 0.0597240602141935, 0.0597240602141935, 0.238896240856774, 0.0597240602141935, 0.0597240602141935, 0.597240602141935, 0.03430985404740823, 0.03430985404740823, 0.03430985404740823, 0.03430985404740823, 0.8577463511852057, 0.03430985404740823, 0.024186154275842225, 0.04837230855168445, 0.024186154275842225, 0.024186154275842225, 0.8707015539303201, 0.024186154275842225, 0.23775826180159554, 0.015850550786773037, 0.015850550786773037, 0.06340220314709215, 0.015850550786773037, 0.3170110157354607, 0.3487121173090068, 0.44237923351345415, 0.13444859057761843, 0.13878564188657386, 0.13661711623209613, 0.09758365445149725, 0.036864936126121184, 0.015179679581344016, 0.042413298683193115, 0.042413298683193115, 0.8482659736638622, 0.042413298683193115, 0.042413298683193115, 0.042413298683193115, 0.05585627732229492, 0.7819878825121289, 0.05585627732229492, 0.05585627732229492, 0.05585627732229492, 0.05585627732229492, 0.2510567657097062, 0.08368558856990206, 0.08368558856990206, 0.08368558856990206, 0.08368558856990206, 0.5021135314194124, 0.9393724103249628, 0.03304325061444593, 0.014161393120476826, 0.004720464373492275, 0.004720464373492275, 0.004720464373492275, 0.04723107735184162, 0.04723107735184162, 0.8029283149813076, 0.04723107735184162, 0.04723107735184162, 0.06344112696462387, 0.06344112696462387, 0.06344112696462387, 0.6978523966108625, 0.06344112696462387, 0.06344112696462387, 0.08537372013754391, 0.08537372013754391, 0.08537372013754391, 0.08537372013754391, 0.6829897611003513, 0.28896704724003924, 0.06668470320923983, 0.23710116696618608, 0.21487293256310613, 0.022228234403079944, 0.01481882293538663, 0.1481882293538663, 0.018309475709040554, 0.9337832611610682, 0.018309475709040554, 0.018309475709040554, 0.018309475709040554, 0.018309475709040554, 0.09044476339727475, 0.09044476339727475, 0.09044476339727475, 0.09044476339727475, 0.09044476339727475, 0.6331133437809233, 0.8660181442804177, 0.0360840893450174, 0.0360840893450174, 0.0360840893450174, 0.0360840893450174, 0.545711960732658, 0.03819983725128606, 0.1364279901831645, 0.15825646861247084, 0.027285598036632903, 0.01091423921465316, 0.08731391371722529, 0.11341187811742996, 0.0756079187449533, 0.06300659895412776, 0.2898303551889877, 0.44104619267889433, 0.025202639581651105, 0.8582494507597797, 0.03731519351129477, 0.03731519351129477, 0.03731519351129477, 0.03731519351129477, 0.03731519351129477, 0.08999621466395706, 0.04499810733197853, 0.04499810733197853, 0.04499810733197853, 0.7424687709776457, 0.022499053665989265, 0.1093786008007383, 0.05468930040036915, 0.05468930040036915, 0.05468930040036915, 0.05468930040036915, 0.7109609052047989, 0.08220009959656961, 0.08220009959656961, 0.08220009959656961, 0.08220009959656961, 0.08220009959656961, 0.6576007967725569, 0.09721825279846029, 0.09721825279846029, 0.09721825279846029, 0.09721825279846029, 0.09721825279846029, 0.5833095167907617, 0.21727076662056308, 0.21727076662056308, 0.21727076662056308, 0.21727076662056308, 0.21727076662056308, 0.04793120082145411, 0.8148304139647199, 0.04793120082145411, 0.04793120082145411, 0.04793120082145411, 0.04793120082145411, 0.3860802908840187, 0.16987532798896823, 0.24194364895398507, 0.08493766399448412, 0.05405124072376262, 0.03860802908840187, 0.023164817453041123, 0.05471551972567036, 0.08207327958850553, 0.2735775986283518, 0.02735775986283518, 0.47876079759961565, 0.06839439965708795, 0.22428759341347163, 0.19936674970086365, 0.07476253113782387, 0.24920843712607957, 0.1744459059882557, 0.024920843712607957, 0.024920843712607957, 0.024920843712607957, 0.0853721957331315, 0.0853721957331315, 0.0853721957331315, 0.0853721957331315, 0.682977565865052, 0.12021837988657574, 0.12021837988657574, 0.12021837988657574, 0.12021837988657574, 0.12021837988657574, 0.480873519546303, 0.20604171046913167, 0.20604171046913167, 0.20604171046913167, 0.20604171046913167, 0.20604171046913167, 0.20604171046913167, 0.2172814597577025, 0.2172814597577025, 0.2172814597577025, 0.2172814597577025, 0.2172814597577025, 0.21341236721607443, 0.21341236721607443, 0.21341236721607443, 0.21341236721607443, 0.21341236721607443, 0.07184643768770713, 0.023948812562569043, 0.7184643768770713, 0.04789762512513809, 0.14369287537541425, 0.023948812562569043, 0.02529613879944693, 0.02529613879944693, 0.12648069399723466, 0.7841803027828549, 0.02529613879944693, 0.02529613879944693, 0.5028114357466099, 0.09024820641605819, 0.1246284755269375, 0.08595067277719828, 0.10314080733263793, 0.038677802749739226, 0.04727287002745905, 0.3274540620429972, 0.2217136878416127, 0.3240430822300493, 0.03752077794242676, 0.06480861644600987, 0.020465878877687325, 0.0034109798129478876, 0.17350804669408185, 0.0277612874710531, 0.5413451056855354, 0.06940321867763274, 0.18044836856184512, 0.006940321867763275, 0.006940321867763275, 0.3615061829510557, 0.09037654573776392, 0.09037654573776392, 0.09037654573776392, 0.09037654573776392, 0.3615061829510557, 0.1201745617285974, 0.0400581872428658, 0.0400581872428658, 0.0400581872428658, 0.7611055576144502, 0.0673445863867246, 0.2020337591601738, 0.0673445863867246, 0.0673445863867246, 0.0673445863867246, 0.5387566910937968, 0.03797395030819187, 0.03797395030819187, 0.18986975154095934, 0.6835311055474537, 0.03797395030819187, 0.03797395030819187, 0.07702422275961761, 0.07702422275961761, 0.07702422275961761, 0.07702422275961761, 0.07702422275961761, 0.6932180048365585, 0.09994592068330722, 0.11243916076872063, 0.11243916076872063, 0.09994592068330722, 0.21238508145202784, 0.012493240085413403, 0.3498107223915753, 0.7489279488980493, 0.01337371337317945, 0.06686856686589725, 0.04012114011953835, 0.09361599361225616, 0.0267474267463589, 0.01337371337317945, 0.06937755010909744, 0.023125850036365813, 0.1618809502545607, 0.06937755010909744, 0.023125850036365813, 0.6475238010182428, 0.09022832232646087, 0.09022832232646087, 0.18045664465292174, 0.09022832232646087, 0.09022832232646087, 0.5413699339587652, 0.41552496937178507, 0.12499531598988657, 0.10810405707233434, 0.10134755350531344, 0.21958636592817912, 0.020269510701062688, 0.010134755350531344, 0.0666903111491155, 0.0666903111491155, 0.0666903111491155, 0.7335934226402705, 0.0666903111491155, 0.09536938865757308, 0.09536938865757308, 0.09536938865757308, 0.09536938865757308, 0.09536938865757308, 0.5722163319454385, 0.15372868210613064, 0.07686434105306532, 0.07686434105306532, 0.03843217052653266, 0.6533468989510552, 0.03843217052653266, 0.8648296115748572, 0.027897729405640552, 0.027897729405640552, 0.027897729405640552, 0.027897729405640552, 0.027897729405640552, 0.027897729405640552, 0.5528091996815977, 0.11191842692940321, 0.1187013618948216, 0.06443788217147457, 0.09835255699856646, 0.037306142309801074, 0.016957337413545943, 0.2750569776761607, 0.11613516835215675, 0.22615795942262104, 0.048899018253539685, 0.29950648680293057, 0.01833713184507738, 0.012224754563384921, 0.07319955813713813, 0.07319955813713813, 0.07319955813713813, 0.7319955813713813, 0.07319955813713813, 0.15350495822700555, 0.15350495822700555, 0.15350495822700555, 0.15350495822700555, 0.15350495822700555, 0.3070099164540111, 0.1211814465443651, 0.32892106919184816, 0.051934905661870756, 0.4674141509568368, 0.017311635220623588, 0.017311635220623588, 0.8257360181830885, 0.03440566742429536, 0.03440566742429536, 0.06881133484859071, 0.03440566742429536, 0.03440566742429536, 0.09535305238174485, 0.09535305238174485, 0.09535305238174485, 0.09535305238174485, 0.09535305238174485, 0.5721183142904691, 0.12566784958284868, 0.12566784958284868, 0.12566784958284868, 0.12566784958284868, 0.12566784958284868, 0.5026713983313947, 0.13820757390044794, 0.13820757390044794, 0.13820757390044794, 0.13820757390044794, 0.13820757390044794, 0.4146227217013438, 0.0864304856066732, 0.0864304856066732, 0.0864304856066732, 0.0864304856066732, 0.0864304856066732, 0.6050133992467124, 0.022843151776331238, 0.7538240086189308, 0.022843151776331238, 0.15990206243431865, 0.022843151776331238, 0.022843151776331238, 0.8403629582888962, 0.046686831016049785, 0.046686831016049785, 0.046686831016049785, 0.046686831016049785, 0.1152023864249792, 0.1152023864249792, 0.1152023864249792, 0.1152023864249792, 0.1152023864249792, 0.576011932124896, 0.13159847061900903, 0.13159847061900903, 0.13159847061900903, 0.13159847061900903, 0.13159847061900903, 0.5263938824760361, 0.24527874836058797, 0.16136759760564998, 0.43891986548736794, 0.103275262467616, 0.025818815616904, 0.012909407808452, 0.006454703904226, 0.21341185645843277, 0.21341185645843277, 0.21341185645843277, 0.21341185645843277, 0.21341185645843277, 0.28733157060438685, 0.2314254279076057, 0.18592042803813266, 0.12091328536745691, 0.14301571387548667, 0.020802285654616243, 0.010401142827308122, 0.08777321378419616, 0.7899589240577654, 0.04388660689209808, 0.04388660689209808, 0.04388660689209808, 0.04388660689209808, 0.05842829035198842, 0.7595677745758495, 0.05842829035198842, 0.05842829035198842, 0.05842829035198842, 0.357070685279978, 0.08569696446719471, 0.2285252385791859, 0.08569696446719471, 0.11426261928959296, 0.0714141370559956, 0.02856565482239824, 0.02856565482239824, 0.10967510167495034, 0.21935020334990069, 0.14101084501065045, 0.1253429733428004, 0.04700361500355015, 0.32902530502485106, 0.01566787166785005, 0.30672447212303205, 0.1951883004419295, 0.05576808584055128, 0.41826064380413464, 0.01394202146013782, 0.01394202146013782, 0.022440642581128167, 0.134643855486769, 0.04488128516225633, 0.04488128516225633, 0.7181005625961013, 0.04488128516225633, 0.2369266053202094, 0.27598044136200217, 0.20828712555622803, 0.10674715184756688, 0.09893638463920831, 0.06769331580577412, 0.0078107672083585515, 0.07173464330070116, 0.07173464330070116, 0.7173464330070115, 0.07173464330070116, 0.07173464330070116, 0.2450493225825841, 0.5367747066094699, 0.09918663056914119, 0.0350070460832263, 0.06417958448591489, 0.011669015361075433, 0.0058345076805377165, 0.10916235466472075, 0.09767158048948699, 0.3791955477827142, 0.1895977738913571, 0.1895977738913571, 0.034472322525701295, 0.005745387087616882, 0.4274852208742565, 0.20145855236602891, 0.10318608779723433, 0.1949070547281093, 0.04586048346543748, 0.02456811614219865, 0.00327574881895982, 0.790330096016045, 0.042720545730597026, 0.08544109146119405, 0.042720545730597026, 0.021360272865298513, 0.021360272865298513, 0.14741374299891374, 0.039688315422784476, 0.6406828061106636, 0.11339518692224135, 0.039688315422784476, 0.011339518692224135, 0.005669759346112068, 0.04930888587708866, 0.04930888587708866, 0.7889421740334186, 0.04930888587708866, 0.04930888587708866, 0.04930888587708866, 0.02836263673761966, 0.11345054695047864, 0.05672527347523932, 0.05672527347523932, 0.7090659184404915, 0.02836263673761966, 0.05430583779367053, 0.05430583779367053, 0.05430583779367053, 0.05430583779367053, 0.814587566905058, 0.05430583779367053, 0.11058302887892649, 0.11058302887892649, 0.11058302887892649, 0.11058302887892649, 0.11058302887892649, 0.5529151443946324, 0.2941936924691908, 0.524432234401601, 0.019186545161034182, 0.08953721075149285, 0.038373090322068364, 0.025582060214712245, 0.030455604780695162, 0.8527569338594645, 0.030455604780695162, 0.030455604780695162, 0.030455604780695162, 0.030455604780695162, 0.15350249172434638, 0.15350249172434638, 0.15350249172434638, 0.15350249172434638, 0.15350249172434638, 0.30700498344869276, 0.1548973490030421, 0.047142671435708466, 0.33673336739791765, 0.17510135104691718, 0.05387733878366682, 0.22224402248262565, 0.006734667347958353, 0.09712975445352828, 0.01942595089070566, 0.3690930669234075, 0.07770380356282264, 0.15540760712564528, 0.01942595089070566, 0.25253736157917356, 0.06399027557760299, 0.7198906002480336, 0.031995137788801496, 0.12798055115520598, 0.015997568894400748, 0.031995137788801496, 0.8890455675472209, 0.012521768557003111, 0.025043537114006222, 0.025043537114006222, 0.025043537114006222, 0.012521768557003111, 0.012521768557003111, 0.8898303470332435, 0.03295667951974976, 0.03295667951974976, 0.03295667951974976, 0.03295667951974976, 0.03295667951974976, 0.1088858567914311, 0.10641117822798948, 0.5246318554496225, 0.0618669640860404, 0.13363264242584727, 0.03217082132474101, 0.03217082132474101, 0.5476242178892015, 0.1671950045767916, 0.06057790020898247, 0.06784724823406035, 0.10904022037616844, 0.046039204158826674, 0.004846232016718597, 0.6712170634281248, 0.10539772070358985, 0.10539772070358985, 0.06101973303892044, 0.03883073920658574, 0.011094496916167353, 0.005547248458083676, 0.16998246246652254, 0.06799298498660902, 0.1813146266309574, 0.011332164164434838, 0.555276044057307, 0.011332164164434838, 0.30519722891695306, 0.10814075040364478, 0.30519722891695306, 0.09131885589641116, 0.12496264491087841, 0.04806255573495324, 0.01441876672048597, 0.05353505441873838, 0.8030258162810757, 0.05353505441873838, 0.05353505441873838, 0.05353505441873838, 0.06441342223385789, 0.06441342223385789, 0.7729610668062946, 0.06441342223385789, 0.06441342223385789, 0.06441342223385789, 0.3476920300181699, 0.08692300750454247, 0.08692300750454247, 0.08692300750454247, 0.08692300750454247, 0.3476920300181699, 0.8886115123038372, 0.008975873861654922, 0.008975873861654922, 0.035903495446619686, 0.008975873861654922, 0.035903495446619686, 0.008975873861654922, 0.09703561021684182, 0.5579547587468404, 0.04851780510842091, 0.2183301229878941, 0.024258902554210454, 0.024258902554210454, 0.024258902554210454, 0.4515774366166137, 0.1505258122055379, 0.1505258122055379, 0.1505258122055379, 0.1505258122055379, 0.1505258122055379, 0.20249510127450657, 0.20249510127450657, 0.20249510127450657, 0.20249510127450657, 0.20249510127450657, 0.20249510127450657, 0.035847530115405785, 0.035847530115405785, 0.035847530115405785, 0.035847530115405785, 0.8603407227697388, 0.035847530115405785, 0.1847644617516985, 0.5660511237302036, 0.08398384625077204, 0.055429338525509554, 0.08398384625077204, 0.01679676925015441, 0.011757738475108087, 0.24182394728895373, 0.2696597973366031, 0.16179587840196186, 0.08872677202688231, 0.1461382127501591, 0.0782883282590138, 0.013917925023824676, 0.03336758810758336, 0.01668379405379168, 0.01668379405379168, 0.7507707324206258, 0.16683794053791684, 0.01668379405379168, 0.04403265621182964, 0.8366204680247632, 0.04403265621182964, 0.04403265621182964, 0.04403265621182964, 0.040958516796735095, 0.8191703359347019, 0.040958516796735095, 0.040958516796735095, 0.040958516796735095, 0.040958516796735095, 0.035392473245941684, 0.8494193579026004, 0.035392473245941684, 0.035392473245941684, 0.035392473245941684, 0.035392473245941684, 0.06345382049353777, 0.06345382049353777, 0.06345382049353777, 0.06345382049353777, 0.7614458459224532, 0.4833604623740824, 0.12148631942022392, 0.16284336432923632, 0.0930533510452779, 0.0723748285907717, 0.033602598988572575, 0.02843296837494602, 0.13461072783170083, 0.13461072783170083, 0.06730536391585042, 0.06730536391585042, 0.06730536391585042, 0.6057482752426537, 0.16288454360223575, 0.10365380047415003, 0.22211528673032147, 0.22211528673032147, 0.19249991516627862, 0.0444230573460643, 0.014807685782021431, 0.029615371564042862, 0.42374161951593403, 0.10593540487898351, 0.3276352728215985, 0.07098764244467967, 0.053513761227527754, 0.015289646065007928, 0.0032763527282159846, 0.14979974847996128, 0.09986649898664085, 0.049933249493320425, 0.586715681546515, 0.09986649898664085, 0.012483312373330106, 0.07318192690573942, 0.07318192690573942, 0.07318192690573942, 0.7318192690573943, 0.07318192690573942, 0.07318192690573942, 0.2172861615958466, 0.2172861615958466, 0.2172861615958466, 0.2172861615958466, 0.2172861615958466, 0.2075724604877626, 0.294060985690997, 0.24216787056905636, 0.1037862302438813, 0.06919082016258753, 0.05189311512194065, 0.01729770504064688, 0.01729770504064688, 0.1406236122771495, 0.1406236122771495, 0.1406236122771495, 0.1406236122771495, 0.1406236122771495, 0.42187083683144855, 0.11204426140670978, 0.03734808713556993, 0.7469617427113986, 0.03734808713556993, 0.03734808713556993, 0.03734808713556993, 0.43932732352417964, 0.1555650850511849, 0.18725426904309295, 0.09218671706736883, 0.0792229599797701, 0.025927514175197487, 0.021606261812664573, 0.05590475088361258, 0.7826665123705762, 0.05590475088361258, 0.05590475088361258, 0.05590475088361258, 0.7675428097496324, 0.03987235375322766, 0.08971279594476222, 0.03987235375322766, 0.03987235375322766, 0.014952132657460373, 0.0049840442191534575, 0.2172612686813826, 0.2172612686813826, 0.2172612686813826, 0.2172612686813826, 0.2172612686813826, 0.055820577737558184, 0.7814880883258146, 0.055820577737558184, 0.055820577737558184, 0.055820577737558184, 0.37232343887674896, 0.0372323438876749, 0.22871296959571724, 0.22871296959571724, 0.053189062696678426, 0.01595671880900353, 0.06382687523601412, 0.11179316892799353, 0.5847642682387354, 0.017198949065845157, 0.051596847197535475, 0.14619106705968385, 0.051596847197535475, 0.025798423598767738, 0.40246815036982453, 0.03018511127773684, 0.3521596315735965, 0.08049363007396491, 0.02012340751849123, 0.02012340751849123, 0.10061703759245613, 0.21338328711470042, 0.21338328711470042, 0.21338328711470042, 0.21338328711470042, 0.21338328711470042, 0.16145606005729807, 0.16145606005729807, 0.16145606005729807, 0.16145606005729807, 0.16145606005729807, 0.16145606005729807, 0.32291212011459614, 0.36965266369512495, 0.36965266369512495, 0.04620658296189062, 0.09241316592378124, 0.04620658296189062, 0.04620658296189062, 0.04620658296189062, 0.03041723535716128, 0.1825034121429677, 0.12166894142864512, 0.1520861767858064, 0.06083447071432256, 0.4562585303574192, 0.06401243946983248, 0.06401243946983248, 0.06401243946983248, 0.7681492736379898, 0.06401243946983248, 0.06401243946983248, 0.023876067714636354, 0.9072905731561814, 0.023876067714636354, 0.023876067714636354, 0.023876067714636354, 0.023876067714636354, 0.040729508518719294, 0.4699558675236841, 0.08145901703743859, 0.05952774321966666, 0.21304665994407015, 0.10182377129679823, 0.03133039116824561, 0.35695394371589234, 0.14698103564772036, 0.1329828417765089, 0.16097922951893182, 0.1119855509696917, 0.06999096935605732, 0.013998193871211463, 0.006999096935605732, 0.26585841430101415, 0.15656106619948612, 0.07975752429030425, 0.09452743619591615, 0.12702124238826232, 0.25108850239540226, 0.020677876667856657, 0.05731224419418224, 0.40900101538575506, 0.16151632454724085, 0.11462448838836448, 0.09378367231775275, 0.15370101852076146, 0.010420408035305861, 0.19556279991969722, 0.033717724124085725, 0.5462271308101888, 0.040461268948902875, 0.06743544824817145, 0.10115317237225718, 0.006743544824817145, 0.017523053251789534, 0.7359682365751604, 0.12266137276252674, 0.017523053251789534, 0.08761526625894768, 0.017523053251789534, 0.017523053251789534, 0.1504601809061324, 0.0752300904530662, 0.0752300904530662, 0.0752300904530662, 0.0752300904530662, 0.6770708140775957, 0.028834709130041172, 0.7785371465111116, 0.028834709130041172, 0.08650412739012352, 0.028834709130041172, 0.028834709130041172, 0.028834709130041172, 0.045614061764911645, 0.045614061764911645, 0.8210531117684096, 0.045614061764911645, 0.045614061764911645, 0.045614061764911645, 0.02184322003642402, 0.02184322003642402, 0.8955720214933849, 0.02184322003642402, 0.04368644007284804, 0.02184322003642402, 0.6131404867928785, 0.08908878867930713, 0.0733672377359, 0.11005085660384999, 0.04716465283022142, 0.05764568679249285, 0.005240516981135713, 0.765740660117895, 0.08414732528768076, 0.05048839517260846, 0.05048839517260846, 0.02524419758630423, 0.008414732528768077, 0.08876147819026957, 0.1980063744244475, 0.34821810674644216, 0.3209068826878977, 0.006827806014636121, 0.006827806014636121, 0.020483418043908363, 0.02204981579058558, 0.7717435526704952, 0.02204981579058558, 0.02204981579058558, 0.15434871053409904, 0.02204981579058558, 0.08104761742723775, 0.08104761742723775, 0.08104761742723775, 0.648380939417902, 0.08104761742723775, 0.16052671099844415, 0.19677467799809284, 0.5022932569951317, 0.025891404999749058, 0.10356561999899623, 0.005178280999949812, 0.005178280999949812, 0.07604390563787806, 0.07604390563787806, 0.6843951507409025, 0.07604390563787806, 0.07604390563787806, 0.10222574100799552, 0.05111287050399776, 0.7666930575599664, 0.05111287050399776, 0.05111287050399776, 0.05111287050399776, 0.06258931512223259, 0.06258931512223259, 0.08345242016297678, 0.6676193613038143, 0.08345242016297678, 0.04172621008148839, 0.03188177894394603, 0.860808031486543, 0.03188177894394603, 0.03188177894394603, 0.03188177894394603, 0.03188177894394603, 0.016136284572505113, 0.5486336754651739, 0.11295399200753581, 0.05244292486064162, 0.2501124108738293, 0.012102213429378837, 0.044033419388728214, 0.8366349683858361, 0.044033419388728214, 0.044033419388728214, 0.044033419388728214, 0.044033419388728214, 0.20100328355778013, 0.10050164177889007, 0.10050164177889007, 0.10050164177889007, 0.10050164177889007, 0.5025082088944504, 0.28885648530633506, 0.21233821105300127, 0.2955518343035018, 0.07460531739700045, 0.08895249381950053, 0.037302658698500225, 0.0028694352845000173, 0.19829411686030923, 0.03965882337206185, 0.03965882337206185, 0.6741999973250514, 0.03965882337206185, 0.03965882337206185, 0.3087383139281569, 0.19682067512920004, 0.3704859767137883, 0.0501699760133255, 0.030873831392815694, 0.04245151816512158, 0.0038592289241019618, 0.1680172714450089, 0.1680172714450089, 0.1680172714450089, 0.1680172714450089, 0.1680172714450089, 0.03983390675257113, 0.8365120418039937, 0.03983390675257113, 0.03983390675257113, 0.03983390675257113, 0.03983390675257113, 0.056312731062850584, 0.056312731062850584, 0.11262546212570117, 0.675752772754207, 0.056312731062850584, 0.056312731062850584, 0.28940933026676713, 0.3409872307103494, 0.2750821356991054, 0.017192633481194087, 0.051577900443582264, 0.022923511308258784, 0.002865438913532348, 0.43706353537606063, 0.11655027610028283, 0.18277202388453445, 0.11390140618891277, 0.0741683575183618, 0.026488699113700644, 0.050328528316031226, 0.1811398456983086, 0.025877120814044086, 0.7245593827932344, 0.025877120814044086, 0.025877120814044086, 0.025877120814044086, 0.13286280581358256, 0.2325099101737695, 0.09964710436018694, 0.4318041188941434, 0.06643140290679128, 0.03321570145339564, 0.03321570145339564, 0.16760725550746194, 0.04788778728784627, 0.6345131815639631, 0.041901813876865486, 0.0718316809317694, 0.01795792023294235, 0.01795792023294235, 0.2640246589874844, 0.27744964164786495, 0.22374971100634272, 0.09844987284279079, 0.08949988440253709, 0.026849965320761126, 0.013424982660380563, 0.004474994220126855, 0.023936761403984413, 0.023936761403984413, 0.023936761403984413, 0.8856601719474233, 0.023936761403984413, 0.023936761403984413, 0.06651220393825974, 0.06651220393825974, 0.06651220393825974, 0.7316342433208571, 0.06651220393825974, 0.06651220393825974, 0.03979316961474221, 0.03979316961474221, 0.03979316961474221, 0.03979316961474221, 0.8356565619095865, 0.03979316961474221, 0.038690751070714284, 0.038690751070714284, 0.7738150214142857, 0.09672687767678571, 0.019345375535357142, 0.019345375535357142, 0.2920281741137351, 0.09547074922949032, 0.12916630778107516, 0.2639485419874144, 0.14601408705686755, 0.0617751906779055, 0.005615926425264137, 0.25299740962067996, 0.09853583322068589, 0.28229184652412714, 0.07456765757241093, 0.20772418895171618, 0.01597878376551663, 0.06924139631723873, 0.06446773326301768, 0.06446773326301768, 0.7736127991562121, 0.06446773326301768, 0.06446773326301768, 0.0807373545441999, 0.0807373545441999, 0.0807373545441999, 0.0807373545441999, 0.7266361908977992, 0.5512893031431592, 0.17227790723223727, 0.10336674433934236, 0.09303006990540812, 0.04823781402502643, 0.02067334886786847, 0.01378223257857898, 0.04354862323292986, 0.13064586969878958, 0.04354862323292986, 0.04354862323292986, 0.04354862323292986, 0.6967779717268777, 0.08524359385669966, 0.17048718771339932, 0.08524359385669966, 0.08524359385669966, 0.08524359385669966, 0.5967051569968976, 0.05636858303087632, 0.05636858303087632, 0.05636858303087632, 0.05636858303087632, 0.7891601624322685, 0.05636858303087632, 0.2742163554878052, 0.04681742654669845, 0.026752815169541973, 0.1070112606781679, 0.4280450427126716, 0.1070112606781679, 0.006688203792385493, 0.5312433019435563, 0.1447670311865652, 0.14735215674346816, 0.06850582725792818, 0.07626120392863703, 0.024558692790578027, 0.00775537667070885, 0.06257098926075869, 0.01564274731518967, 0.7977801130746733, 0.02607124552531612, 0.07299948747088514, 0.01564274731518967, 0.005214249105063224, 0.07159531707209085, 0.07159531707209085, 0.7159531707209086, 0.07159531707209085, 0.07159531707209085, 0.03161616502920473, 0.03161616502920473, 0.03161616502920473, 0.8852526208177325, 0.03161616502920473, 0.03161616502920473, 0.039328808164612095, 0.039328808164612095, 0.039328808164612095, 0.039328808164612095, 0.039328808164612095, 0.8259049714568539, 0.06429374643770322, 0.06429374643770322, 0.7715249572524386, 0.06429374643770322, 0.06429374643770322, 0.04864158548811772, 0.04864158548811772, 0.04864158548811772, 0.04864158548811772, 0.04864158548811772, 0.8269069532980012, 0.10260730279989667, 0.10260730279989667, 0.10260730279989667, 0.10260730279989667, 0.10260730279989667, 0.6156438167993801, 0.29994136789268805, 0.391472771240222, 0.10702133314480888, 0.09223549106559187, 0.04646978939182491, 0.05984745603492602, 0.0021122631541738595, 0.0014081754361159064, 0.8615881269882967, 0.04307940634941483, 0.04307940634941483, 0.04307940634941483, 0.04307940634941483, 0.04307940634941483, 0.06088004441220902, 0.06088004441220902, 0.06088004441220902, 0.06088004441220902, 0.7305605329465082, 0.25719361059035495, 0.039568247783131526, 0.019784123891565763, 0.6133078406385387, 0.019784123891565763, 0.039568247783131526, 0.24111814642183746, 0.16074543094789162, 0.040186357736972905, 0.040186357736972905, 0.040186357736972905, 0.4822362928436749, 0.027843652024742076, 0.8353095607422624, 0.027843652024742076, 0.05568730404948415, 0.027843652024742076, 0.027843652024742076, 0.050775480395665484, 0.10155096079133097, 0.22848966178049468, 0.012693870098916371, 0.5077548039566548, 0.11424483089024734, 0.15622005221717947, 0.32595914741469173, 0.1952750652714743, 0.027038085960665675, 0.07360367844847879, 0.21780680357202906, 0.0030042317734072974, 0.8411032969529117, 0.04672796094182843, 0.04672796094182843, 0.04672796094182843, 0.04672796094182843, 0.04672796094182843, 0.11888437890454838, 0.4136185682720746, 0.12879141047992743, 0.0941167999661008, 0.14365195784299598, 0.09659355785994556, 0.0024767578938447578, 0.05127141831508423, 0.05127141831508423, 0.05127141831508423, 0.05127141831508423, 0.7690712747262634, 0.10254283663016846, 0.0180041293236445, 0.895705433851314, 0.004501032330911125, 0.036008258647289, 0.02700619398546675, 0.013503096992733376, 0.031082710972379905, 0.8703159072266373, 0.031082710972379905, 0.031082710972379905, 0.031082710972379905, 0.031082710972379905, 0.7359570925382503, 0.05110813142626738, 0.08177301028202781, 0.07155138399677433, 0.040886505141013905, 0.010221626285253476, 0.010221626285253476, 0.8506647690163043, 0.03150610255615942, 0.03150610255615942, 0.03150610255615942, 0.03150610255615942, 0.03150610255615942, 0.3938481122386908, 0.12392634566131219, 0.18843595025213225, 0.10015964923311534, 0.10525251275344323, 0.05432387755016425, 0.033952423468852654, 0.1927286800310349, 0.1927286800310349, 0.1927286800310349, 0.1927286800310349, 0.1927286800310349, 0.1927286800310349, 0.6278662902849497, 0.1172521385471894, 0.17776937134573875, 0.03404094344918402, 0.03025861639927468, 0.003782327049909335, 0.00756465409981867, 0.07906890821137787, 0.07906890821137787, 0.07906890821137787, 0.07906890821137787, 0.07906890821137787, 0.6325512656910229, 0.6112245878461794, 0.1633042791955441, 0.10264840406577058, 0.03266085583910882, 0.037326692387552936, 0.037326692387552936, 0.009331673096888234, 0.058451912139252354, 0.058451912139252354, 0.7598748578102806, 0.058451912139252354, 0.058451912139252354, 0.018625474456941467, 0.800895401648483, 0.037250948913882934, 0.018625474456941467, 0.09312737228470733, 0.018625474456941467, 0.03876757869712377, 0.03876757869712377, 0.03876757869712377, 0.8141191526395993, 0.03876757869712377, 0.03876757869712377, 0.20386177244682624, 0.05096544311170656, 0.20386177244682624, 0.458688988005359, 0.05096544311170656, 0.05096544311170656, 0.05096544311170656, 0.1315717839816617, 0.14006028617402697, 0.2886090745404192, 0.06790801753892216, 0.15279303946257486, 0.21221255480913176, 0.00848850219236527, 0.10604451416594213, 0.10604451416594213, 0.10604451416594213, 0.10604451416594213, 0.10604451416594213, 0.5302225708297106, 0.1648555813301597, 0.1648555813301597, 0.3297111626603194, 0.1648555813301597, 0.1648555813301597, 0.1648555813301597, 0.4432880384800573, 0.18943933268378518, 0.11176920628343325, 0.1288187462249739, 0.09661405966873043, 0.024627113248892073, 0.005683179980513555, 0.7054785260145318, 0.015171581204613586, 0.19723055565997663, 0.02275737180692038, 0.03792895301153397, 0.015171581204613586, 0.037028428035245725, 0.7405685607049145, 0.037028428035245725, 0.07405685607049145, 0.037028428035245725, 0.037028428035245725, 0.07405685607049145, 0.037028428035245725, 0.04222234365426314, 0.04222234365426314, 0.04222234365426314, 0.8444468730852628, 0.04222234365426314, 0.04222234365426314, 0.04597164045901161, 0.37390267573329444, 0.0827489528262209, 0.18388656183604643, 0.2482468584786627, 0.06129552061201548, 0.003064776030600774, 0.07262747009788088, 0.07262747009788088, 0.07262747009788088, 0.07262747009788088, 0.7262747009788089, 0.07262747009788088, 0.18034718422297658, 0.022543398027872072, 0.6537585428082902, 0.06763019408361622, 0.022543398027872072, 0.022543398027872072, 0.022543398027872072, 0.26365584162700384, 0.2858918764630162, 0.19059458430867748, 0.07623783372347098, 0.07623783372347098, 0.08576756293890486, 0.025412611241156995, 0.20249858312354643, 0.20249858312354643, 0.20249858312354643, 0.20249858312354643, 0.20249858312354643, 0.20249858312354643, 0.14331955805363328, 0.023886593008938882, 0.023886593008938882, 0.023886593008938882, 0.6927111972592276, 0.09554637203575553, 0.42891093334172026, 0.2824535414689377, 0.04184496910650929, 0.09415118048964591, 0.11507366504290055, 0.010461242276627323, 0.010461242276627323, 0.03813442900243243, 0.8389574380535133, 0.03813442900243243, 0.03813442900243243, 0.03813442900243243, 0.03813442900243243, 0.058667264810955966, 0.058667264810955966, 0.058667264810955966, 0.7626744425424276, 0.058667264810955966, 0.058667264810955966, 0.2774007786451848, 0.1376251925061382, 0.23654329961992504, 0.24514487415155867, 0.06451180898725228, 0.03225590449362614, 0.006451180898725229, 0.0952432921394312, 0.0952432921394312, 0.0952432921394312, 0.0952432921394312, 0.0952432921394312, 0.5714597528365871, 0.9520493272563423, 0.003487360173100155, 0.017436800865500774, 0.003487360173100155, 0.003487360173100155, 0.017436800865500774, 0.91792048828132, 0.019954793223506958, 0.019954793223506958, 0.019954793223506958, 0.019954793223506958, 0.019954793223506958, 0.8487222308275988, 0.03394888923310395, 0.03394888923310395, 0.03394888923310395, 0.03394888923310395, 0.12064298275276349, 0.06032149137638174, 0.06032149137638174, 0.06032149137638174, 0.723857896516581, 0.8744186206176064, 0.03497674482470426, 0.03497674482470426, 0.03497674482470426, 0.03497674482470426, 0.03497674482470426, 0.18907783035501632, 0.2701111862214519, 0.3646501013989601, 0.0900370620738173, 0.04051667793321779, 0.04051667793321779, 0.004501853103690865, 0.04642521147242227, 0.04642521147242227, 0.4178269032518004, 0.04642521147242227, 0.13927563441726679, 0.04642521147242227, 0.32497648030695586, 0.04552505518345138, 0.04552505518345138, 0.8194509933021249, 0.04552505518345138, 0.04552505518345138, 0.041100758920384395, 0.041100758920384395, 0.041100758920384395, 0.8220151784076879, 0.041100758920384395, 0.0506515700114662, 0.016883856670488737, 0.03376771334097747, 0.016883856670488737, 0.8779605468654142, 0.016883856670488737, 0.06660710914933267, 0.06660710914933267, 0.06660710914933267, 0.7326782006426593, 0.06660710914933267, 0.06660710914933267, 0.026347644202166273, 0.026347644202166273, 0.8958199028736532, 0.026347644202166273, 0.026347644202166273, 0.026347644202166273, 0.041069404267855825, 0.041069404267855825, 0.8213880853571165, 0.041069404267855825, 0.041069404267855825, 0.041069404267855825, 0.027155927846744407, 0.027155927846744407, 0.868989691095821, 0.027155927846744407, 0.027155927846744407, 0.027155927846744407, 0.07181655560415545, 0.07181655560415545, 0.7181655560415546, 0.07181655560415545, 0.07181655560415545, 0.5186209254122163, 0.08364853635680909, 0.14777908089702937, 0.07807196726635515, 0.041824268178404546, 0.08922510544726302, 0.041824268178404546, 0.22285212389572642, 0.04952269419905031, 0.6933177187867043, 0.024761347099525155, 0.024761347099525155, 0.024761347099525155, 0.5073267860706149, 0.07651100021946629, 0.22835590834733013, 0.05532333862022947, 0.0482607847538172, 0.052969153998092044, 0.030604400087786515, 0.04508508381197913, 0.030056722541319417, 0.030056722541319417, 0.1653119739772568, 0.721361340991666, 0.015028361270659709, 0.20037546345098564, 0.21707341873856778, 0.15028159758823925, 0.06679182115032856, 0.19202648580719459, 0.15028159758823925, 0.01669795528758214, 0.00834897764379107, 0.20253100073081903, 0.20253100073081903, 0.20253100073081903, 0.20253100073081903, 0.20253100073081903, 0.20253100073081903, 0.05850419927628085, 0.7605545905916511, 0.05850419927628085, 0.05850419927628085, 0.05850419927628085, 0.0708710585679385, 0.0708710585679385, 0.0708710585679385, 0.0708710585679385, 0.0708710585679385, 0.7087105856793849, 0.20604752804327986, 0.20604752804327986, 0.20604752804327986, 0.20604752804327986, 0.20604752804327986, 0.20604752804327986, 0.11261024980479321, 0.05630512490239661, 0.05630512490239661, 0.6756614988287593, 0.05630512490239661, 0.05630512490239661, 0.08601878090732197, 0.08601878090732197, 0.08601878090732197, 0.08601878090732197, 0.08601878090732197, 0.6021314663512538, 0.037353336850577706, 0.037353336850577706, 0.8591267475632872, 0.037353336850577706, 0.037353336850577706, 0.07882756213106247, 0.08868100739744528, 0.5222325991182889, 0.04926722633191405, 0.1083878979302109, 0.04926722633191405, 0.1083878979302109, 0.1382141115963928, 0.1382141115963928, 0.1382141115963928, 0.1382141115963928, 0.1382141115963928, 0.41464233478917845, 0.09851632009100933, 0.09851632009100933, 0.09851632009100933, 0.09851632009100933, 0.09851632009100933, 0.5910979205460559, 0.17116046843236593, 0.17116046843236593, 0.019017829825818438, 0.07607131930327375, 0.5324992351229163, 0.019017829825818438, 0.05044087675008058, 0.05044087675008058, 0.05044087675008058, 0.05044087675008058, 0.8070540280012892, 0.05044087675008058, 0.010026503763831199, 0.19050357151279276, 0.11029154140214319, 0.040106015055324795, 0.6015902258298719, 0.010026503763831199, 0.050132518819155994, 0.029678336075862975, 0.029678336075862975, 0.029678336075862975, 0.8606717462000263, 0.029678336075862975, 0.029678336075862975, 0.07079420030927448, 0.07079420030927448, 0.07079420030927448, 0.07079420030927448, 0.07079420030927448, 0.07079420030927448, 0.7079420030927449, 0.18505097300053316, 0.2518749354729479, 0.09766579130583695, 0.26215554508408867, 0.06168365766684439, 0.13364792494482952, 0.010280609611140731, 0.032692204540140386, 0.06538440908028077, 0.032692204540140386, 0.7846129089633693, 0.032692204540140386, 0.032692204540140386, 0.05831437496828497, 0.014578593742071242, 0.014578593742071242, 0.5977223434249209, 0.014578593742071242, 0.014578593742071242, 0.2915718748414248, 0.8771674039687198, 0.030247151860990338, 0.030247151860990338, 0.030247151860990338, 0.030247151860990338, 0.030247151860990338, 0.9326151469568892, 0.015288772900932609, 0.015288772900932609, 0.015288772900932609, 0.015288772900932609, 0.015288772900932609, 0.23896703888475276, 0.20312198305203985, 0.17922527916356457, 0.07169011166542583, 0.07169011166542583, 0.03584505583271291, 0.19117363110780222, 0.056272284065530066, 0.056272284065530066, 0.056272284065530066, 0.7315396928518909, 0.056272284065530066, 0.056272284065530066, 0.045734162879028505, 0.045734162879028505, 0.1372024886370855, 0.045734162879028505, 0.6860124431854275, 0.045734162879028505, 0.045734162879028505, 0.18912604871919036, 0.14184453653939277, 0.18912604871919036, 0.04728151217979759, 0.04728151217979759, 0.04728151217979759, 0.33097058525858314, 0.05343269826573934, 0.8014904739860902, 0.05343269826573934, 0.05343269826573934, 0.05343269826573934, 0.1531159283907113, 0.1531159283907113, 0.1531159283907113, 0.1531159283907113, 0.1531159283907113, 0.3062318567814226, 0.2172748408157694, 0.2172748408157694, 0.2172748408157694, 0.2172748408157694, 0.2172748408157694, 0.1100492748360377, 0.7116519772730439, 0.044019709934415084, 0.014673236644805026, 0.10271265651363519, 0.007336618322402513, 0.007336618322402513, 0.007336618322402513, 0.4000274126984814, 0.18155090268623386, 0.16462666599514425, 0.10308398711845482, 0.08000548253969628, 0.033848473382179195, 0.03692560732601367, 0.001538566971917236, 0.10795923178130554, 0.05397961589065277, 0.10795923178130554, 0.05397961589065277, 0.05397961589065277, 0.701735006578486, 0.8902318148915828, 0.008478398237062692, 0.004239199118531346, 0.06782718589650154, 0.004239199118531346, 0.008478398237062692, 0.01271759735559404, 0.21728027436729208, 0.21728027436729208, 0.21728027436729208, 0.21728027436729208, 0.21728027436729208, 0.8799885679065999, 0.037446322038578714, 0.037446322038578714, 0.018723161019289357, 0.018723161019289357, 0.018723161019289357, 0.05616519633889955, 0.03744346422593303, 0.03744346422593303, 0.03744346422593303, 0.7863127487445937, 0.018721732112966516, 0.018721732112966516, 0.026958592606975206, 0.8896335560301818, 0.026958592606975206, 0.026958592606975206, 0.026958592606975206, 0.026958592606975206, 0.25761445574404135, 0.25761445574404135, 0.12880722787202067, 0.06440361393601034, 0.21467871312003448, 0.021467871312003447, 0.042935742624006894, 0.06449533894057259, 0.25798135576229037, 0.021498446313524194, 0.06449533894057259, 0.12899067788114518, 0.021498446313524194, 0.4514673725840081, 0.9129671517013822, 0.020749253447758687, 0.020749253447758687, 0.020749253447758687, 0.020749253447758687, 0.020749253447758687, 0.17613076607742364, 0.10064615204424208, 0.15096922806636315, 0.03774230701659079, 0.4906499912156802, 0.02516153801106052, 0.02516153801106052, 0.10010541987713555, 0.654535437658194, 0.07700416913625811, 0.05390291839538068, 0.015400833827251622, 0.10010541987713555, 0.5222052481569527, 0.16797047791035738, 0.10144751636170099, 0.07483833174223845, 0.08481677597453689, 0.01995688846459692, 0.029935332696895377, 0.19154168464639187, 0.019154168464639187, 0.6512417277977324, 0.019154168464639187, 0.09577084232319594, 0.019154168464639187, 0.019154168464639187, 0.12565284060111193, 0.12565284060111193, 0.12565284060111193, 0.12565284060111193, 0.12565284060111193, 0.5026113624044477, 0.21983432178202933, 0.03140490311171847, 0.5809907075667918, 0.06280980622343695, 0.07851225777929619, 0.015702451555859236, 0.015702451555859236, 0.03354526590110711, 0.03354526590110711, 0.03354526590110711, 0.03354526590110711, 0.8721769134287849, 0.03354526590110711, 0.042785102148681656, 0.06417765322302249, 0.042785102148681656, 0.08557020429736331, 0.5348137768585207, 0.19253295966906744, 0.3538513061408331, 0.19982191405599986, 0.07909617431383327, 0.07077026122816661, 0.10407391357083326, 0.18733304442749987, 0.3616441100297689, 0.13524901675910056, 0.25089672674151986, 0.12348823269309181, 0.06762450837955028, 0.03920261355336248, 0.021561437454349363, 0.09386755964646262, 0.18773511929292525, 0.09386755964646262, 0.09386755964646262, 0.09386755964646262, 0.5632053578787757, 0.5194570638815915, 0.20999328114362212, 0.07736594568449236, 0.07736594568449236, 0.0276306948873187, 0.01657841693239122, 0.07183980670702862, 0.03140896962504705, 0.03140896962504705, 0.03140896962504705, 0.03140896962504705, 0.8794511495013174, 0.03140896962504705, 0.29732558402762155, 0.2411488607781631, 0.16716000576668125, 0.10276229862705814, 0.126055086315858, 0.052066231304376126, 0.012331475835246977, 0.0013701639816941086, 0.24070320593457517, 0.19516476156857446, 0.0845713966797156, 0.1236043489934305, 0.18865926951628864, 0.16263730130714538, 0.2581124674220675, 0.08603748914068918, 0.17207497828137835, 0.08603748914068918, 0.08603748914068918, 0.3441499565627567, 0.16710418135825092, 0.06684167254330037, 0.06684167254330037, 0.6015750528897034, 0.033420836271650184, 0.033420836271650184, 0.0775617681577346, 0.0775617681577346, 0.0387808840788673, 0.0387808840788673, 0.6592750293407441, 0.11634265223660191, 0.4985889610939359, 0.1147380454400271, 0.16480555617749346, 0.1147380454400271, 0.07927355866765508, 0.016689170245822123, 0.008344585122911061, 0.09145655456146978, 0.15242759093578298, 0.12194207274862638, 0.06097103637431319, 0.09145655456146978, 0.45728277280734897, 0.07104878223123325, 0.07104878223123325, 0.07104878223123325, 0.07104878223123325, 0.07104878223123325, 0.7104878223123325, 0.02106665058845144, 0.905865975303412, 0.02106665058845144, 0.02106665058845144, 0.02106665058845144, 0.02106665058845144, 0.04257573047776111, 0.8515146095552221, 0.04257573047776111, 0.04257573047776111, 0.04257573047776111, 0.04257573047776111, 0.07179733059482706, 0.07179733059482706, 0.7179733059482706, 0.07179733059482706, 0.07179733059482706, 0.8286922290116847, 0.04874660170656969, 0.04874660170656969, 0.04874660170656969, 0.04874660170656969, 0.04874660170656969, 0.06665144899948262, 0.06665144899948262, 0.06665144899948262, 0.7331659389943088, 0.06665144899948262, 0.06665144899948262, 0.7615118548483703, 0.11243799199103455, 0.027257695028129584, 0.030664906906645785, 0.045997360359968674, 0.022146877210355288, 0.001703605939258099, 0.5812766067483837, 0.18798732813990282, 0.09399366406995141, 0.04947034951050074, 0.037102762132875555, 0.04204979708392563, 0.007420552426575111, 0.1013085614721574, 0.6979034234748621, 0.011256506830239712, 0.022513013660479423, 0.14633458879311625, 0.011256506830239712, 0.09138948209455494, 0.04569474104727747, 0.04569474104727747, 0.776810597803717, 0.04569474104727747, 0.04569474104727747, 0.8284169278900363, 0.03313667711560145, 0.03313667711560145, 0.03313667711560145, 0.03313667711560145, 0.03313667711560145, 0.06945731126587253, 0.06945731126587253, 0.06945731126587253, 0.06945731126587253, 0.6945731126587252, 0.03156787485130965, 0.03156787485130965, 0.015783937425654825, 0.8996844332623251, 0.015783937425654825, 0.015783937425654825, 0.07171042100603635, 0.07171042100603635, 0.7171042100603634, 0.07171042100603635, 0.07171042100603635, 0.07171042100603635, 0.22875689796912219, 0.4110475510382664, 0.12152710204609615, 0.12152710204609615, 0.08220951020765328, 0.021445959184605203, 0.010722979592302602, 0.04103853717704898, 0.04103853717704898, 0.8618092807180285, 0.04103853717704898, 0.04103853717704898, 0.09692667995982945, 0.09692667995982945, 0.04846333997991473, 0.04846333997991473, 0.04846333997991473, 0.7269500996987209, 0.10862996849769722, 0.10862996849769722, 0.10862996849769722, 0.10862996849769722, 0.10862996849769722, 0.5431498424884862, 0.1804083761891813, 0.09020418809459065, 0.1503403134909844, 0.5412251285675438, 0.03006806269819688, 0.01503403134909844, 0.01503403134909844, 0.36393582107318106, 0.18196791053659053, 0.18196791053659053, 0.18196791053659053, 0.18196791053659053, 0.052960677264559365, 0.026480338632279683, 0.026480338632279683, 0.8473708362329498, 0.026480338632279683, 0.026480338632279683, 0.03451573990722669, 0.34515739907226695, 0.06903147981445339, 0.03451573990722669, 0.03451573990722669, 0.4832203587011737, 0.3230561531663765, 0.19490164612516928, 0.10145565140762236, 0.18689198943509383, 0.1441738204213581, 0.040048283450377246, 0.00800965669007545, 0.1128191367627151, 0.16922870514407265, 0.47243013519386945, 0.15512631304873326, 0.014102392095339387, 0.05640956838135755, 0.014102392095339387, 0.16032305658854723, 0.12692241979926655, 0.544430379665275, 0.03674070046820874, 0.09018171933105781, 0.04008076414713681, 0.0033400636789280673, 0.21729690974387433, 0.21729690974387433, 0.21729690974387433, 0.21729690974387433, 0.21729690974387433, 0.26184082815689336, 0.15179178443877875, 0.33394192576531323, 0.07969068683035885, 0.12902301677296193, 0.03415315149872522, 0.011384383832908405, 0.12012183879004365, 0.6673435488335758, 0.053387483906686066, 0.053387483906686066, 0.06673435488335759, 0.04004061293001455, 0.013346870976671516, 0.0379213542990731, 0.8342697945796081, 0.05688203144860964, 0.01896067714953655, 0.01896067714953655, 0.01896067714953655, 0.01896067714953655, 0.3746665217515025, 0.2915814771789936, 0.059570409316138474, 0.10346439512802998, 0.12227610333312634, 0.040758701111042114, 0.007838211752123483, 0.0015676423504246966, 0.14868545998399774, 0.04055057999563575, 0.013516859998545249, 0.702876719924353, 0.054067439994180996, 0.04055057999563575, 0.8351401638121594, 0.0363104419048765, 0.0363104419048765, 0.0363104419048765, 0.0363104419048765, 0.0363104419048765, 0.8402856133908922, 0.04668253407727179, 0.04668253407727179, 0.04668253407727179, 0.04668253407727179, 0.8878981575478142, 0.02864187604992949, 0.02864187604992949, 0.02864187604992949, 0.02864187604992949, 0.02864187604992949, 0.1282872539336974, 0.2411800373953511, 0.3130208995982216, 0.05644639173082685, 0.1282872539336974, 0.1282872539336974, 0.1763579796887898, 0.19215123160121875, 0.4079923410710809, 0.03421871247692937, 0.09475951147457363, 0.09212730282250214, 0.0026322086520714897, 0.08666016408768804, 0.02888672136256268, 0.02888672136256268, 0.7799414767891922, 0.02888672136256268, 0.05777344272512536, 0.08325192413622966, 0.08325192413622966, 0.08325192413622966, 0.04162596206811483, 0.6452024120557799, 0.04162596206811483, 0.7750505588435792, 0.11772919881168292, 0.019621533135280488, 0.009810766567640244, 0.0686753659734817, 0.009810766567640244, 0.7358251997427209, 0.09460609710977841, 0.07358251997427209, 0.021023577135506313, 0.052558942838765776, 0.021023577135506313, 0.24284665957746962, 0.6291936179961712, 0.022076969052497238, 0.022076969052497238, 0.05519242263124309, 0.022076969052497238, 0.023198682082325596, 0.023198682082325596, 0.09279472832930238, 0.04639736416465119, 0.023198682082325596, 0.7887551907990703, 0.08796420476757127, 0.08796420476757127, 0.08796420476757127, 0.08796420476757127, 0.08796420476757127, 0.6157494333729989, 0.11154596663341457, 0.11154596663341457, 0.11154596663341457, 0.11154596663341457, 0.11154596663341457, 0.44618386653365827, 0.042270350641968366, 0.042270350641968366, 0.042270350641968366, 0.8454070128393674, 0.042270350641968366, 0.042270350641968366, 0.3141000732240999, 0.16913080865913072, 0.07852501830602497, 0.26577698503577685, 0.06644424625894421, 0.08456540432956536, 0.018121158070621146, 0.13164932511872432, 0.3754443716348805, 0.13164932511872432, 0.07313851395484684, 0.13652522604904743, 0.14627702790969369, 0.004875900930323123, 0.06693739733928708, 0.33468698669643543, 0.2677495893571483, 0.06693739733928708, 0.13387479467857416, 0.06693739733928708, 0.06693739733928708, 0.06805709943950237, 0.06805709943950237, 0.7486280938345261, 0.06805709943950237, 0.06805709943950237, 0.06805709943950237, 0.31219030455920965, 0.23910758695247353, 0.16523049198044681, 0.09294215173900135, 0.11677347269771964, 0.05957830239679573, 0.013504415209940366, 0.5640553136795982, 0.13352033995314158, 0.14850731688665747, 0.07357243221907801, 0.05449809794005779, 0.020436786727521673, 0.004087357345504334, 0.4836008920914721, 0.31188753185609436, 0.07008708581035827, 0.05957402293880454, 0.03153918861466123, 0.03504354290517914, 0.007008708581035828, 0.6863708873160272, 0.14996338714467825, 0.07498169357233912, 0.02883911291243812, 0.05191040324238862, 0.01153564516497525, 0.005767822582487625, 0.8516683793443474, 0.044824651544439334, 0.044824651544439334, 0.044824651544439334, 0.044824651544439334, 0.044824651544439334, 0.2536944465028931, 0.18019418630112033, 0.12091978291259389, 0.12329075904813495, 0.22287175674085935, 0.09009709315056016, 0.00711292840662317, 0.19589974118285314, 0.19589974118285314, 0.19589974118285314, 0.19589974118285314, 0.19589974118285314, 0.19589974118285314, 0.04321984508697029, 0.021609922543485146, 0.3241488381522772, 0.06482976763045543, 0.04321984508697029, 0.4970282185001584, 0.021609922543485146, 0.20601387754398032, 0.20601387754398032, 0.20601387754398032, 0.20601387754398032, 0.20601387754398032, 0.20601387754398032, 0.21727564833256058, 0.21727564833256058, 0.21727564833256058, 0.21727564833256058, 0.21727564833256058, 0.06429841766401767, 0.06429841766401767, 0.7715810119682119, 0.06429841766401767, 0.06429841766401767, 0.0554829018913674, 0.7074069991149343, 0.01387072547284185, 0.1109658037827348, 0.06935362736420925, 0.04161217641852555, 0.04282463335367759, 0.7922557170430353, 0.021412316676838794, 0.021412316676838794, 0.08564926670735518, 0.04282463335367759, 0.0534051503690892, 0.801077255536338, 0.0534051503690892, 0.0534051503690892, 0.0534051503690892, 0.0534051503690892, 0.05081302797389523, 0.5843498216997951, 0.03175814248368452, 0.06351628496736904, 0.05081302797389523, 0.20960374039231783, 0.006351628496736904, 0.17320439183792036, 0.17320439183792036, 0.17320439183792036, 0.17320439183792036, 0.17320439183792036, 0.17320439183792036, 0.17320439183792036, 0.202505089256424, 0.202505089256424, 0.202505089256424, 0.202505089256424, 0.202505089256424, 0.202505089256424, 0.10248867610287415, 0.10248867610287415, 0.10248867610287415, 0.10248867610287415, 0.10248867610287415, 0.6149320566172449, 0.023527647914517984, 0.023527647914517984, 0.023527647914517984, 0.16469353540162587, 0.7528847332645755, 0.023527647914517984, 0.0633752138358829, 0.1267504276717658, 0.0633752138358829, 0.6971273521947119, 0.0633752138358829, 0.0633752138358829, 0.25356875368643844, 0.2941397542762686, 0.18764087772796445, 0.12678437684321922, 0.032963937979236996, 0.10142750147457537, 0.002535687536864384, 0.840063855658481, 0.04667021420324894, 0.04667021420324894, 0.04667021420324894, 0.04667021420324894, 0.323714688597038, 0.204587683193328, 0.17610079059678868, 0.10099898284227586, 0.09064011280717064, 0.07251209024573652, 0.03107661010531565, 0.08835190573968724, 0.26505571721906174, 0.08835190573968724, 0.08835190573968724, 0.17670381147937447, 0.35340762295874895, 0.13099641656786012, 0.13099641656786012, 0.25544301230732724, 0.27509247479250626, 0.13754623739625313, 0.07204802911232308, 0.006549820828393007], \"Term\": [\"abruptly\", \"abruptly\", \"abruptly\", \"abruptly\", \"abruptly\", \"acoustic_signal\", \"acoustic_signal\", \"acoustic_signal\", \"acoustic_signal\", \"acoustic_signal\", \"acoustic_signal\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"activation\", \"activation\", \"activation\", \"activation\", \"activation\", \"activation\", \"activation\", \"activity\", \"activity\", \"activity\", \"activity\", \"activity\", \"activity\", \"ad\", \"ad\", \"ad\", \"ad\", \"ad\", \"ad\", \"ad\", \"adaptive_sample\", \"adaptive_sample\", \"adaptive_sample\", \"adaptive_sample\", \"adaptive_sample\", \"adaptive_sample\", \"adaptive_sampling\", \"adaptive_sampling\", \"adaptive_sampling\", \"adaptive_sampling\", \"adaptive_sampling\", \"adaptive_sampling\", \"adversarial_example\", \"adversarial_example\", \"adversarial_example\", \"adversarial_example\", \"adversarial_example\", \"adversarial_example\", \"adversarial_severity\", \"adversarial_severity\", \"adversarial_severity\", \"adversarial_severity\", \"adversarial_severity\", \"advertisement\", \"advertisement\", \"advertisement\", \"advertisement\", \"advertisement\", \"advertisement\", \"advertiser\", \"advertiser\", \"advertiser\", \"advertiser\", \"advertiser\", \"advertiser\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"alignment\", \"alignment\", \"alignment\", \"alignment\", \"alignment\", \"alignment\", \"alignment\", \"alternative_splice\", \"alternative_splice\", \"alternative_splice\", \"alternative_splice\", \"alternative_splice\", \"alternative_splice\", \"anastasio\", \"anastasio\", \"anastasio\", \"anastasio\", \"anastasio\", \"anastasio\", \"anatomical_registration\", \"anatomical_registration\", \"anatomical_registration\", \"anatomical_registration\", \"anatomical_registration\", \"anatomical_registration\", \"anchor_point\", \"anchor_point\", \"anchor_point\", \"anchor_point\", \"anchor_point\", \"anchor_point\", \"anneal\", \"anneal\", \"anneal\", \"anneal\", \"anneal\", \"anneal\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"armed\", \"armed\", \"armed\", \"armed\", \"armed\", \"armed\", \"armed_duele\", \"armed_duele\", \"armed_duele\", \"armed_duele\", \"armed_duele\", \"armed_duele\", \"attacker\", \"attacker\", \"attacker\", \"attacker\", \"attacker\", \"attacker\", \"attention\", \"attention\", \"attention\", \"attention\", \"attention\", \"attention\", \"attention\", \"attractor\", \"attractor\", \"attractor\", \"attractor\", \"attractor\", \"attractor\", \"aud\", \"aud\", \"aud\", \"aud\", \"aud\", \"aud\", \"audio\", \"audio\", \"audio\", \"audio\", \"audio\", \"audio\", \"bandit\", \"bandit\", \"bandit\", \"bandit\", \"bandit\", \"bandit\", \"bandit\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"bayes_error\", \"bayes_error\", \"bayes_error\", \"bayes_error\", \"bayes_error\", \"bayes_error\", \"beak\", \"beak\", \"beak\", \"beak\", \"beak\", \"beak\", \"beat\", \"beat\", \"beat\", \"beat\", \"beat\", \"beat\", \"belief\", \"belief\", \"belief\", \"belief\", \"belief\", \"belief\", \"bep\", \"bep\", \"bep\", \"bep\", \"bep\", \"bifurcation\", \"bifurcation\", \"bifurcation\", \"bifurcation\", \"bifurcation\", \"bifurcation\", \"bike\", \"bike\", \"bike\", \"bike\", \"bike\", \"bind\", \"bind\", \"bind\", \"bind\", \"bind\", \"bind\", \"bind\", \"bird\", \"bird\", \"bird\", \"bird\", \"bird\", \"bird\", \"bmix\", \"bmix\", \"bmix\", \"bmix\", \"bmix\", \"bmix\", \"bootstrap\", \"bootstrap\", \"bootstrap\", \"bootstrap\", \"bootstrap\", \"bound\", \"bound\", \"bound\", \"bound\", \"bound\", \"bound\", \"bound\", \"brain\", \"brain\", \"brain\", \"brain\", \"brain\", \"brain\", \"bregman_divergence\", \"bregman_divergence\", \"bregman_divergence\", \"bregman_divergence\", \"bregman_divergence\", \"bregman_divergence\", \"brief\", \"brief\", \"brief\", \"brief\", \"brief\", \"brief\", \"budget\", \"budget\", \"budget\", \"budget\", \"budget\", \"budget\", \"budget_constraint\", \"budget_constraint\", \"budget_constraint\", \"budget_constraint\", \"budget_constraint\", \"budget_constraint\", \"bxyz_bxyz\", \"bxyz_bxyz\", \"bxyz_bxyz\", \"bxyz_bxyz\", \"bxyz_bxyz\", \"bxyz_bxyz\", \"canal\", \"canal\", \"canal\", \"canal\", \"canal\", \"caption\", \"caption\", \"caption\", \"caption\", \"caption\", \"caption\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"category\", \"category\", \"category\", \"category\", \"category\", \"category\", \"cause\", \"cause\", \"cause\", \"cause\", \"cause\", \"cause\", \"cause\", \"cause\", \"cayley\", \"cayley\", \"cayley\", \"cayley\", \"cayley\", \"ccb\", \"ccb\", \"ccb\", \"ccb\", \"ccb\", \"ccb\", \"central_adaptation\", \"central_adaptation\", \"central_adaptation\", \"central_adaptation\", \"central_adaptation\", \"central_adaptation\", \"cerebellar\", \"cerebellar\", \"cerebellar\", \"cerebellar\", \"cerebellar\", \"cerebellum\", \"cerebellum\", \"cerebellum\", \"cerebellum\", \"cerebellum\", \"character\", \"character\", \"character\", \"character\", \"character\", \"character\", \"chip\", \"chip\", \"chip\", \"chip\", \"chip\", \"chip\", \"choose\", \"choose\", \"choose\", \"choose\", \"choose\", \"choose\", \"choose\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"clique_partition\", \"clique_partition\", \"clique_partition\", \"clique_partition\", \"clique_partition\", \"clique_partition\", \"cn\", \"cn\", \"cn\", \"cn\", \"cn\", \"codebook\", \"codebook\", \"codebook\", \"codebook\", \"codebook\", \"codebook\", \"codeword\", \"codeword\", \"codeword\", \"codeword\", \"codeword\", \"codeword\", \"collective_information\", \"collective_information\", \"collective_information\", \"collective_information\", \"collective_information\", \"collective_information\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"community\", \"community\", \"community\", \"community\", \"community\", \"community\", \"community_detection\", \"community_detection\", \"community_detection\", \"community_detection\", \"community_detection\", \"community_detection\", \"compute\", \"compute\", \"compute\", \"compute\", \"compute\", \"compute\", \"compute\", \"condensation\", \"condensation\", \"condensation\", \"condensation\", \"condensation\", \"condorcet_winner\", \"condorcet_winner\", \"condorcet_winner\", \"condorcet_winner\", \"condorcet_winner\", \"condorcet_winner\", \"cone\", \"cone\", \"cone\", \"cone\", \"cone\", \"cone\", \"confidence_interval\", \"confidence_interval\", \"confidence_interval\", \"confidence_interval\", \"confidence_interval\", \"confidence_interval\", \"confidence_interval\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint_satisfaction\", \"constraint_satisfaction\", \"constraint_satisfaction\", \"constraint_satisfaction\", \"constraint_satisfaction\", \"continued_sample\", \"continued_sample\", \"continued_sample\", \"continued_sample\", \"continued_sample\", \"continued_sample\", \"contour\", \"contour\", \"contour\", \"contour\", \"contour\", \"contour\", \"coordinate_descent\", \"coordinate_descent\", \"coordinate_descent\", \"coordinate_descent\", \"coordinate_descent\", \"coordinate_descent\", \"copeland\", \"copeland\", \"copeland\", \"copeland\", \"copeland\", \"copeland\", \"copeland_duele\", \"copeland_duele\", \"copeland_duele\", \"copeland_duele\", \"copeland_duele\", \"copeland_duele\", \"copeland_score\", \"copeland_score\", \"copeland_score\", \"copeland_score\", \"copeland_score\", \"copeland_score\", \"copeland_winner\", \"copeland_winner\", \"copeland_winner\", \"copeland_winner\", \"copeland_winner\", \"copeland_winner\", \"cortical\", \"cortical\", \"cortical\", \"cortical\", \"cortical\", \"cortical\", \"coverage_error\", \"coverage_error\", \"coverage_error\", \"coverage_error\", \"coverage_error\", \"cpld\", \"cpld\", \"cpld\", \"cpld\", \"cpld\", \"cpld\", \"cssp\", \"cssp\", \"cssp\", \"cssp\", \"cssp\", \"cssp\", \"curve\", \"curve\", \"curve\", \"curve\", \"curve\", \"curve\", \"curve\", \"darkness\", \"darkness\", \"darkness\", \"darkness\", \"darkness\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"datum\", \"dbn\", \"dbn\", \"dbn\", \"dbn\", \"dbn\", \"dbn\", \"decoy\", \"decoy\", \"decoy\", \"decoy\", \"decoy\", \"decrease\", \"decrease\", \"decrease\", \"decrease\", \"decrease\", \"decrease\", \"decrease\", \"decrease\", \"degree\", \"degree\", \"degree\", \"degree\", \"degree\", \"degree\", \"degree\", \"dependency\", \"dependency\", \"dependency\", \"dependency\", \"dependency\", \"dependency\", \"descriptor\", \"descriptor\", \"descriptor\", \"descriptor\", \"descriptor\", \"descriptor\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"differential_privacy\", \"differential_privacy\", \"differential_privacy\", \"differential_privacy\", \"differential_privacy\", \"direction\", \"direction\", \"direction\", \"direction\", \"direction\", \"direction\", \"direction\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"divergence\", \"divergence\", \"divergence\", \"divergence\", \"divergence\", \"divergence\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain_adaptation\", \"domain_adaptation\", \"domain_adaptation\", \"domain_adaptation\", \"domain_adaptation\", \"domain_adaptation\", \"dot_product\", \"dot_product\", \"dot_product\", \"dot_product\", \"dot_product\", \"dot_product\", \"driven_searchlight\", \"driven_searchlight\", \"driven_searchlight\", \"driven_searchlight\", \"driven_searchlight\", \"driven_searchlight\", \"dueling_bandit\", \"dueling_bandit\", \"dueling_bandit\", \"dueling_bandit\", \"dueling_bandit\", \"dueling_bandit\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic_texture\", \"dynamic_texture\", \"dynamic_texture\", \"dynamic_texture\", \"dynamic_texture\", \"dynamic_texture\", \"ect\", \"ect\", \"ect\", \"ect\", \"ect\", \"ect\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"eigenvalue\", \"eigenvalue\", \"eigenvalue\", \"eigenvalue\", \"eigenvalue\", \"eigenvalue\", \"eigenvalue\", \"energy\", \"energy\", \"energy\", \"energy\", \"energy\", \"energy\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"equivalence_relation\", \"equivalence_relation\", \"equivalence_relation\", \"equivalence_relation\", \"equivalence_relation\", \"equivalence_relation\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimation\", \"estimation\", \"estimation\", \"estimation\", \"estimation\", \"estimation\", \"estimation\", \"event\", \"event\", \"event\", \"event\", \"event\", \"event\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"excitability\", \"excitability\", \"excitability\", \"excitability\", \"excitability\", \"exon\", \"exon\", \"exon\", \"exon\", \"exon\", \"exon\", \"expban\", \"expban\", \"expban\", \"expban\", \"expban\", \"expban\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye_movement\", \"eye_movement\", \"eye_movement\", \"eye_movement\", \"eye_movement\", \"eye_movement\", \"eye_velocity\", \"eye_velocity\", \"eye_velocity\", \"eye_velocity\", \"eye_velocity\", \"eye_velocity\", \"familiarity\", \"familiarity\", \"familiarity\", \"familiarity\", \"familiarity\", \"familiarity\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"file\", \"file\", \"file\", \"file\", \"file\", \"file\", \"firing\", \"firing\", \"firing\", \"firing\", \"firing\", \"firing_rate\", \"firing_rate\", \"firing_rate\", \"firing_rate\", \"firing_rate\", \"firing_rate\", \"fisher_vector\", \"fisher_vector\", \"fisher_vector\", \"fisher_vector\", \"fisher_vector\", \"fisher_vector\", \"flow_graph\", \"flow_graph\", \"flow_graph\", \"flow_graph\", \"flow_graph\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"forget\", \"forget\", \"forget\", \"forget\", \"forget\", \"forget\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"functional\", \"functional\", \"functional\", \"functional\", \"functional\", \"functional\", \"functional_connectivity\", \"functional_connectivity\", \"functional_connectivity\", \"functional_connectivity\", \"functional_connectivity\", \"functional_connectivity\", \"furman\", \"furman\", \"furman\", \"furman\", \"furman\", \"gain\", \"gain\", \"gain\", \"gain\", \"gain\", \"gain\", \"gain\", \"gain\", \"ggm\", \"ggm\", \"ggm\", \"ggm\", \"ggm\", \"ggm\", \"gi\", \"gi\", \"gi\", \"gi\", \"gi\", \"gi\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"gmm\", \"gmm\", \"gmm\", \"gmm\", \"gmm\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"goldfish\", \"goldfish\", \"goldfish\", \"goldfish\", \"goldfish\", \"gpfa\", \"gpfa\", \"gpfa\", \"gpfa\", \"gpfa\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"graph\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"habituate\", \"habituate\", \"habituate\", \"habituate\", \"habituate\", \"habituation\", \"habituation\", \"habituation\", \"habituation\", \"habituation\", \"habituation\", \"habituation\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"hidden_unit\", \"hidden_unit\", \"hidden_unit\", \"hidden_unit\", \"hidden_unit\", \"hidden_unit\", \"hopf_bifurcation\", \"hopf_bifurcation\", \"hopf_bifurcation\", \"hopf_bifurcation\", \"hopf_bifurcation\", \"hopf_bifurcation\", \"hsld\", \"hsld\", \"hsld\", \"hsld\", \"hsld\", \"hsld\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"intensity\", \"intensity\", \"intensity\", \"intensity\", \"intensity\", \"intensity\", \"intensity\", \"invocation\", \"invocation\", \"invocation\", \"invocation\", \"invocation\", \"invocation\", \"ip\", \"ip\", \"ip\", \"ip\", \"ip\", \"ip\", \"ip\", \"isoform\", \"isoform\", \"isoform\", \"isoform\", \"isoform\", \"isoform\", \"isomap\", \"isomap\", \"isomap\", \"isomap\", \"isomap\", \"isomap\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"joint\", \"joint\", \"joint\", \"joint\", \"joint\", \"joint\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"keypoint\", \"keypoint\", \"keypoint\", \"keypoint\", \"keypoint\", \"keypoint\", \"kl_distance\", \"kl_distance\", \"kl_distance\", \"kl_distance\", \"kl_distance\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label_ranking\", \"label_ranking\", \"label_ranking\", \"label_ranking\", \"label_ranking\", \"landmark\", \"landmark\", \"landmark\", \"landmark\", \"landmark\", \"landmark\", \"language\", \"language\", \"language\", \"language\", \"language\", \"language\", \"lar\", \"lar\", \"lar\", \"lar\", \"lar\", \"lar\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"layered_dynamic\", \"layered_dynamic\", \"layered_dynamic\", \"layered_dynamic\", \"layered_dynamic\", \"layered_dynamic\", \"lc\", \"lc\", \"lc\", \"lc\", \"lc\", \"lc\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learner\", \"learner\", \"learner\", \"learner\", \"learner\", \"learner\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"lesion\", \"lesion\", \"lesion\", \"lesion\", \"lesion\", \"linear_dynamical\", \"linear_dynamical\", \"linear_dynamical\", \"linear_dynamical\", \"linear_dynamical\", \"linear_dynamical\", \"linguistic\", \"linguistic\", \"linguistic\", \"linguistic\", \"linguistic\", \"linguistic\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"log\", \"log\", \"log\", \"log\", \"log\", \"log\", \"log\", \"logistic_regression\", \"logistic_regression\", \"logistic_regression\", \"logistic_regression\", \"logistic_regression\", \"logistic_regression\", \"loop\", \"loop\", \"loop\", \"loop\", \"loop\", \"loop\", \"loop\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"lpmrf\", \"lpmrf\", \"lpmrf\", \"lpmrf\", \"lpmrf\", \"lpmrf\", \"lpmrf_topic\", \"lpmrf_topic\", \"lpmrf_topic\", \"lpmrf_topic\", \"lpmrf_topic\", \"lpmrf_topic\", \"lucid\", \"lucid\", \"lucid\", \"lucid\", \"lucid\", \"lucid\", \"manifold\", \"manifold\", \"manifold\", \"manifold\", \"manifold\", \"manifold\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix_completion\", \"matrix_completion\", \"matrix_completion\", \"matrix_completion\", \"matrix_completion\", \"mds_code\", \"mds_code\", \"mds_code\", \"mds_code\", \"mds_code\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"memorability\", \"memorability\", \"memorability\", \"memorability\", \"memorability\", \"memorability\", \"memorable\", \"memorable\", \"memorable\", \"memorable\", \"memorable\", \"memorable\", \"memorized\", \"memorized\", \"memorized\", \"memorized\", \"memorized\", \"memorized\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"metric\", \"metric\", \"metric\", \"metric\", \"metric\", \"metric\", \"metric\", \"minkowski\", \"minkowski\", \"minkowski\", \"minkowski\", \"minkowski\", \"mismatch_error\", \"mismatch_error\", \"mismatch_error\", \"mismatch_error\", \"mismatch_error\", \"mismatch_error\", \"mixed_membership\", \"mixed_membership\", \"mixed_membership\", \"mixed_membership\", \"mixed_membership\", \"mixed_membership\", \"mlb\", \"mlb\", \"mlb\", \"mlb\", \"mlb\", \"mmsb\", \"mmsb\", \"mmsb\", \"mmsb\", \"mmsb\", \"mmsb\", \"mmtm\", \"mmtm\", \"mmtm\", \"mmtm\", \"mmtm\", \"mmtm\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"mrbcd\", \"mrbcd\", \"mrbcd\", \"mrbcd\", \"mrbcd\", \"mrbcd\", \"mri\", \"mri\", \"mri\", \"mri\", \"mri\", \"multinomial\", \"multinomial\", \"multinomial\", \"multinomial\", \"multinomial\", \"multinomial\", \"mutual\", \"mutual\", \"mutual\", \"mutual\", \"mutual\", \"mutual\", \"native\", \"native\", \"native\", \"native\", \"native\", \"native\", \"net\", \"net\", \"net\", \"net\", \"net\", \"net\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network\", \"network_load\", \"network_load\", \"network_load\", \"network_load\", \"network_load\", \"network_load\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural_net\", \"neural_net\", \"neural_net\", \"neural_net\", \"neural_net\", \"neural_net\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"neuron\", \"neuronal\", \"neuronal\", \"neuronal\", \"neuronal\", \"neuronal\", \"neuronal\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"nonparametric\", \"nonparametric\", \"nonparametric\", \"nonparametric\", \"nonparametric\", \"nonparametric\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"nystagmus\", \"nystagmus\", \"nystagmus\", \"nystagmus\", \"nystagmus\", \"nystagmus\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"opt\", \"opt\", \"opt\", \"opt\", \"opt\", \"opt\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"order_optimality\", \"order_optimality\", \"order_optimality\", \"order_optimality\", \"order_optimality\", \"orientation\", \"orientation\", \"orientation\", \"orientation\", \"orientation\", \"orientation\", \"orl_cf\", \"orl_cf\", \"orl_cf\", \"orl_cf\", \"orl_cf\", \"orl_cf\", \"oscillation\", \"oscillation\", \"oscillation\", \"oscillation\", \"oscillation\", \"oscillation\", \"oscillation\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"paint\", \"paint\", \"paint\", \"paint\", \"paint\", \"paint\", \"pan\", \"pan\", \"pan\", \"pan\", \"pan\", \"pan\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"path\", \"path\", \"path\", \"path\", \"path\", \"path\", \"pathway\", \"pathway\", \"pathway\", \"pathway\", \"pathway\", \"pathway\", \"pathway\", \"pathway\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern_age\", \"pattern_age\", \"pattern_age\", \"pattern_age\", \"pattern_age\", \"pattern_age\", \"penalize\", \"penalize\", \"penalize\", \"penalize\", \"penalize\", \"penalize\", \"penalize\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"periodic_alternate\", \"periodic_alternate\", \"periodic_alternate\", \"periodic_alternate\", \"periodic_alternate\", \"periodic_alternate\", \"permutation\", \"permutation\", \"permutation\", \"permutation\", \"permutation\", \"permutation\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"plasticity\", \"plasticity\", \"plasticity\", \"plasticity\", \"plasticity\", \"plasticity\", \"pmrf\", \"pmrf\", \"pmrf\", \"pmrf\", \"pmrf\", \"pmrf\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"pol\", \"pol\", \"pol\", \"pol\", \"pol\", \"pol\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdp\", \"pomdps\", \"pomdps\", \"pomdps\", \"pomdps\", \"pomdps\", \"power_iteration\", \"power_iteration\", \"power_iteration\", \"power_iteration\", \"power_iteration\", \"pq_route\", \"pq_route\", \"pq_route\", \"pq_route\", \"pq_route\", \"pq_route\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"preference\", \"preference\", \"preference\", \"preference\", \"preference\", \"preference\", \"preference\", \"preference_graph\", \"preference_graph\", \"preference_graph\", \"preference_graph\", \"preference_graph\", \"primary_stress\", \"primary_stress\", \"primary_stress\", \"primary_stress\", \"primary_stress\", \"primitive\", \"primitive\", \"primitive\", \"primitive\", \"primitive\", \"primitive\", \"principal_curve\", \"principal_curve\", \"principal_curve\", \"principal_curve\", \"principal_curve\", \"principal_curve\", \"privacy\", \"privacy\", \"privacy\", \"privacy\", \"privacy\", \"privacy\", \"privacy_preserving\", \"privacy_preserving\", \"privacy_preserving\", \"privacy_preserving\", \"privacy_preserving\", \"privacy_preserving\", \"private\", \"private\", \"private\", \"private\", \"private\", \"private\", \"prl\", \"prl\", \"prl\", \"prl\", \"prl\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probe\", \"probe\", \"probe\", \"probe\", \"probe\", \"probe\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"processor\", \"processor\", \"processor\", \"processor\", \"processor\", \"processor\", \"produce\", \"produce\", \"produce\", \"produce\", \"produce\", \"produce\", \"produce\", \"produce\", \"prolong\", \"prolong\", \"prolong\", \"prolong\", \"prolong\", \"prolong\", \"proposed_scfvc\", \"proposed_scfvc\", \"proposed_scfvc\", \"proposed_scfvc\", \"proposed_scfvc\", \"ptr_net\", \"ptr_net\", \"ptr_net\", \"ptr_net\", \"ptr_net\", \"ptr_net\", \"purkinje_cell\", \"purkinje_cell\", \"purkinje_cell\", \"purkinje_cell\", \"purkinje_cell\", \"purkinje_cell\", \"quantization\", \"quantization\", \"quantization\", \"quantization\", \"quantization\", \"quantization\", \"query_phrase\", \"query_phrase\", \"query_phrase\", \"query_phrase\", \"query_phrase\", \"query_phrase\", \"rac\", \"rac\", \"rac\", \"rac\", \"rac\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"rank\", \"ranker_evaluation\", \"ranker_evaluation\", \"ranker_evaluation\", \"ranker_evaluation\", \"ranker_evaluation\", \"ranker_evaluation\", \"rating\", \"rating\", \"rating\", \"rating\", \"rating\", \"rating\", \"recall\", \"recall\", \"recall\", \"recall\", \"recall\", \"recall\", \"recollection\", \"recollection\", \"recollection\", \"recollection\", \"recollection\", \"recollection\", \"reconstruction\", \"reconstruction\", \"reconstruction\", \"reconstruction\", \"reconstruction\", \"reconstruction\", \"reconstruction\", \"reeb_graph\", \"reeb_graph\", \"reeb_graph\", \"reeb_graph\", \"reeb_graph\", \"reeb_graph\", \"reflectance\", \"reflectance\", \"reflectance\", \"reflectance\", \"reflectance\", \"reflectance\", \"reflectance\", \"region\", \"region\", \"region\", \"region\", \"region\", \"region\", \"region\", \"registration\", \"registration\", \"registration\", \"registration\", \"registration\", \"registration\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret\", \"reinforcement_learne\", \"reinforcement_learne\", \"reinforcement_learne\", \"reinforcement_learne\", \"reinforcement_learne\", \"reinforcement_learne\", \"reinforcement_learning\", \"reinforcement_learning\", \"reinforcement_learning\", \"reinforcement_learning\", \"reinforcement_learning\", \"reinforcement_learning\", \"relative\", \"relative\", \"relative\", \"relative\", \"relative\", \"relative\", \"relative\", \"relevance_relation\", \"relevance_relation\", \"relevance_relation\", \"relevance_relation\", \"relevance_relation\", \"relevance_relation\", \"repetition\", \"repetition\", \"repetition\", \"repetition\", \"repetition\", \"repetition\", \"repetition\", \"residual\", \"residual\", \"residual\", \"residual\", \"residual\", \"residual\", \"residual\", \"residue\", \"residue\", \"residue\", \"residue\", \"residue\", \"resonance\", \"resonance\", \"resonance\", \"resonance\", \"resonance\", \"resonance\", \"resonant\", \"resonant\", \"resonant\", \"resonant\", \"resonant\", \"response\", \"response\", \"response\", \"response\", \"response\", \"response\", \"response\", \"response\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"revenue\", \"revenue\", \"revenue\", \"revenue\", \"revenue\", \"revenue\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"robinson\", \"robinson\", \"robinson\", \"robinson\", \"robinson\", \"robot\", \"robot\", \"robot\", \"robot\", \"robot\", \"robot\", \"robustness\", \"robustness\", \"robustness\", \"robustness\", \"robustness\", \"robustness\", \"robustness\", \"rosetta\", \"rosetta\", \"rosetta\", \"rosetta\", \"rosetta\", \"rosetta\", \"rotation\", \"rotation\", \"rotation\", \"rotation\", \"rotation\", \"rotation\", \"rotation\", \"round\", \"round\", \"round\", \"round\", \"round\", \"round\", \"round\", \"route\", \"route\", \"route\", \"route\", \"route\", \"route\", \"row\", \"row\", \"row\", \"row\", \"row\", \"row\", \"row\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"satisfie\", \"satisfie\", \"satisfie\", \"satisfie\", \"satisfie\", \"satisfie\", \"satisfie\", \"scb\", \"scb\", \"scb\", \"scb\", \"scb\", \"scb\", \"scenario\", \"scenario\", \"scenario\", \"scenario\", \"scenario\", \"scenario\", \"scenario\", \"searchlight\", \"searchlight\", \"searchlight\", \"searchlight\", \"searchlight\", \"searchlight\", \"semantic\", \"semantic\", \"semantic\", \"semantic\", \"semantic\", \"semantic\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"shading\", \"shading\", \"shading\", \"shading\", \"shading\", \"shading\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"short_dot\", \"short_dot\", \"short_dot\", \"short_dot\", \"short_dot\", \"short_dot\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"signal\", \"signal\", \"signal\", \"signal\", \"signal\", \"signal\", \"singular_value\", \"singular_value\", \"singular_value\", \"singular_value\", \"singular_value\", \"singular_value\", \"software\", \"software\", \"software\", \"software\", \"software\", \"software\", \"sound\", \"sound\", \"sound\", \"sound\", \"sound\", \"sound\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"speech\", \"speech\", \"speech\", \"speech\", \"speech\", \"speech\", \"speech_signal\", \"speech_signal\", \"speech_signal\", \"speech_signal\", \"speech_signal\", \"speech_signal\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike\", \"spike_time\", \"spike_time\", \"spike_time\", \"spike_time\", \"spike_time\", \"spike_time\", \"splice\", \"splice\", \"splice\", \"splice\", \"splice\", \"spvrg\", \"spvrg\", \"spvrg\", \"spvrg\", \"spvrg\", \"spvrg\", \"starter_file\", \"starter_file\", \"starter_file\", \"starter_file\", \"starter_file\", \"starter_file\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stimulus\", \"stock\", \"stock\", \"stock\", \"stock\", \"stock\", \"stock\", \"stop\", \"stop\", \"stop\", \"stop\", \"stop\", \"stop\", \"straggler\", \"straggler\", \"straggler\", \"straggler\", \"straggler\", \"stress\", \"stress\", \"stress\", \"stress\", \"stress\", \"stress\", \"stroke\", \"stroke\", \"stroke\", \"stroke\", \"stroke\", \"stroke\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"submodular\", \"submodular\", \"submodular\", \"submodular\", \"submodular\", \"subsample\", \"subsample\", \"subsample\", \"subsample\", \"subsample\", \"subsample\", \"subsampling\", \"subsampling\", \"subsampling\", \"subsampling\", \"subsampling\", \"subsampling\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"superimpose\", \"superimpose\", \"superimpose\", \"superimpose\", \"superimpose\", \"syllable\", \"syllable\", \"syllable\", \"syllable\", \"syllable\", \"syllable\", \"synchronization\", \"synchronization\", \"synchronization\", \"synchronization\", \"synchronization\", \"synchronization\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"target\", \"target\", \"target\", \"target\", \"target\", \"target\", \"target\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"temporary\", \"temporary\", \"temporary\", \"temporary\", \"temporary\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"texture\", \"texture\", \"texture\", \"texture\", \"texture\", \"texture\", \"texture\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"tp\", \"tp\", \"tp\", \"tp\", \"tp\", \"tp\", \"tpdp\", \"tpdp\", \"tpdp\", \"tpdp\", \"tpdp\", \"tps\", \"tps\", \"tps\", \"tps\", \"tps\", \"tps\", \"train\", \"train\", \"train\", \"train\", \"train\", \"train\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"transaction\", \"transaction\", \"transaction\", \"transaction\", \"transaction\", \"transaction\", \"transform\", \"transform\", \"transform\", \"transform\", \"transform\", \"transform\", \"transition\", \"transition\", \"transition\", \"transition\", \"transition\", \"transition\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"trial\", \"trial\", \"trial\", \"trial\", \"trial\", \"trial\", \"triangle\", \"triangle\", \"triangle\", \"triangle\", \"triangle\", \"triangle\", \"triangular_motif\", \"triangular_motif\", \"triangular_motif\", \"triangular_motif\", \"triangular_motif\", \"triangular_motif\", \"trimmed_graphical\", \"trimmed_graphical\", \"trimmed_graphical\", \"trimmed_graphical\", \"trimmed_graphical\", \"trimmed_graphical\", \"tumor\", \"tumor\", \"tumor\", \"tumor\", \"tumor\", \"tumor\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unstable\", \"unstable\", \"unstable\", \"unstable\", \"unstable\", \"unstable\", \"unstable\", \"unsupervised_domain\", \"unsupervised_domain\", \"unsupervised_domain\", \"unsupervised_domain\", \"unsupervised_domain\", \"unsupervised_domain\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variance\", \"variance\", \"variance\", \"variance\", \"variance\", \"variance\", \"variance\", \"variance_asymptotic\", \"variance_asymptotic\", \"variance_asymptotic\", \"variance_asymptotic\", \"variance_asymptotic\", \"variance_asymptotic\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"velocity_storage\", \"velocity_storage\", \"velocity_storage\", \"velocity_storage\", \"velocity_storage\", \"velocity_storage\", \"vertex\", \"vertex\", \"vertex\", \"vertex\", \"vertex\", \"vertex\", \"vertex\", \"vestibular\", \"vestibular\", \"vestibular\", \"vestibular\", \"vestibular\", \"vestibular\", \"vestibulo\", \"vestibulo\", \"vestibulo\", \"vestibulo\", \"vestibulo\", \"victim\", \"victim\", \"victim\", \"victim\", \"victim\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"visible\", \"visible\", \"visible\", \"visible\", \"visible\", \"visible\", \"visible_neuron\", \"visible_neuron\", \"visible_neuron\", \"visible_neuron\", \"visible_neuron\", \"visible_neuron\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"visual\", \"vor\", \"vor\", \"vor\", \"vor\", \"vor\", \"vor\", \"vor\", \"vor_gain\", \"vor_gain\", \"vor_gain\", \"vor_gain\", \"vor_gain\", \"vor_gain\", \"vowel\", \"vowel\", \"vowel\", \"vowel\", \"vowel\", \"vowel\", \"voxel\", \"voxel\", \"voxel\", \"voxel\", \"voxel\", \"voxel\", \"wealth\", \"wealth\", \"wealth\", \"wealth\", \"wealth\", \"wealth\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weighted_classification\", \"weighted_classification\", \"weighted_classification\", \"weighted_classification\", \"weighted_classification\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"winner\", \"winner\", \"winner\", \"winner\", \"winner\", \"winner\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [6, 1, 8, 5, 4, 2, 3, 7]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1631363616018563683800250488\", ldavis_el1631363616018563683800250488_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1631363616018563683800250488\", ldavis_el1631363616018563683800250488_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1631363616018563683800250488\", ldavis_el1631363616018563683800250488_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "import pyLDAvis.gensim_models as gensimvis\n",
        "import pickle\n",
        "import pyLDAvis\n",
        "\n",
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "LDAvis_data_filepath = os.path.join('ldavis_tuned_'+str(num_topics))\n",
        "\n",
        "# # this is a bit time consuming - make the if statement True\n",
        "# # if you want to execute visualization prep yourself\n",
        "if 1 == 1:\n",
        "    LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
        "    with open(LDAvis_data_filepath, 'wb') as f:\n",
        "        pickle.dump(LDAvis_prepared, f)\n",
        "\n",
        "# load the pre-prepared pyLDAvis data from disk\n",
        "with open(LDAvis_data_filepath, 'rb') as f:\n",
        "    LDAvis_prepared = pickle.load(f)\n",
        "\n",
        "pyLDAvis.save_html(LDAvis_prepared, 'ldavis_tuned_'+ str(num_topics) +'.html')\n",
        "\n",
        "LDAvis_prepared"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsljZeqa2Wp0"
      },
      "source": [
        "** **\n",
        "#### Closing Notes\n",
        "\n",
        "We started with understanding why evaluating the topic model is essential. Next, we reviewed existing methods and scratched the surface of topic coherence, along with the available coherence measures. Then we built a default LDA model using Gensim implementation to establish the baseline coherence score and reviewed practical ways to optimize the LDA hyperparameters.\n",
        "\n",
        "Hopefully, this article has managed to shed light on the underlying topic evaluation strategies, and intuitions behind it.\n",
        "\n",
        "** **\n",
        "#### References:\n",
        "1. http://qpleple.com/perplexity-to-evaluate-topic-models/\n",
        "2. https://www.amazon.com/Machine-Learning-Probabilistic-Perspective-Computation/dp/0262018020\n",
        "3. https://papers.nips.cc/paper/3700-reading-tea-leaves-how-humans-interpret-topic-models.pdf\n",
        "4. https://github.com/mattilyra/pydataberlin-2017/blob/master/notebook/EvaluatingUnsupervisedModels.ipynb\n",
        "5. https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
        "6. http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf\n",
        "7. http://palmetto.aksw.org/palmetto-webapp/"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vjPvti4y2Wp0"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}